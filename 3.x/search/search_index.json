{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"","boost":10},{"location":"api/","title":"Api","text":"<pre><code>classDiagram\n    class RapidataClient {\n        +RapidataOrderManager order\n        +RapidataValidationManager validation\n    }\n\n    class RapidataOrderManager {\n        +RapidataFilters filter\n        +RapidataSettings settings\n        +RapidataSelections selections\n        +create_****_order()\n        +get_order_by_id()\n        +find_orders()\n    }\n\n    class RapidataValidationManager {\n        +RapidsManager rapid\n        +create_****_set()\n        +get_validation_set_by_id()\n        +find_validation_sets()\n    }\n\n    class RapidataFilters {\n        +user_score\n        +age\n        +country\n        +gender\n        +language\n    }\n\n    class RapidataSettings {\n        +alert_on_fast_response\n        +translation_behaviour\n        +free_text_minimum_characters\n        +no_shuffle\n        +play_video_until_the_end\n    }\n\n    class RapidataSelections {\n        +demographic\n        +labeling\n        +validation\n        +conditionl_validation\n        +capped\n    }\n\n    class RapidsManager {\n        +****_rapid()\n    }\n\n    RapidataClient --* RapidataOrderManager\n    RapidataClient --* RapidataValidationManager\n    RapidataOrderManager --* RapidataFilters\n    RapidataOrderManager --* RapidataSettings\n    RapidataOrderManager --* RapidataSelections\n    RapidataValidationManager --* RapidsManager\n\n    link RapidataClient \"../reference/rapidata/rapidata_client/rapidata_client/\" \"\"\n    link RapidataOrderManager \"../reference/rapidata/rapidata_client/order/rapidata_order_manager/\" \"\"\n    link RapidataValidationManager \"../reference/rapidata/rapidata_client/validation/validation_set_manager/\" \"\"\n    link RapidataFilters \"../reference/rapidata/rapidata_client/filter/rapidata_filters/\" \"\"\n    link RapidataSettings \"../reference/rapidata/rapidata_client/settings/rapidata_settings/\" \"\"\n    link RapidataSelections \"../reference/rapidata/rapidata_client/selection/rapidata_selections/\" \"\"\n    link RapidsManager \"../reference/rapidata/rapidata_client/validation/rapids/rapids_manager/\" \"\"\n</code></pre>","boost":10},{"location":"api/#rapidata-api","title":"Rapidata API","text":"<p>The Rapidata API builds on the RapidataClient class. This class is the entry point for all operations. The RapidataClient class has two main properties, order and validation, which are used to manage orders and validation sets respectively.</p>","boost":10},{"location":"api/#order-related-classes","title":"Order related classes","text":"<p>RapidataOrderManger - accessible through the RapidataClient(rapi) under rapi.order</p> <p>RapidataFilters - accessible through the RapidataClient(rapi) under rapi.order</p> <p>RapidataSettings - accessible through the RapidataClient(rapi) under rapi.order</p> <p>RapidataSelections - accessible through the RapidataClient(rapi) under rapi.order</p>","boost":10},{"location":"api/#validation-related-classes","title":"Validation related classes","text":"<p>RapidataValidationManger - accessible through the RapidataClient(rapi) under rapi.validation</p> <p>RapidsManager - accessible through the RapidataClient(rapi) under rapi.validation.rapid. Used to create specific rapids to be added to a validation set.</p>","boost":10},{"location":"audiences/","title":"\ud83d\udc65 Custom Audiences","text":"","boost":10},{"location":"audiences/#custom-audiences","title":"Custom Audiences","text":"<p>Custom audiences let you train labelers with qualification examples specific to your task, resulting in higher quality labels.</p>","boost":10},{"location":"audiences/#audience-types","title":"Audience Types","text":"Audience Type Speed Quality Best For Global Fastest Baseline Quick prototyping, simple tasks Curated Fast Good Tasks with a known domain (e.g. prompt alignment) Custom Slower initial setup Highest Production workloads, nuanced tasks <p>The global audience is the broadest pool of labelers, ready to work on any task immediately.</p> <p>A curated audience is a pre-existing pool of labelers trained on a specific type of task. It offers better quality than the global audience without requiring any setup.</p> <p>A custom audience filters labelers through qualification examples before they can work on your data. Only labelers who demonstrate they understand your tasks will be included, leading to the most accurate results.</p> <p>Note: You can see the curated audiences along with your own in the Rapidata Dashboard.</p>","boost":10},{"location":"audiences/#creating-a-custom-audience","title":"Creating a Custom Audience","text":"","boost":10},{"location":"audiences/#step-1-create-the-audience","title":"Step 1: Create the Audience","text":"<pre><code>from rapidata import RapidataClient\n\nclient = RapidataClient()\naudience = client.audience.create_audience(name=\"Image Comparison Audience\")\n</code></pre>","boost":10},{"location":"audiences/#step-2-add-qualification-examples","title":"Step 2: Add Qualification Examples","text":"<p>Qualification examples are questions with known correct answers. Labelers must answer these correctly to join your audience:</p> <pre><code>for _ in range(3):\n    audience.add_compare_example(\n        instruction=\"Which image follows the prompt more accurately?\",\n        datapoint=[\n            \"https://assets.rapidata.ai/flux_sign_diffusion.jpg\",\n            \"https://assets.rapidata.ai/mj_sign_diffusion.jpg\"\n        ],\n        truth=\"https://assets.rapidata.ai/flux_sign_diffusion.jpg\",\n        context=\"A sign that says 'Diffusion'.\"\n    )\n</code></pre> <p>Note: You need at least 3 examples to create an audience. In this example, we're adding the same qualification example 5 times for demonstration purposes only. Adding duplicates doesn't improve quality beyond adding it once. For best results, provide diverse, unique examples that cover different aspects of your task.</p> <p>Parameters:</p> <ul> <li><code>instruction</code>: The question shown to labelers</li> <li><code>datapoint</code>: The items to compare (list of URLs, local paths or text)</li> <li><code>truth</code>: The correct answer (must match one of the datapoint items exactly)</li> <li><code>context</code>: Additional context shown alongside the comparison (optional)</li> </ul>","boost":10},{"location":"audiences/#complete-example","title":"Complete Example","text":"<p>Here's the full workflow for creating a custom audience and running a labeling job:</p> <pre><code>from rapidata import RapidataClient\n\nclient = RapidataClient()\n\n# Create and configure audience with qualification examples\naudience = client.audience.create_audience(name=\"Prompt Alignment Audience\")\n\nfor _ in range(3):\n    audience.add_compare_example(\n        instruction=\"Which image follows the prompt more accurately?\",\n        datapoint=[\n            \"https://assets.rapidata.ai/flux_sign_diffusion.jpg\",\n            \"https://assets.rapidata.ai/mj_sign_diffusion.jpg\"\n        ],\n        truth=\"https://assets.rapidata.ai/flux_sign_diffusion.jpg\",\n        context=\"A sign that says 'Diffusion'.\"\n    )\n\n# Create job definition\njob_definition = client.job.create_compare_job_definition(\n    name=\"Prompt Alignment Job\",\n    instruction=\"Which image follows the prompt more accurately?\",\n    datapoints=[\n        [\"https://assets.rapidata.ai/flux_flower.jpg\",\n         \"https://assets.rapidata.ai/mj_flower.jpg\"]\n    ],\n    contexts=[\"A yellow flower sticking out of a green pot.\"]\n)\n\n# Preview before running\njob_definition.preview()\n\n# Assign to audience and get results\njob = audience.assign_job(job_definition)\njob.display_progress_bar()\nresults = job.get_results()\nprint(results)\n</code></pre>","boost":10},{"location":"audiences/#reusing-audiences","title":"Reusing Audiences","text":"<p>Once created, you can reuse your audience for multiple jobs:</p> <pre><code># Find existing audiences by name\naudiences = client.audience.find_audiences(\"Prompt Alignment\")\n\n# Or get by ID\naudience = client.audience.get_audience_by_id(\"audience_id\")\n\n# Assign new jobs to the same audience\njob = audience.assign_job(new_job_definition)\n</code></pre>","boost":10},{"location":"audiences/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Classification Jobs for categorizing data</li> <li>Understand the Results Format</li> <li>Configure Early Stopping based on confidence thresholds</li> </ul> \ud83d\udccb","boost":10},{"location":"claude_code/","title":"\ud83e\udd16 Claude Code Plugin","text":"","boost":10},{"location":"claude_code/#using-rapidata-with-claude-code","title":"Using Rapidata with Claude Code","text":"<p>The Rapidata SDK has an official Claude Code plugin that teaches Claude how to use the SDK. Once installed, Claude can help you write Rapidata integration code, create labeling jobs, set up audiences, and more - either automatically when it detects you're working with Rapidata, or on demand via the <code>/rapidata</code> command.</p>","boost":10},{"location":"claude_code/#installation","title":"Installation","text":"","boost":10},{"location":"claude_code/#1-add-the-marketplace","title":"1. Add the marketplace","text":"<p>In Claude Code, run:</p> <pre><code>/plugin marketplace add rapidataAI/skills\n</code></pre>","boost":10},{"location":"claude_code/#2-install-the-plugin","title":"2. Install the plugin","text":"<pre><code>/plugin install rapidata-sdk-plugin@rapidata-sdk-marketplace\n</code></pre> <p>That's it. The <code>/rapidata</code> skill is now available.</p>","boost":10},{"location":"claude_code/#usage","title":"Usage","text":"","boost":10},{"location":"claude_code/#automatic","title":"Automatic","text":"<p>Claude will automatically use its knowledge of the Rapidata SDK when it detects you're working with Rapidata code. Just ask naturally:</p> <pre><code>Create a comparison job that evaluates image quality between two models\n</code></pre> <pre><code>Set up a custom audience with 3 qualification examples for prompt adherence\n</code></pre>","boost":10},{"location":"claude_code/#manual","title":"Manual","text":"<p>Invoke the skill directly for SDK guidance:</p> <pre><code>/rapidata\n</code></pre> <p>Or with a specific question:</p> <pre><code>/rapidata How do I set up early stopping with a confidence threshold?\n</code></pre>","boost":10},{"location":"claude_code/#what-the-plugin-provides","title":"What the plugin provides","text":"<p>The plugin gives Claude detailed knowledge of:</p> <ul> <li>Classification, comparison, and ranking jobs \u2014 creating job definitions, configuring parameters, and interpreting results</li> <li>Audiences \u2014 finding curated audiences, creating custom audiences with qualification examples, applying demographic filters</li> <li>Flows \u2014 continuous ranking without full job setup</li> <li>MRI / Benchmarks \u2014 comparing and ranking AI models on leaderboards</li> <li>Settings \u2014 <code>NoShuffle</code>, <code>AllowNeitherBoth</code>, <code>Markdown</code>, and other display options</li> <li>Error handling \u2014 working with <code>FailedUploadException</code> for partial upload failures</li> <li>Legacy order API \u2014 backwards-compatible order creation</li> </ul>","boost":10},{"location":"claude_code/#keeping-the-plugin-up-to-date","title":"Keeping the plugin up to date","text":"<p>To pull the latest version of the plugin:</p> <pre><code>/plugin marketplace update\n</code></pre>","boost":10},{"location":"claude_code/#adding-the-plugin-to-your-project","title":"Adding the plugin to your project","text":"<p>To make the plugin available to all contributors of a project automatically, add this to your project's <code>.claude/settings.json</code>:</p> <pre><code>{\n    \"extraKnownMarketplaces\": {\n        \"rapidata-sdk-marketplace\": {\n            \"source\": {\n                \"source\": \"github\",\n                \"repo\": \"rapidataAI/skills\"\n            }\n        }\n    },\n    \"enabledPlugins\": {\n        \"rapidata-sdk-plugin@rapidata-sdk-marketplace\": true\n    }\n}\n</code></pre> <p>Contributors will be prompted to install the marketplace and plugin when they open the project.</p> \ud83d\udccb","boost":10},{"location":"confidence_stopping/","title":"\ud83d\uded1 Confidence Stopping","text":"","boost":10},{"location":"confidence_stopping/#early-stopping-based-on-confidence","title":"Early Stopping Based on Confidence","text":"<p>To improve the efficiency and cost-effectiveness of your data labeling tasks, Rapidata offers an Early Stopping feature based on confidence thresholds. This feature allows you to automatically stop collecting responses for a datapoint once a specified confidence level is reached, saving time and resources without compromising quality.</p>","boost":10},{"location":"confidence_stopping/#why-use-early-stopping","title":"Why Use Early Stopping?","text":"<p>In traditional data labeling workflows, you might request a fixed number of responses per datapoint to ensure accuracy. However, once a consensus is reached with high confidence, continuing to collect more responses becomes redundant and incurs unnecessary costs.</p> <p>Early Stopping addresses this by:</p> <ul> <li>Reducing Costs: Stop collecting responses when sufficient confidence is achieved.</li> <li>Improving Efficiency: Accelerate the labeling process by focusing resources where they are most needed.</li> <li>Maintaining Quality: Ensure that each datapoint meets your specified confidence level before stopping.</li> </ul>","boost":10},{"location":"confidence_stopping/#how-it-works","title":"How it Works","text":"<p>The Early Stopping feature leverages the trustworthiness, quantified through their <code>userScores</code>, to calculate the confidence level of each category for any given datapoint.</p>","boost":10},{"location":"confidence_stopping/#confidence-calculation","title":"Confidence Calculation","text":"<ul> <li>UserScores: Each labeler has a <code>userScore</code> between 0 and 1, representing their reliability. More information</li> <li>Aggregated Confidence: By combining the userScores of labelers who selected a particular category, the system computes the probability that this category is the correct one.</li> <li>Threshold Comparison: If the calculated confidence exceeds your specified threshold, the system stops collecting further responses for that datapoint.</li> </ul>","boost":10},{"location":"confidence_stopping/#understanding-the-confidence-threshold","title":"Understanding the Confidence Threshold","text":"<p>We've created a plot based on empirical data aided by simulations to give you an estimate of the number of responses required to reach a certain confidence level.</p> <p>There are a few things to keep in mind when interpreting the results:</p> <ul> <li>Unambiguous Scenario: The graph represents an ideal situation such as in the example below with no ambiguity which category is the correct one. A counter-example would be subjective tasks like \"Which image do you prefer?\", where there's no clear correct answer.</li> <li>Real-World Variability: Actual required responses may vary based on task complexity.</li> <li>Guidance Tool: Use the graph as a reference to set realistic expectations for your jobs.</li> <li>Response Overflow: The number of responses per datapoint may exceed the specified amount due to multiple users answering simultaneously.</li> </ul> <p>Note: The Early Stopping feature is supported for the Classification and Comparison workflows. The number of categories is the number of options in the Classification task. For the Comparison task, the number of categories is always 2.</p>","boost":10},{"location":"confidence_stopping/#using-early-stopping-in-your-job","title":"Using Early Stopping in Your Job","text":"<p>Implementing Early Stopping is straightforward. You simply add the confidence threshold as a parameter when creating the job definition.</p>","boost":10},{"location":"confidence_stopping/#example-classification-job-with-early-stopping","title":"Example: Classification Job with Early Stopping","text":"<pre><code>from rapidata import RapidataClient\n\nclient = RapidataClient()\n\n# Create audience with qualification example\naudience = client.audience.create_audience(name=\"Animal Classification Audience\")\naudience.add_classification_example(\n    instruction=\"What do you see in the image?\",\n    answer_options=[\"Cat\", \"Dog\"],\n    datapoint=\"https://assets.rapidata.ai/cat.jpeg\",\n    truth=[\"Cat\"]\n)\n\n# Create job definition with early stopping\njob_definition = client.job.create_classification_job_definition(\n    name=\"Test Classification with Early Stopping\",\n    instruction=\"What do you see in the image?\",\n    answer_options=[\"Cat\", \"Dog\"],\n    datapoints=[\"https://assets.rapidata.ai/dog.jpeg\"],\n    responses_per_datapoint=50,\n    confidence_threshold=0.99,\n)\n\n# Preview and run\njob_definition.preview()\njob = audience.assign_job(job_definition)\njob.display_progress_bar()\nresults = job.get_results()\nprint(results)\n</code></pre> <p>In this example:</p> <ul> <li><code>responses_per_datapoint=50</code>: Sets the maximum number of responses per datapoint.</li> <li><code>confidence_threshold=0.99</code>: Specifies that data collection for a datapoint should stop once a 99% confidence level is reached.</li> </ul> <p>We'd expect this to take roughly 4 responses to reach the 99% confidence level.</p>","boost":10},{"location":"confidence_stopping/#when-to-use-early-stopping","title":"When to Use Early Stopping","text":"<p>We recommend using Early Stopping when:</p> <ul> <li>Cost Efficiency: You want to optimize costs by reducing the number of responses per datapoint.</li> <li>Clear Correct Answer: The task has a clear correct answer, and you're not interested in a distribution.</li> </ul>","boost":10},{"location":"confidence_stopping/#analyzing-early-stopping-results","title":"Analyzing Early Stopping Results","text":"<p>When using Early Stopping, the results will additionally include a <code>confidencePerCategory</code> field for each datapoint. This field shows the confidence level for each of the categories in the task.</p> <p>Example: </p><pre><code>{\n    \"info\": {\n        \"createdAt\": \"2099-12-30T00:00:00.000000+00:00\",\n        \"version\": \"3.0.0\"\n    },\n    \"results\": {\n        \"globalAggregatedData\": {\n            \"Dog\": 4,\n            \"Cat\": 0\n        },\n        \"data\": [\n            {\n                \"originalFileName\": \"dog.jpeg\",\n                \"aggregatedResults\": {\n                    \"Dog\": 4,\n                    \"Cat\": 0\n                },\n                \"aggregatedResultsRatios\": {\n                    \"Dog\": 1.0,\n                    \"Cat\": 0.0\n                },\n                \"summedUserScores\": {\n                    \"Dog\": 2.0865,\n                    \"Cat\": 0.0\n                },\n                \"summedUserScoresRatios\": {\n                    \"Dog\": 1.0,\n                    \"Cat\": 0.0\n                },\n                # this only appears when using early stopping\n                \"confidencePerCategory\": {\n                    \"Dog\": 0.9943,\n                    \"Cat\": 0.0057\n                },\n                \"detailedResults\": [\n                    {\n                        \"selectedCategory\": \"Dog\",\n                        \"userDetails\": {\n                            \"country\": \"PT\",\n                            \"language\": \"pt\",\n                            \"userScore\": 0.3\n                        }\n                    },\n                    {\n                        \"selectedCategory\": \"Dog\",\n                        \"userDetails\": {\n                            \"country\": \"RS\",\n                            \"language\": \"sr\",\n                            \"userScore\": 0.8486\n                        }\n                    },\n                    {\n                        \"selectedCategory\": \"Dog\",\n                        \"userDetails\": {\n                            \"country\": \"SG\",\n                            \"language\": \"en\",\n                            \"userScore\": 0.4469\n                        }\n                    },\n                    {\n                        \"selectedCategory\": \"Dog\",\n                        \"userDetails\": {\n                            \"country\": \"IN\",\n                            \"language\": \"en\",\n                            \"userScore\": 0.4911\n                        }\n                    }\n                ]\n            }\n        ]\n    }\n}\n</code></pre><p></p> \ud83d\udccb","boost":10},{"location":"config/","title":"\ud83d\udcdd Logging & Config","text":"","boost":10},{"location":"config/#configuration-and-logging","title":"Configuration and Logging","text":"<p>The Rapidata SDK provides a centralized configuration system through the global <code>rapidata_config</code> object that controls all aspects of the SDK's behavior including logging, output management, upload settings, and data sharing.</p>","boost":10},{"location":"config/#rapidata-configuration-system","title":"Rapidata Configuration System","text":"<p>All configuration is managed through the global <code>rapidata_config</code> object, which provides a unified way to configure:</p> <ol> <li>Logging Configuration: Log levels, file output, formatting, silent mode and OpenTelemetry integration</li> <li>Upload Configuration: Worker threads and retry settings</li> </ol>","boost":10},{"location":"config/#basic-usage","title":"Basic Usage","text":"<pre><code>from rapidata import rapidata_config, logger\n\nlogger.info(\"This will not be shown\")\nrapidata_config.logging.level = \"INFO\"\nlogger.info(\"This will be shown\")\n</code></pre> <p>Note: The logging system is now fully managed through <code>rapidata_config.logging</code>. Changes to the configuration are automatically applied to the logger in real-time.</p>","boost":10},{"location":"config/#logging-configuration-options","title":"Logging Configuration Options","text":"Parameter Type Default Description <code>level</code> <code>str</code> <code>\"WARNING\"</code> Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL) <code>log_file</code> <code>Optional[str]</code> <code>None</code> Optional file path for log output <code>format</code> <code>str</code> <code>\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"</code> Log message format <code>silent_mode</code> <code>bool</code> <code>False</code> Suppress prints and progress bars (doesn't affect logging) <code>enable_otlp</code> <code>bool</code> <code>True</code> Enable OpenTelemetry trace logs to Rapidata <p>Note: Rapidata SDK tracking is limited exclusively to SDK-generated logs and traces. No other data is collected.</p>","boost":10},{"location":"config/#upload-configuration-options","title":"Upload Configuration Options","text":"Parameter Type Default Description <code>maxWorkers</code> <code>int</code> <code>25</code> Maximum concurrent upload threads <code>maxRetries</code> <code>int</code> <code>3</code> Retry attempts for failed uploads <code>cacheToDisk</code> <code>bool</code> <code>True</code> Enable disk-based caching for file uploads <code>cacheTimeout</code> <code>float</code> <code>1</code> Cache operation timeout in seconds <code>cacheLocation</code> <code>Path</code> <code>~/.cache/rapidata/upload_cache</code> Directory for cache storage (immutable) <code>cacheShards</code> <code>int</code> <code>128</code> Number of cache shards for parallel access (immutable) <code>batchSize</code> <code>int</code> <code>1000</code> Number of URLs per batch (100\u20135000) <code>batchPollInterval</code> <code>float</code> <code>0.5</code> Batch polling interval in seconds","boost":10},{"location":"config/#environment-variables","title":"Environment Variables","text":"<p>Every configuration field can also be set through an environment variable prefixed with <code>RAPIDATA_</code> followed by the field name (e.g. <code>RAPIDATA_maxWorkers</code>). This is useful for CI/CD pipelines, containers, or any context where you want to configure the SDK without changing code.</p> <p>Environment variables are applied at initialization and act as defaults \u2014 values passed explicitly in code always take precedence.</p> <p>Precedence (highest to lowest):</p> <ol> <li>Values set in code (e.g. <code>rapidata_config.upload.maxWorkers = 10</code>)</li> <li>Environment variables (<code>RAPIDATA_*</code>)</li> <li>Built-in defaults</li> </ol>","boost":10},{"location":"config/#example-env-file","title":"Example <code>.env</code> file","text":"<pre><code># --- Upload ---\nRAPIDATA_maxWorkers=25\nRAPIDATA_maxRetries=3\nRAPIDATA_cacheToDisk=true\nRAPIDATA_cacheTimeout=1\nRAPIDATA_cacheLocation=~/.cache/rapidata/upload_cache\nRAPIDATA_cacheShards=128\nRAPIDATA_batchSize=1000\nRAPIDATA_batchPollInterval=0.5\n\n# --- Logging ---\nRAPIDATA_level=WARNING\nRAPIDATA_log_file=\nRAPIDATA_format=%(asctime)s - %(name)s - %(levelname)s - %(message)s\nRAPIDATA_silent_mode=false\nRAPIDATA_enable_otlp=true\n</code></pre>","boost":10},{"location":"config/#boolean-values","title":"Boolean values","text":"<p>Boolean environment variables accept <code>1</code>, <code>true</code>, or <code>yes</code> (case-insensitive) as truthy. Everything else is treated as <code>false</code>.</p>","boost":10},{"location":"config/#loading-a-env-file","title":"Loading a <code>.env</code> file","text":"<p>The SDK does not load <code>.env</code> files automatically. Use a library like <code>python-dotenv</code> to load them before importing the SDK:</p> <pre><code>from dotenv import load_dotenv\nload_dotenv()  # reads .env into os.environ\n\nfrom rapidata import RapidataClient\n</code></pre> \ud83d\udccb","boost":10},{"location":"error_handling/","title":"\u274c Error Handling","text":"","boost":10},{"location":"error_handling/#error-handling","title":"Error Handling","text":"","boost":10},{"location":"error_handling/#introduction","title":"Introduction","text":"<p>When creating job definitions or orders with the Rapidata SDK, datapoints may fail to upload due to various reasons such as missing files, invalid formats, or network issues. Understanding how to handle these failures is essential for building robust integrations.</p> <p>When one or more datapoints fail to upload, the SDK raises a <code>FailedUploadException</code>. This exception provides detailed information about what went wrong and gives you several recovery options:</p> <ul> <li>Inspect which datapoints failed and why</li> <li>Retry the failed datapoints</li> <li>Continue with the successfully uploaded datapoints</li> </ul> <p>This guide shows you how to handle upload failures effectively.</p>","boost":10},{"location":"error_handling/#understanding-faileduploadexception","title":"Understanding FailedUploadException","text":"<p>The <code>FailedUploadException</code> is raised during <code>JobDefinition</code> or <code>Order</code> creation when one or more datapoints cannot be uploaded.  Important: Despite the exception being raised, a <code>JobDefinition</code> or <code>Order</code> object is still created with the successfully uploaded datapoints, allowing you to continue if you catch the exception.</p>","boost":10},{"location":"error_handling/#exception-properties","title":"Exception Properties","text":"<p>The exception provides these properties to help you understand and recover from failures:</p> <pre><code>FailedUploadException(\n    dataset: RapidataDataset,              # The dataset that was being created\n    failed_uploads: list[FailedUpload],    # Basic list of failed datapoints\n    order: Optional[RapidataOrder],        # The order object (if order creation)\n    job_definition: Optional[JobDefinition] # The job definition object (if job creation)\n)\n</code></pre>","boost":10},{"location":"error_handling/#understanding-failure-information","title":"Understanding Failure Information","text":"<p>The exception provides two ways to inspect failures, depending on your needs:</p>","boost":10},{"location":"error_handling/#detailed_failures-full-error-details","title":"<code>detailed_failures</code> - Full Error Details","text":"<p>Use this when you need complete information about each failure, including error type, timestamp, and the original exception:</p> <pre><code>exception.detailed_failures\n# Returns: list[FailedUpload[Datapoint]]\n</code></pre> <p>Each <code>FailedUpload</code> object contains:</p> <ul> <li><code>item</code>: The datapoint that failed</li> <li><code>error_message</code>: Human-readable explanation of what went wrong</li> <li><code>error_type</code>: The type of error (e.g., \"AssetUploadFailed\", \"RapidataError\")</li> <li><code>timestamp</code>: When the failure occurred</li> <li><code>exception</code>: The original exception (if available)</li> </ul> <p>Example: </p><pre><code>[\n    FailedUpload(\n        item=Datapoint(asset=['missing.jpg', 'valid.jpg'], ...),\n        error_message='One or more required assets failed to upload',\n        error_type='AssetUploadFailed',\n        timestamp=datetime(2026, 2, 2, 15, 32, 30),\n        exception=None\n    )\n]\n</code></pre><p></p>","boost":10},{"location":"error_handling/#failures_by_reason-grouped-by-error-type","title":"<code>failures_by_reason</code> - Grouped by Error Type","text":"<p>Use this when you want to identify patterns and handle different failure types differently:</p> <pre><code>exception.failures_by_reason\n# Returns: dict[str, list[Datapoint]]\n</code></pre> <p>This groups all failed datapoints by their error message, making it easy to see common issues at a glance.</p> <p>Example: </p><pre><code>{\n    'One or more required assets failed to upload': [\n        Datapoint(asset=['missing1.jpg', 'valid.jpg'], ...),\n        Datapoint(asset=['missing2.jpg', 'valid.jpg'], ...)\n    ],\n    'Invalid datapoint format': [\n        Datapoint(asset=['test.jpg'], ...)\n    ]\n}\n</code></pre><p></p>","boost":10},{"location":"error_handling/#types-of-failures","title":"Types of Failures","text":"<p>Asset Upload Failures: When assets (images, videos, etc.) fail to upload, all affected datapoints will have the same error message: <code>\"One or more required assets failed to upload\"</code>. This happens before datapoint creation begins.</p> <p>Datapoint Creation Failures: After assets are successfully uploaded, datapoints are created. These failures can have different reasons depending on what went wrong (e.g., validation errors, format issues, backend constraints). Each datapoint may fail for a unique reason.</p>","boost":10},{"location":"error_handling/#recovery-strategies","title":"Recovery Strategies","text":"","boost":10},{"location":"error_handling/#strategy-1-continue-with-successfully-uploaded-datapoints","title":"Strategy 1: Continue with Successfully Uploaded Datapoints","text":"<p>When a <code>FailedUploadException</code> is raised, the <code>JobDefinition</code> or <code>Order</code> is still created with the successfully uploaded datapoints. You can catch the exception and continue using the created object:</p> <p>For Job Definitions: </p><pre><code>from rapidata import RapidataClient\nfrom rapidata.rapidata_client.exceptions import FailedUploadException\n\nclient = RapidataClient()\n\ntry:\n    job_def = client.job.create_classification_job_definition(\n        name=\"Image Classification\",\n        instruction=\"What animal is in this image?\",\n        answer_options=[\"Cat\", \"Dog\", \"Bird\"],\n        datapoints=[\"cat1.jpg\", \"dog1.jpg\", \"missing.jpg\"]\n    )\nexcept FailedUploadException as e:\n    print(f\"Warning: {len(e.failed_uploads)} datapoints failed to upload\")\n\n    # Check if failure rate is acceptable\n    if len(e.failed_uploads) &gt; len(datapoints) * 0.1:  # More than 10% failed\n        raise ValueError(\"Too many failures, aborting\")\n\n    # Continue with the job definition that was created with successful datapoints\n    job_def = e.job_definition\n    # You can now use job_def normally - it contains the successfully uploaded datapoints\n</code></pre><p></p> <p>For Orders: </p><pre><code>from rapidata import RapidataClient\nfrom rapidata.rapidata_client.exceptions import FailedUploadException\n\nclient = RapidataClient()\n\ntry:\n    order = client.order.create(\n        name=\"Image Classification Order\",\n        instruction=\"What animal is in this image?\",\n        answer_options=[\"Cat\", \"Dog\", \"Bird\"],\n        datapoints=[\"cat1.jpg\", \"dog1.jpg\", \"missing.jpg\"]\n    )\nexcept FailedUploadException as e:\n    print(f\"Warning: {len(e.failed_uploads)} datapoints failed\")\n\n    # Continue with the order that was created with successful datapoints\n    order = e.order\n\n    # Run the order with the successfully uploaded datapoints\n    order.run()\n</code></pre><p></p>","boost":10},{"location":"error_handling/#strategy-2-retry-failed-datapoints","title":"Strategy 2: Retry Failed Datapoints","text":"<p>After catching the exception, you can fix the issues (e.g., correct file paths, fix formats) and retry the failed datapoints by adding them to the dataset:</p> <pre><code>from rapidata import RapidataClient\nfrom rapidata.rapidata_client.exceptions import FailedUploadException\n\nclient = RapidataClient()\n\ntry:\n    job_def = client.job.create_classification_job_definition(\n        name=\"Image Classification\",\n        instruction=\"What animal is in this image?\",\n        answer_options=[\"Cat\", \"Dog\", \"Bird\"],\n        datapoints=[\"cat1.jpg\", \"dog1.jpg\", \"missing.jpg\"]\n    )\nexcept FailedUploadException as e:\n    # Inspect what failed\n    print(f\"{len(e.failed_uploads)} datapoints failed:\")\n    for reason, datapoints in e.failures_by_reason.items():\n        print(f\"  {reason}: {len(datapoints)} datapoints\")\n\n    # Fix the issues (e.g., correct file paths), then retry\n    # Note: You need to fix the issues before retrying\n    successful_retries, failed_retries = e.dataset.add_datapoints(e.failed_uploads)\n    print(f\"{len(successful_retries)} datapoints successfully added on retry\")\n\n    if failed_retries:\n        print(f\"{len(failed_retries)} datapoints still failed after retry\")\n</code></pre>","boost":10},{"location":"error_handling/#strategy-3-retrieve-and-use-after-exception-if-not-caught","title":"Strategy 3: Retrieve and Use After Exception (If Not Caught)","text":"<p>If you didn't catch the exception during creation, you can still retrieve and use the job definition or order. They were created with the successfully uploaded datapoints and can be used through code or the app.rapidata.ai UI:</p> <p>For Orders: </p><pre><code>from rapidata import RapidataClient\n\nclient = RapidataClient()\n\n# Retrieve the order using its ID (from the exception message or UI)\norder = client.order.get_order_by_id(order_id)\n\n# Run the order with the successfully uploaded datapoints\norder.run()\n</code></pre><p></p> <p>For Job Definitions: </p><pre><code>from rapidata import RapidataClient\n\nclient = RapidataClient()\n\n# Retrieve the job definition using its ID (from the exception message or UI)\njob_def = client.job.get_job_definition_by_id(job_definition_id)\n\n# Use the job definition normally (e.g., assign it to an audience)\naudience.assign_job(job_def)\n</code></pre><p></p> \ud83d\udccb","boost":10},{"location":"flows/","title":"Overview","text":"","boost":10},{"location":"flows/#ranking-flows","title":"Ranking Flows","text":"","boost":10},{"location":"flows/#overview","title":"Overview","text":"<p>Ranking Flows provide a lightweight way to continuously rank items using human comparisons without the overhead of creating full orders. They are ideal for ongoing evaluation where new items are added over time and ranked against existing ones using a bradley terry paired comparison based rating system.</p> <p>Note: Can be used with Images, Videos, Audio, and Text.</p>","boost":10},{"location":"flows/#how-to-use-ranking-flows","title":"How to use Ranking Flows","text":"","boost":10},{"location":"flows/#1-create-a-flow","title":"1. Create a Flow","text":"<p>Start by creating a ranking flow with an instruction that will be shown to evaluators for each comparison:</p> <pre><code>from rapidata import RapidataClient\n\nclient = RapidataClient()\n\nflow = client.flow.create_ranking_flow(\n    name=\"Image Quality Ranking\",\n    instruction=\"Which image looks better?\",\n)\n</code></pre>","boost":10},{"location":"flows/#2-add-a-flow-batch","title":"2. Add a Flow Batch","text":"<p>Submit datapoints to the flow by creating a batch. Each batch uploads a set of items that will be compared and ranked:</p> <pre><code>flow_item = flow.create_new_flow_batch(\n    datapoints=[\n        \"https://example.com/image_a.jpg\",\n        \"https://example.com/image_b.jpg\",\n        \"https://example.com/image_c.jpg\",\n    ],\n)\n</code></pre> <p>You can optionally provide a <code>context</code> string that will be shown alongside the instruction, and a <code>time_to_live</code> to automatically stop the flow item after a given number of seconds (minimum 60):</p> <pre><code>flow_item = flow.create_new_flow_batch(\n    datapoints=[\n        \"https://example.com/image_a.jpg\",\n        \"https://example.com/image_b.jpg\",\n        \"https://example.com/image_c.jpg\",\n    ],\n    context=\"These images were generated by model X\",\n    time_to_live=300,  # stop after maximum 5 minutes and return partial results\n)\n</code></pre>","boost":10},{"location":"flows/#3-get-results","title":"3. Get Results","text":"<p>Call <code>get_results()</code> on a flow item to retrieve the ranking results. If the flow item is still processing, this will automatically wait until it completes (or becomes incomplete due to <code>time_to_live</code>):</p> <pre><code>results = flow_item.get_results()\n</code></pre> <p>You can also check the status without blocking:</p> <pre><code>status = flow_item.get_status()  # Pending, Running, Completed, Failed, Stopped, or Incomplete\n</code></pre> <p>Note: A flow item enters the <code>Incomplete</code> state when its <code>time_to_live</code> expires before all responses are collected. You can still retrieve partial results from incomplete flow items.</p> <p>To get the win/loss matrix per flow item and see what datapoints were preferred over each other:</p> <pre><code>matrix = flow_item.get_win_loss_matrix()\n</code></pre> <p>This returns a pandas <code>DataFrame</code> where <code>matrix.loc[a, b]</code> is the number of times item <code>a</code> was preferred over item <code>b</code>.</p> <p>To get the total number of pairwise comparison responses collected for a flow item:</p> <pre><code>response_count = flow_item.get_response_count()\n</code></pre> <p>To query all flow items for a flow:</p> <pre><code>all_items = flow.get_flow_items()\n</code></pre>","boost":10},{"location":"flows/#4-update-flow-configuration","title":"4. Update Flow Configuration","text":"<p>You can update the flow configuration at any time:</p> <pre><code>flow.update_config(\n    instruction=\"Which image has higher visual quality?\",\n)\n</code></pre> <p>Note: This config will only effect new flow items and not modify existing ones.</p>","boost":10},{"location":"flows/#retrieving-existing-flows","title":"Retrieving Existing Flows","text":"<p>You can retrieve flows by ID or list your recent flows:</p> <pre><code># Get a specific flow by ID\nflow = client.flow.get_flow_by_id(\"flow_id_here\")\n\n# List recent flows\nrecent_flows = client.flow.find_flows(amount=10)\n</code></pre>","boost":10},{"location":"flows/#deleting-a-flow","title":"Deleting a Flow","text":"<pre><code>flow.delete()\n</code></pre> \ud83d\udccb","boost":10},{"location":"human_prompting/","title":"\ud83d\udca1 Human Prompting","text":"","boost":10},{"location":"human_prompting/#effective-instruction-design-for-rapidata-tasks","title":"Effective Instruction Design for Rapidata Tasks","text":"<p>When creating tasks for human labelers using the Rapidata API, phrasing your instructions well can significantly improve quality and consistency of the responses you receive. This guide provides best practices for designing effective instructions for your Rapidata tasks.</p>","boost":10},{"location":"human_prompting/#time-constraints","title":"Time Constraints","text":"<p>Each labeler session has a limited time window of 25 seconds to complete all tasks. With this in mind:</p> <ul> <li>Be concise: Keep instructions as brief as possible while maintaining clarity</li> <li>Use simple language: Avoid complex terminology or jargon</li> <li>Focus on the essentials: Include only what is needed to complete the task</li> </ul>","boost":10},{"location":"human_prompting/#language-clarity","title":"Language Clarity","text":"<p>Since Rapidata tasks are presented to a diverse audience of labelers:</p> <ul> <li>Use accessible language: The average person should be able to understand your instructions clearly</li> <li>Avoid ambiguity: Ensure there's only one way to interpret your instructions</li> <li>Be specific: Clearly state what you're looking for in the responses</li> </ul>","boost":10},{"location":"human_prompting/#question-framing","title":"Question Framing","text":"<p>The way you frame questions significantly impacts response quality:</p>","boost":10},{"location":"human_prompting/#use-positive-framing","title":"Use Positive Framing","text":"<p>Frame questions in the positive rather than negative. Positive questions are easier to process quickly.</p> <p>Better: </p><pre><code>\"Which image looks more realistic?\"\n</code></pre><p></p> <p>Avoid: </p><pre><code>\"Which image looks less AI-generated?\"\n</code></pre><p></p>","boost":10},{"location":"human_prompting/#limit-decision-criteria","title":"Limit Decision Criteria","text":"<p>Don't overload labelers with multiple criteria in a single question.</p> <p>Better: </p><pre><code>\"What animal is in the image? - rabbit/dog/cat/other\"\n</code></pre><p></p> <p>Avoid: </p><pre><code>\"Does this image contain a rabbit, a dog, or a cat? - yes/no\"\n</code></pre><p></p>","boost":10},{"location":"human_prompting/#use-clear-response-options","title":"Use Clear Response Options","text":"<p>Provide distinct, non-overlapping response options.</p> <p>Better: </p><pre><code>\"Rate the image quality: poor/acceptable/excellent\"\n</code></pre><p></p> <p>Avoid: </p><pre><code>\"Rate the image quality: bad/not good/fine/good/great\"\n</code></pre><p></p>","boost":10},{"location":"human_prompting/#example-implementation","title":"Example Implementation","text":"<p>When creating a Rapidata job, implement these principles as follows:</p> <pre><code>from rapidata import RapidataClient\n\nclient = RapidataClient()\n\n# Create audience with clear qualification example\naudience = client.audience.create_audience(name=\"Image Coherence Audience\")\naudience.add_compare_example(\n    instruction=\"Which image has more glitches and is more likely to be AI generated?\",\n    datapoint=[\n        \"https://assets.rapidata.ai/good_ai_generated_image.png\",\n        \"https://assets.rapidata.ai/bad_ai_generated_image.png\"\n    ],\n    truth=\"https://assets.rapidata.ai/bad_ai_generated_image.png\"\n)\n\n# Create job definition with clear instruction\njob_definition = client.job.create_compare_job_definition(\n    name=\"Image Coherence Comparison\",\n    instruction=\"Which image has more glitches and is more likely to be AI generated?\",\n    datapoints=[\n        [\"https://assets.rapidata.ai/flux-1.1-pro/33_2.jpg\",\n         \"https://assets.rapidata.ai/stable-diffusion-3/33_0.jpg\"]\n    ]\n)\n\n# Preview before running\njob_definition.preview()\n</code></pre>","boost":10},{"location":"human_prompting/#common-task-types-and-recommended-instructions","title":"Common Task Types and Recommended Instructions","text":"","boost":10},{"location":"human_prompting/#image-comparison-tasks","title":"Image Comparison Tasks","text":"<pre><code># Comparing image preference\ninstruction=\"Which image do you prefer?\"\n\n# Comparing prompt adherence\ninstruction=\"Which image matches the description better?\"\n\n# Comparing image coherence\ninstruction=\"Which image has more glitches and is more likely to be AI generated?\"\n\n# Comparing two texts\ninstruction=\"Which of these sentences makes more sense?\"\n</code></pre>","boost":10},{"location":"human_prompting/#classification-tasks","title":"Classification Tasks","text":"<pre><code># Simple classification\ninstruction=\"What object is in the image?\"\n\n# Likert classification (add NoShuffle setting)\ninstruction=\"How well does the video match the description?\"\nanswer_options=[\"1: Perfectly\",\n                \"2: Very well\",\n                \"3: Moderately\",\n                \"4: A little\",\n                \"5: Not at all\"]\n</code></pre>","boost":10},{"location":"human_prompting/#monitoring-and-iteration","title":"Monitoring and Iteration","text":"<p>After assigning your job to an audience, monitor the initial responses to see if labelers are understanding your instructions as intended.</p> <p>You can preview how users will see the task by calling the <code>.preview()</code> method on the job definition: </p><pre><code>job_definition.preview()\n</code></pre><p></p> <p>If you see that labelers are giving inconsistent or incorrect answers:</p> <ol> <li>Review and simplify your instructions</li> <li>Update your audience's qualification examples if needed</li> <li>Create a new job definition with the improved settings</li> </ol> <p>This helps ensure you get high quality results from labelers.</p> <p>For more information on creating and managing jobs, refer to the Rapidata API documentation and Understanding the Results guide.</p> \ud83d\udccb","boost":10},{"location":"job_definition_parameters/","title":"\ud83d\udcd6 Parameter Reference","text":"","boost":10},{"location":"job_definition_parameters/#job-definition-parameter-reference","title":"Job Definition Parameter Reference","text":"<p>This guide provides a comprehensive reference for all parameters available when creating job definitions in the Rapidata Python SDK.</p>","boost":10},{"location":"job_definition_parameters/#overview","title":"Overview","text":"<p>When creating a job definition, you'll use parameters to control:</p> <ul> <li>What data is shown to labelers (datapoints, contexts)</li> <li>How many responses you need (responses_per_datapoint)</li> <li>How tasks are displayed (settings)</li> <li>Quality assurance (confidence_threshold)</li> </ul>","boost":10},{"location":"job_definition_parameters/#core-parameters","title":"Core Parameters","text":"<p>These parameters are required or commonly used across all job types.</p>","boost":10},{"location":"job_definition_parameters/#name","title":"<code>name</code>","text":"Property Value Type <code>str</code> Required Yes <p>A descriptive name for your job definition. Used to identify the job in the Rapidata Dashboard and when retrieving jobs programmatically. This name is not shown to labelers.</p> <pre><code>name=\"Image Quality Rating v2 - January Batch\"\n</code></pre>","boost":10},{"location":"job_definition_parameters/#instruction","title":"<code>instruction</code>","text":"Property Value Type <code>str</code> Required Yes <p>The task instruction shown to labelers. This should clearly explain what action they need to take.</p> <p>Best Practices:</p> <ul> <li>Be specific and unambiguous</li> <li>Use action verbs (\"Select\", \"Choose\", \"Identify\")</li> <li>For comparisons, use comparative language (\"Which looks better?\")</li> <li>See Human Prompting for detailed guidance</li> </ul> <pre><code>instruction=\"Which image follows the prompt more accurately?\"\n</code></pre>","boost":10},{"location":"job_definition_parameters/#datapoints","title":"<code>datapoints</code>","text":"Property Value Type <code>list[str]</code> or <code>list[list[str]]</code> Required Yes <p>The data to be labeled. The format depends on the job type:</p> Job Type Format Description Classification <code>list[str]</code> Single items to classify Compare <code>list[list[str]]</code> Pairs of items (exactly 2 per inner list) <p>Supported Formats:</p> <ul> <li>Public URLs (https://...)</li> <li>Local file paths (will be uploaded automatically)</li> </ul> <pre><code># Classification - list of single items\ndatapoints=[\"https://example.com/img1.jpg\", \"https://example.com/img2.jpg\"]\n\n# Compare - list of pairs\ndatapoints=[\n    [\"https://example.com/a1.jpg\", \"https://example.com/b1.jpg\"],\n    [\"https://example.com/a2.jpg\", \"https://example.com/b2.jpg\"],\n]\n</code></pre>","boost":10},{"location":"job_definition_parameters/#responses_per_datapoint","title":"<code>responses_per_datapoint</code>","text":"Property Value Type <code>int</code> Required No Default <code>10</code> <p>The minimum number of responses to collect for each datapoint. The actual number may slightly exceed this due to concurrent labelers.</p> <p>Best Practices:</p> <ul> <li>Use 15-25 for ambiguous or subjective tasks</li> <li>Use 5-10 for clear-cut decisions</li> </ul> <pre><code>responses_per_datapoint=15\n</code></pre>","boost":10},{"location":"job_definition_parameters/#data-type","title":"Data Type","text":"","boost":10},{"location":"job_definition_parameters/#data_type","title":"<code>data_type</code>","text":"Property Value Type <code>Literal[\"media\", \"text\"]</code> Required No Default <code>\"media\"</code> <p>Specifies how datapoints should be interpreted and displayed.</p> Value Description <code>\"media\"</code> Datapoints are URLs or paths to images, videos, or audio files <code>\"text\"</code> Datapoints are raw text strings to be displayed directly <pre><code># Comparing two text responses\njob_definition = client.job.create_compare_job_definition(\n    name=\"LLM Response Comparison\",\n    instruction=\"Which response is more helpful?\",\n    datapoints=[\n        [\"Response A text here...\", \"Response B text here...\"],\n    ],\n    data_type=\"text\",\n)\n</code></pre>","boost":10},{"location":"job_definition_parameters/#context-parameters","title":"Context Parameters","text":"<p>Context parameters allow you to provide additional information alongside each datapoint.</p>","boost":10},{"location":"job_definition_parameters/#contexts","title":"<code>contexts</code>","text":"Property Value Type <code>Optional[list[str]]</code> Required No Default <code>None</code> <p>Text context shown alongside each datapoint. Commonly used to provide prompts, descriptions, or additional instructions specific to each item.</p> <p>Constraints: If provided, must have the same length as <code>datapoints</code>.</p> <pre><code>datapoints=[\"image1.jpg\", \"image2.jpg\"],\ncontexts=[\"A cat sitting on a red couch\", \"A blue car in the rain\"]\n</code></pre>","boost":10},{"location":"job_definition_parameters/#media_contexts","title":"<code>media_contexts</code>","text":"Property Value Type <code>Optional[list[str]]</code> Required No Default <code>None</code> <p>Media URLs shown as reference context alongside each datapoint. Useful when you need to show a reference image or video alongside the item being evaluated.</p> <p>Constraints: If provided, must have the same length as <code>datapoints</code>.</p> <pre><code># Show original image as context while evaluating edited versions\ndatapoints=[\"edited1.jpg\", \"edited2.jpg\"],\nmedia_contexts=[\"original1.jpg\", \"original2.jpg\"]\n</code></pre>","boost":10},{"location":"job_definition_parameters/#quality-control-parameters","title":"Quality Control Parameters","text":"","boost":10},{"location":"job_definition_parameters/#confidence_threshold","title":"<code>confidence_threshold</code>","text":"Property Value Type <code>Optional[float]</code> Required No Default <code>None</code> Range <code>0.0</code> to <code>1.0</code> (typically <code>0.99</code> to <code>0.999</code>) <p>Enables early stopping when a specified confidence level is reached. The system stops collecting responses once consensus is achieved, reducing costs while maintaining quality.</p> <p>How It Works: Uses labeler trust scores (<code>userScore</code>) to calculate statistical confidence for each category.</p> <p>Related: Confidence Stopping</p> <pre><code>job_definition = client.job.create_classification_job_definition(\n    name=\"Cat or Dog with Early Stopping\",\n    instruction=\"What animal is in this image?\",\n    answer_options=[\"Cat\", \"Dog\"],\n    datapoints=[\"pet1.jpg\", \"pet2.jpg\"],\n    responses_per_datapoint=50,  # Maximum responses\n    confidence_threshold=0.99,   # Stop at 99% confidence\n)\n</code></pre>","boost":10},{"location":"job_definition_parameters/#settings","title":"Settings","text":"<p>Settings allow you to customize how tasks are displayed.</p> Property Value Type <code>Sequence[RapidataSetting]</code> Required No Default <code>[]</code>","boost":10},{"location":"job_definition_parameters/#commonly-used-settings","title":"Commonly Used Settings","text":"","boost":10},{"location":"job_definition_parameters/#noshuffle","title":"<code>NoShuffle()</code>","text":"<p>Keeps answer options in the order you specified. By default, options are randomized to reduce bias. Use this for Likert scales or any ordered options.</p> <pre><code>from rapidata import NoShuffle\n\njob_definition = client.job.create_classification_job_definition(\n    instruction=\"Rate the quality of this image\",\n    answer_options=[\"1: Poor\", \"2: Fair\", \"3: Good\", \"4: Excellent\"],\n    datapoints=[\"image.jpg\"],\n    settings=[NoShuffle()]\n)\n</code></pre>","boost":10},{"location":"job_definition_parameters/#markdown","title":"<code>Markdown()</code>","text":"<p>Enables limited markdown rendering for text datapoints. Useful when comparing formatted text like LLM outputs.</p> <pre><code>from rapidata import Markdown\n\njob_definition = client.job.create_compare_job_definition(\n    name=\"LLM Response Comparison\",\n    instruction=\"Which response is better formatted?\",\n    datapoints=[[\"**Bold** and _italic_\", \"Plain text only\"]],\n    data_type=\"text\",\n    settings=[Markdown()]\n)\n</code></pre>","boost":10},{"location":"job_definition_parameters/#allowneitherboth","title":"<code>AllowNeitherBoth()</code>","text":"<p>For Compare jobs, allows labelers to select \"Neither\" or \"Both\" instead of forcing a choice.</p> <pre><code>from rapidata import AllowNeitherBoth\n\njob_definition = client.job.create_compare_job_definition(\n    name=\"Image Quality Comparison\",\n    instruction=\"Which image is higher quality?\",\n    datapoints=[[\"img_a.jpg\", \"img_b.jpg\"]],\n    settings=[AllowNeitherBoth()]\n)\n</code></pre>","boost":10},{"location":"job_definition_parameters/#job-specific-parameters","title":"Job-Specific Parameters","text":"","boost":10},{"location":"job_definition_parameters/#classification-job","title":"Classification Job","text":"Parameter Type Description <code>answer_options</code> <code>list[str]</code> List of categories to classify into <pre><code>job_definition = client.job.create_classification_job_definition(\n    name=\"Animal Classification\",\n    instruction=\"What animal is in the image?\",\n    answer_options=[\"Cat\", \"Dog\", \"Bird\", \"Other\"],\n    datapoints=[\"image1.jpg\", \"image2.jpg\"],\n)\n</code></pre>","boost":10},{"location":"job_definition_parameters/#compare-job","title":"Compare Job","text":"Parameter Type Description <code>a_b_names</code> <code>Optional[list[str]]</code> Custom labels for the two options (list of exactly 2 strings) <pre><code>job_definition = client.job.create_compare_job_definition(\n    name=\"Model Comparison\",\n    instruction=\"Which image is better?\",\n    datapoints=[[\"model_a.jpg\", \"model_b.jpg\"]],\n    a_b_names=[\"Flux\", \"Midjourney\"],  # Results will show these names\n)\n</code></pre>","boost":10},{"location":"job_definition_parameters/#parameter-availability-matrix","title":"Parameter Availability Matrix","text":"Parameter Classification Compare <code>name</code> <code>instruction</code> <code>datapoints</code> <code>responses_per_datapoint</code> <code>data_type</code> <code>contexts</code> <code>media_contexts</code> <code>confidence_threshold</code> <code>settings</code> <code>answer_options</code> <code>a_b_names</code> \ud83d\udccb","boost":10},{"location":"migration_guide/","title":"\ud83d\udd04 Migration Guide","text":"","boost":10},{"location":"migration_guide/#migration-guide-orders-to-audiences","title":"Migration Guide: Orders to Audiences","text":"<p>This guide helps you migrate from the legacy Order API to the recommended Audience &amp; Job API.</p> <p>Note: The Order and Validation APIs (<code>client.order</code>, <code>client.validation</code>) remain available for backwards compatibility in the near term.</p> <p>We observe higher quality responses when first curating an audience that is vetted on your specific task. While it was possible to do this with the previous Order API, the new Audience &amp; Job API puts the recommended workflow front and center. The new paradigm revolves around two steps:</p> <ol> <li> <p>Curate an Audience: Out of the millions of people available through Rapidata, select an audience that performs especially well on your task. This audience is curated by giving people validation examples and only accepting high performers.</p> </li> <li> <p>Define the Job: Define the annotation task in a Job Definition, which can then be assigned to an audience for processing.</p> </li> </ol>","boost":10},{"location":"migration_guide/#side-by-side-comparison","title":"Side-by-Side Comparison","text":"","boost":10},{"location":"migration_guide/#legacy-orders","title":"Legacy: Orders","text":"<pre><code>from rapidata import RapidataClient\n\nclient = RapidataClient()\n\n# Step 1: Create validation set with quality control examples\nvalidation_set = client.validation.create_compare_set(\n    name=\"Image Comparison Validation\",\n    instruction=\"Which image follows the prompt better?\",\n    datapoints=[[\"good_example.jpg\", \"bad_example.jpg\"]],\n    truths=[\"good_example.jpg\"],\n    contexts=[\"A sign that says 'Diffusion'.\"]\n)\n\n# Step 2: Create order with validation set reference\norder = client.order.create_compare_order(\n    name=\"Prompt Alignment Comparison\",\n    instruction=\"Which image follows the prompt better?\",\n    datapoints=[\n        [\"flux_image.jpg\", \"midjourney_image.jpg\"],\n        [\"flux_image2.jpg\", \"midjourney_image2.jpg\"]\n    ],\n    contexts=[\"A cat on a chair\", \"A sunset over mountains\"],\n    validation_set_id=validation_set.id,\n    responses_per_datapoint=10\n)\n\n# Step 3: Run and get results\norder.run()\nresults = order.get_results()\n</code></pre>","boost":10},{"location":"migration_guide/#new-audiences-jobs","title":"New: Audiences &amp; Jobs","text":"<pre><code>from rapidata import RapidataClient\n\nclient = RapidataClient()\n\n# Step 1: Create audience with qualification examples built-in\naudience = client.audience.create_audience(name=\"Prompt Alignment Judges\")\naudience.add_compare_example(\n    instruction=\"Which image follows the prompt better?\",\n    datapoint=[\"good_example.jpg\", \"bad_example.jpg\"],\n    truth=\"good_example.jpg\",\n    context=\"A sign that says 'Diffusion'.\"\n)\n\n# Step 2: Create job definition\njob_definition = client.job.create_compare_job_definition(\n    name=\"Prompt Alignment Comparison\",\n    instruction=\"Which image follows the prompt better?\",\n    datapoints=[\n        [\"flux_image.jpg\", \"midjourney_image.jpg\"],\n        [\"flux_image2.jpg\", \"midjourney_image2.jpg\"]\n    ],\n    contexts=[\"A cat on a chair\", \"A sunset over mountains\"],\n    responses_per_datapoint=10\n)\n\n# Step 3: Assign and get results\njob = audience.assign_job(job_definition)\nresults = job.get_results()\n</code></pre>","boost":10},{"location":"migration_guide/#what-changed","title":"What Changed","text":"Legacy Recommended Notes <code>client.order.create_*_order()</code> <code>client.job.create_*_job_definition()</code> Same parameters <code>client.validation.create_*_set()</code> <code>audience.add_*_example()</code> Simpler API <code>validation_set_id</code> parameter Not needed Built into audience <code>filters</code> parameter <code>filters</code> on audience creation Applied at audience level <code>order.run()</code> <code>audience.assign_job(job_def)</code> Automatic","boost":10},{"location":"migration_guide/#key-benefits","title":"Key Benefits","text":"<ul> <li>Simpler: No separate validation set management</li> <li>Reusable: One audience can run multiple jobs or a job on multiple audiences</li> <li>Previewable &amp; Editable: <code>job_definition.preview()</code> before assigning</li> <li>Result Alignment: The labelers in an audience are filtered according to your examples, improving the quality of the results</li> </ul>","boost":10},{"location":"migration_guide/#quick-reference","title":"Quick Reference","text":"<p>Classification:</p> <ul> <li><code>create_classification_order()</code> \u2192 <code>create_classification_job_definition()</code></li> <li><code>create_classification_set()</code> \u2192 <code>audience.add_classification_example()</code></li> </ul> <p>Compare:</p> <ul> <li><code>create_compare_order()</code> \u2192 <code>create_compare_job_definition()</code></li> <li><code>create_compare_set()</code> \u2192 <code>audience.add_compare_example()</code></li> </ul> <p>Results work the same way: <code>results.to_pandas()</code>, <code>results.to_json()</code></p> \ud83d\udccb","boost":10},{"location":"mri/","title":"\ud83e\udde0 Model Ranking Insights","text":"","boost":10},{"location":"mri/#model-ranking-insights","title":"Model Ranking Insights","text":"","boost":10},{"location":"mri/#overview","title":"Overview","text":"<p>Model Ranking Insights (MRI) provides a powerful way to compare and rank different AI models based on their performance on specific tasks. They allow you to create standardized evaluation environments where multiple models can be tested against each other and ranked based on human feedback.</p> <p></p> <p>Note: Can be used with Images, Videos, and Audio.</p> <p>Each evaluation aspect results in a leaderboard and these leaderboards are grouped under a benchmark. This allows convenient extensibility because when you would like to evaluate the models under a new criteria, it is as easy as adding a new leaderboard to your benchmark.</p>","boost":10},{"location":"mri/#how-to-use-mri","title":"How to use MRI","text":"","boost":10},{"location":"mri/#1-benchmark-creation","title":"1. Benchmark Creation","text":"<p>You start by creating a benchmark with specific settings:</p> <ul> <li>Name: Identifies your benchmark in the overview</li> <li>Prompts: A list of prompts that will be used to generate the media to evaluate the models.</li> </ul> <p>Use the <code>RapidataClient</code> to authenticate yourself and create a new leaderboard:</p> <pre><code>from rapidata import RapidataClient\n\n# Initialize the client\n# Running this the first time will open a browser window and ask you to login\nclient = RapidataClient() \n\n# Create a new benchmark\nbenchmark = client.mri.create_new_benchmark(\n    name=\"AI Art Competition\",\n    prompts=[\n        \"A serene mountain landscape at sunset\",\n        \"A futuristic city with flying cars\",\n        \"A portrait of a wise old wizard\"\n    ]\n)\n</code></pre>","boost":10},{"location":"mri/#2-leaderboard-creation","title":"2. Leaderboard Creation","text":"<p>Once your benchmark is set up, you can create leaderboards for it.</p> <ul> <li>Name: Identifies your leaderboard in the overview</li> <li>Instruction: The criteria upon which labelers choose the better model</li> <li>Show Prompt: Whether to display the prompt to evaluators. Including this option adds complexity and cost, so it is advised to only include it in settings where the prompt is necessary for the labelers to follow the instruction (e.g., prompt alignment).</li> </ul> <p>Note: You can find all leaderboards for a benchmark by using the <code>leaderboards</code> attribute of the benchmark.</p> <pre><code># Create a new leaderboard on a benchmark\nleaderboard = benchmark.create_leaderboard(\n    name=\"Realism\", \n    instruction=\"Which image is more realistic?\", \n    show_prompt=False\n)\n</code></pre>","boost":10},{"location":"mri/#3-model-evaluation","title":"3. Model Evaluation","text":"<p>Once your benchmark and leaderboard are set up, you can evaluate models by the following:</p> <ul> <li>Media: Images, videos, or audio files generated by your model</li> <li>Prompts: Each media file must be paired with a prompt</li> </ul> <p>All prompts must be from the benchmark's registered prompt set (available through the <code>prompts</code> attribute of the benchmark)</p> <p>Note: You are not limited to one media per prompt; you can supply the same prompt multiple times.</p> <pre><code># Evaluate a model\nbenchmark.evaluate_model(\n    name=\"MyAIModel_v2.1\",\n    media=[\n        \"https://assets.rapidata.ai/mountain_sunset1.png\",\n        \"https://assets.rapidata.ai/mountain_sunset2.png\",\n        \"https://assets.rapidata.ai/futuristic_city.png\", \n        \"https://assets.rapidata.ai/wizard_portrait.png\"\n    ],\n    prompts=[\n        \"A serene mountain landscape at sunset\",\n        \"A serene mountain landscape at sunset\",\n        \"A futuristic city with flying cars\",\n        \"A portrait of a wise old wizard\"\n    ]\n)\n</code></pre>","boost":10},{"location":"mri/#3b-adding-models-without-immediate-submission","title":"3b. Adding Models Without Immediate Submission","text":"<p>If you want to add a model and control when it is submitted for evaluation, use <code>add_model</code> instead of <code>evaluate_model</code>. This lets you upload media, inspect the participant, and submit on your own schedule.</p> <pre><code># Add a model without submitting\nparticipant = benchmark.add_model(\n    name=\"MyAIModel_v2.1\",\n    media=[\n        \"https://assets.rapidata.ai/mountain_sunset1.png\",\n        \"https://assets.rapidata.ai/futuristic_city.png\",\n        \"https://assets.rapidata.ai/wizard_portrait.png\"\n    ],\n    prompts=[\n        \"A serene mountain landscape at sunset\",\n        \"A futuristic city with flying cars\",\n        \"A portrait of a wise old wizard\"\n    ]\n)\n\n# Upload additional media to the same participant\nparticipant.upload_media(\n    assets=[\"https://assets.rapidata.ai/mountain_sunset2.png\"],\n    identifiers=[\"A serene mountain landscape at sunset\"]\n)\n\n# Submit the individual participant\nparticipant.run()\n\n# Or submit all unsubmitted participants at once\nbenchmark.run()\n</code></pre> <p>You can also inspect existing participants:</p> <pre><code># List all participants\nfor p in benchmark.participants:\n    print(p.name, p.status)\n</code></pre>","boost":10},{"location":"mri/#4-matchmaking-and-ranking","title":"4. Matchmaking and Ranking","text":"<p>MRI creates fair comparisons by:</p> <ul> <li>Prompt-based matching: Only media with the same prompt are compared against each other</li> <li>Mixed evaluation: New models are matched up with existing models to maximize the information gained</li> <li>User-driven assessment: Human evaluators compare model outputs based on the instruction to determine rankings</li> </ul>","boost":10},{"location":"mri/#5-results-and-visibility","title":"5. Results and Visibility","text":"<p>Your leaderboard results are:</p> <ul> <li>Directly viewable on the Rapidata dashboard at app.rapidata.ai/mri/benchmarks</li> <li>Continuously updated as new models are added and evaluated</li> <li>Provides deeper insights into model performances over time</li> </ul>","boost":10},{"location":"mri/#retrieving-existing-benchmarks","title":"Retrieving Existing Benchmarks","text":"<p>You can retrieve benchmarks by ID or search for them:</p> <pre><code># Get a specific benchmark by ID\nbenchmark = client.mri.get_benchmark_by_id(\"benchmark_id_here\")\n\n# Find benchmarks by name\nrecent_benchmarks = client.mri.find_benchmarks(\n    name=\"AI Art\",\n    amount=10\n)\n</code></pre>","boost":10},{"location":"mri/#retrieving-results","title":"Retrieving Results","text":"<pre><code># Get the leaderboard\nleaderboard = benchmark.leaderboards[0]\n\n# Get the standings\nstandings = leaderboard.get_standings() # Returns a pandas dataframe\n</code></pre> \ud83d\udccb","boost":10},{"location":"mri_advanced/","title":"\ud83d\udd2d Model Ranking Insights Advanced","text":"","boost":10},{"location":"mri_advanced/#model-ranking-insights-advanced","title":"Model Ranking Insights Advanced","text":"","boost":10},{"location":"mri_advanced/#overview","title":"Overview","text":"<p>To unlock the full potential of Model Ranking Insights (MRI), you can use the advanced features. These include sophisticated configuration options for benchmarks, leaderboards, and evaluation settings that give you fine-grained control over your model evaluation process.</p>","boost":10},{"location":"mri_advanced/#benchmark-configuration","title":"Benchmark Configuration","text":"","boost":10},{"location":"mri_advanced/#using-identifiers","title":"Using Identifiers","text":"<p>In the MRI quickstart we used the prompts to identify the media and create the appropriate matchups. However, more generally you might not have an exact 1-to-1 relationship between prompts and media (e.g., you may have different settings or inputs for the same prompt - for example input images for image-to-video models. More about this below). To handle this case, we allow you to supply your own identifiers, which will then be used when creating the matchups.</p> <pre><code># Example 1: Explicit identifiers\nbenchmark = client.mri.create_new_benchmark(\n    name=\"Preference Benchmark\",\n    identifiers=[\"scene_1\", \"scene_2\", \"scene_3\"],\n    prompts=[\n        \"A serene mountain landscape at sunset\",\n        \"A futuristic city with flying cars\",\n        \"A portrait of a wise old wizard\"\n    ],\n    prompt_assets=[\n        \"https://assets.rapidata.ai/mountain_sunset.png\",\n        \"https://assets.rapidata.ai/futuristic_city.png\", \n        \"https://assets.rapidata.ai/wizard_portrait.png\"\n    ]\n)\n\n# Example 2: Identifiers used for the same prompts but different seeding\nbenchmark = client.mri.create_new_benchmark(\n    name=\"Preference Benchmark\",\n    identifiers=[\"seed_1\", \"seed_2\", \"seed_3\"],\n    prompts=[\"prompt_1\", \"prompt_1\", \"prompt_1\"],\n    prompt_assets=[\"https://example.com/asset1.jpg\", \"https://example.com/asset1.jpg\", \"https://example.com/asset1.jpg\"]\n)\n\n# Example 3: Using only prompt assets\nbenchmark = client.mri.create_new_benchmark(\n    name=\"Preference Benchmark\",\n    identifiers=[\"image_1\", \"image_2\", \"image_3\"],   \n    prompt_assets=[\"https://example.com/asset1.jpg\", \"https://example.com/asset2.jpg\", \"https://example.com/asset3.jpg\"]\n)\n</code></pre> <p>Note: Media assets are images, videos, or audio files that provide visual or auditory context for your evaluation prompts. For example when evaluating image to video models.</p>","boost":10},{"location":"mri_advanced/#tagging-system","title":"Tagging System","text":"<p>Tags provide metadata for filtering and organizing benchmark results without showing them to evaluators. These tags can also be set and used in the frontend. To view the frontend, you can use the <code>view</code> method of the benchmark or leaderboard.</p> <pre><code># Tags for filtering leaderboard results\ntags = [\n    [\"landscape\", \"outdoor\", \"beach\"],\n    [\"landscape\", \"outdoor\", \"mountain\"],\n    [\"outdoor\", \"city\"],\n    [\"indoor\", \"vehicle\"]\n]\n\nbenchmark = client.mri.create_new_benchmark(\n    name=\"Tagged Benchmark\",\n    identifiers=[\"scene_1\", \"scene_2\", \"scene_3\", \"scene_4\"],\n    prompts=[\"A sunny beach\", \"A mountain landscape\", \"A city skyline\", \"A car in a garage\"],\n    tags=tags\n)\n\n# Filter leaderboard results by tags\nstandings = leaderboard.get_standings(tags=[\"landscape\", \"outdoor\"])\n</code></pre>","boost":10},{"location":"mri_advanced/#adding-prompts-and-assets-after-benchmark-creation","title":"Adding prompts and assets after benchmark creation","text":"<p>If you have already created a benchmark and want to add new prompts and assets after the fact. Note however that these will only take effect for new models.</p> <pre><code># Adding individual prompts with assets\nbenchmark.add_prompt(\n    identifier=\"new_style\",\n    prompt=\"Generate artwork in this new style\",\n    prompt_asset=\"https://assets.rapidata.ai/new_style_ref.jpg\",\n    tags=[\"abstract\", \"modern\"]\n)\n</code></pre>","boost":10},{"location":"mri_advanced/#leaderboard-configuration","title":"Leaderboard Configuration","text":"","boost":10},{"location":"mri_advanced/#inverse-ranking","title":"Inverse Ranking","text":"<p>For evaluation questions where lower scores are better (e.g., \"Which image is worse?\"), use inverse ranking.</p> <pre><code>leaderboard = benchmark.create_leaderboard(\n    name=\"Quality Assessment\",\n    instruction=\"Which image has lower quality?\",\n    inverse_ranking=True,  # Lower scores = better performance\n    show_prompt=True,\n    show_prompt_asset=True\n)\n</code></pre>","boost":10},{"location":"mri_advanced/#level-of-detail","title":"Level of Detail","text":"<p>Controls the number of comparisons performed, affecting accuracy vs. speed.</p> <pre><code># Different detail levels\nleaderboard_fast = benchmark.create_leaderboard(\n    name=\"Quick Evaluation\", \n    instruction=\"Which image do you prefer?\",\n    level_of_detail=\"low\"      # Fewer comparisons, faster results\n)\n\nleaderboard_precise = benchmark.create_leaderboard(\n    name=\"Precise Evaluation\",\n    instruction=\"Which image do you prefer?\", \n    level_of_detail=\"very high\"  # More comparisons, higher accuracy\n)\n</code></pre>","boost":10},{"location":"mri_advanced/#prompt-and-asset-display","title":"Prompt and Asset Display","text":"<p>Control what evaluators see during comparison.</p> <pre><code>leaderboard = benchmark.create_leaderboard(\n    name=\"Context-Aware Evaluation\",\n    instruction=\"Which generated image better matches the prompt?\",\n    show_prompt=True,           # Show the original text prompt\n    show_prompt_asset=True,     # Show reference images/videos\n    level_of_detail=\"medium\"\n)\n</code></pre>","boost":10},{"location":"mri_advanced/#participant-management","title":"Participant Management","text":"","boost":10},{"location":"mri_advanced/#listing-participants","title":"Listing Participants","text":"<p>You can list all participants in a benchmark using the <code>participants</code> property:</p> <pre><code>for participant in benchmark.participants:\n    print(f\"{participant.name} - {participant.status}\")\n</code></pre>","boost":10},{"location":"mri_advanced/#submitting-participants","title":"Submitting Participants","text":"<p>When using <code>add_model</code>, participants are created in the <code>CREATED</code> state and are not yet submitted for evaluation. You can submit them individually or in bulk:</p> <pre><code># Submit a single participant\nparticipant = benchmark.add_model(\n    name=\"ModelA\",\n    media=[\"https://example.com/img1.png\"],\n    identifiers=[\"scene_1\"]\n)\nparticipant.run()\n\n# Or add multiple models and submit them all at once\nbenchmark.add_model(name=\"ModelB\", media=[\"https://example.com/img2.png\"], identifiers=[\"scene_1\"])\nbenchmark.add_model(name=\"ModelC\", media=[\"https://example.com/img3.png\"], identifiers=[\"scene_1\"])\nbenchmark.run()  # Submits all participants in CREATED state\n</code></pre>","boost":10},{"location":"mri_advanced/#references","title":"References","text":"<ul> <li>RapidataBenchmarkManager</li> <li>RapidataBenchmark</li> <li>RapidataLeaderboard</li> <li>BenchmarkParticipant</li> </ul> \ud83d\udccb","boost":10},{"location":"quickstart/","title":"\ud83d\ude80 Quick Start","text":"","boost":10},{"location":"quickstart/#quickstart-guide","title":"Quickstart Guide","text":"<p>Get real humans to label your data. This guide shows you how to create a labeling job using the Rapidata API.</p> <p>The workflow consists of three main concepts:</p> <ol> <li>Audience: A group of labelers who will work on your tasks</li> <li>Job Definition: The configuration for your labeling task (instruction, datapoints, settings)</li> <li>Job: A running labeling task assigned to an audience</li> </ol>","boost":10},{"location":"quickstart/#installation","title":"Installation","text":"<p>Install Rapidata using pip:</p> <pre><code>pip install -U rapidata\n</code></pre>","boost":10},{"location":"quickstart/#usage","title":"Usage","text":"<p>All operations are managed through the <code>RapidataClient</code>.</p> <p>Create a client as follows. This will save your credentials in your <code>~/.config/rapidata/credentials.json</code> file so you don't have to log in again on that machine:</p> <pre><code>from rapidata import RapidataClient\n\n# The first time executing it on a machine will require you to log in\nclient = RapidataClient()\n</code></pre> <p>Alternatively you can generate a Client ID and Secret in the Rapidata Settings and pass them to the client constructor:</p> <pre><code>from rapidata import RapidataClient\nclient = RapidataClient(client_id=\"Your client ID\", client_secret=\"Your client secret\")\n</code></pre>","boost":10},{"location":"quickstart/#step-1-get-an-audience","title":"Step 1: Get an Audience","text":"<p>The simplest way to get started is with a curated audience - a pre-existing pool of labelers trained on a specific type of task:</p> <pre><code>audience = client.audience.find_audiences(\"alignment\")[0]\n</code></pre> <p>Note: The curated audience gets you started quickly, but results may be less accurate than a custom audience trained with examples specific to your task. For higher quality, see Custom Audiences.</p>","boost":10},{"location":"quickstart/#step-2-create-a-job-definition","title":"Step 2: Create a Job Definition","text":"<p>A job definition configures what you want labeled. Here we create a compare job to assess image-prompt alignment:</p> <pre><code>job_definition = client.job.create_compare_job_definition(\n    name=\"Example Image Prompt Alignment\",\n    instruction=\"Which image matches the description better?\",\n    datapoints=[\n        [\"https://assets.rapidata.ai/midjourney-5.2_37_3.jpg\",\n         \"https://assets.rapidata.ai/flux-1-pro_37_0.jpg\"]\n    ],\n    contexts=[\"A small blue book sitting on a large red book.\"]\n)\n</code></pre> <p>Tip: If some datapoints fail to upload, a <code>FailedUploadException</code> will be raised. Learn how to handle this in the Error Handling Guide.</p> <p>For a detailed explanation of all available parameters (including name, instruction, datapoints, contexts, quality control options, and more), see the Job Definition Parameters Reference.</p>","boost":10},{"location":"quickstart/#step-3-preview-the-job-definition","title":"Step 3: Preview the Job Definition","text":"<p>Before running your job, preview it to see exactly what labelers will see:</p> <pre><code>job_definition.preview()\n</code></pre> <p>This opens your browser where you can review and adjust the job configuration.</p>","boost":10},{"location":"quickstart/#step-4-run-and-get-results","title":"Step 4: Run and Get Results","text":"<p>Assign your job definition to the audience and monitor progress:</p> <pre><code>job = audience.assign_job(job_definition)\njob.display_progress_bar()\n</code></pre> <p>Once complete, retrieve your results:</p> <pre><code>results = job.get_results()\n</code></pre> <p>You can also monitor progress on the Rapidata Dashboard.</p> <p>To understand the results format, see the Understanding the Results guide.</p>","boost":10},{"location":"quickstart/#retrieve-existing-resources","title":"Retrieve Existing Resources","text":"","boost":10},{"location":"quickstart/#find-audiences","title":"Find Audiences","text":"<pre><code># Find audiences by name\naudiences = client.audience.find_audiences(\"alignment\")\n\n# Get a specific audience by ID\naudience = client.audience.get_audience_by_id(\"audience_id\")\n</code></pre>","boost":10},{"location":"quickstart/#find-job-definitions","title":"Find Job Definitions","text":"<pre><code># Find job definitions by name\njob_definitions = client.job.find_job_definitions(\"Example Image Prompt Alignment\")\n\n# Get a specific job definition by ID\njob_definition = client.job.get_job_defintion_by_id(\"job_definition_id\")\n</code></pre>","boost":10},{"location":"quickstart/#find-jobs","title":"Find Jobs","text":"<pre><code># Find jobs by name\njobs = client.job.find_jobs(\"Example Image Prompt Alignment\")\n\n# Get a specific job by ID\njob = client.job.get_job_by_id(\"job_id\")\n\n# Find jobs for a specific audience\naudience = client.audience.get_audience_by_id(\"audience_id\")\njobs = audience.find_jobs(\"Prompt Alignment\")\n</code></pre> <p>Note: The <code>find_*</code> can be executed without the <code>name</code> parameter to return the most recent resources.</p>","boost":10},{"location":"quickstart/#complete-example","title":"Complete Example","text":"<p>Here's the full workflow using the curated alignment audience:</p> <pre><code>from rapidata import RapidataClient\n\nclient = RapidataClient()\n\n# Get the curated alignment audience\naudience = client.audience.find_audiences(\"alignment\")[0]\n\n# Create job definition\njob_definition = client.job.create_compare_job_definition(\n    name=\"Example Image Prompt Alignment\",\n    instruction=\"Which image matches the description better?\",\n    datapoints=[\n        [\"https://assets.rapidata.ai/midjourney-5.2_37_3.jpg\",\n         \"https://assets.rapidata.ai/flux-1-pro_37_0.jpg\"]\n    ],\n    contexts=[\"A small blue book sitting on a large red book.\"]\n)\n\n# Preview before running\njob_definition.preview()\n\n# Assign to audience and get results\njob = audience.assign_job(job_definition)\njob.display_progress_bar()\nresults = job.get_results()\nprint(results)\n</code></pre>","boost":10},{"location":"quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Create Custom Audiences for higher quality results</li> <li>Learn about Classification Jobs for categorizing data</li> <li>Understand the Results Format</li> <li>Configure Early Stopping based on confidence thresholds</li> <li>Migrating from Orders? See the Migration Guide</li> </ul> \ud83d\udccb","boost":10},{"location":"starting_page/","title":"\ud83d\udc40 Overview","text":"Rapidata developer documentation <ul> <li> <p>Get real humans to label your data in minutes.</p> <pre><code>pip install -U rapidata\n</code></pre> ImageVideoAudioText <pre><code>from rapidata import RapidataClient\n\nclient = RapidataClient()\n\n# Get the curated alignment audience\naudience = client.audience.find_audiences(\"alignment\")[0]\n\n# Create job definition\njob_definition = client.job.create_compare_job_definition(\n    name=\"Example Image Comparison\",\n    instruction=\"Which image matches the description better?\",\n    contexts=[\"A small blue book sitting on a large red book.\"],\n    datapoints=[[\"https://assets.rapidata.ai/midjourney-5.2_37_3.jpg\",\n                \"https://assets.rapidata.ai/flux-1-pro_37_0.jpg\"]],\n)\n\n# Assign to audience\njob = audience.assign_job(job_definition)\n\n# View the job in the browser\njob.view()\njob.display_progress_bar()\nresults = job.get_results()\nprint(results)\n</code></pre> <pre><code>from rapidata import RapidataClient\n\nclient = RapidataClient()\n\n# Get the curated alignment audience\naudience = client.audience.find_audiences(\"alignment\")[0]\n\n# Create job definition\njob_definition = client.job.create_compare_job_definition(\n    name=\"Example Video Comparison\",\n    instruction=\"Which video fits the description better?\",\n    contexts=[\"A group of elephants painting vibrant murals on a city wall.\"],\n    datapoints=[[\"https://assets.rapidata.ai/0074_sora_1.mp4\",\n                \"https://assets.rapidata.ai/0074_hunyuan_1724.mp4\"]],\n)\n\n# Assign to audience\njob = audience.assign_job(job_definition)\n\n# View the job in the browser\njob.view()\njob.display_progress_bar()\nresults = job.get_results()\nprint(results)\n</code></pre> <pre><code>from rapidata import RapidataClient, LanguageFilter\n\nclient = RapidataClient()\n\n# Get the global audience\naudience = client.audience.get_audience_by_id(\"global\")\n\n# Create job definition\njob_definition = client.job.create_compare_job_definition(\n    name=\"Example Audio Comparison\",\n    instruction=\"Which audio clip sounds more natural?\",\n    datapoints=[[\"https://assets.rapidata.ai/Chat_gpt.mp3\",\n                \"https://assets.rapidata.ai/ElevenLabs.mp3\"]],\n)\n\n# Assign to audience\njob = audience.assign_job(job_definition)\n\n# View the job in the browser\njob.view()\njob.display_progress_bar()\nresults = job.get_results()\nprint(results)\n</code></pre> <pre><code>from rapidata import RapidataClient, LanguageFilter\n\nclient = RapidataClient()\n\n# Get the global audience\naudience = client.audience.get_audience_by_id(\"global\")\n\n# Create job definition\njob_definition = client.job.create_compare_job_definition(\n    name=\"Example Text Comparison\",\n    instruction=\"Which sentence is grammatically more correct?\",\n    datapoints=[[\"The children were amazed by the magician's tricks\",\n                \"The children were amusing by the magician's tricks.\"]],\n    data_type=\"text\",\n)\n\n# Assign to audience\njob = audience.assign_job(job_definition)\n\n# View the job in the browser\njob.view()\njob.display_progress_bar()\nresults = job.get_results()\nprint(results)\n</code></pre> <p>Note: The curated/global audiences get you started quickly. For higher quality results, use a custom audience with qualification examples.</p> <p> Quickstart Guide</p> </li> </ul> \ud83d\udccb","boost":10},{"location":"understanding_the_results/","title":"\ud83d\udcca Understanding Results","text":"","boost":10},{"location":"understanding_the_results/#interpreting-the-results","title":"Interpreting the Results","text":"<p>After running your job and collecting responses, you'll receive a structured result containing valuable insights from the labelers. Understanding each component of this result is crucial for analyzing and utilizing the data effectively.</p> <p>Here's an example of the results you might receive when running a COMPARE task (for simplicity, this example uses 3 responses):</p> <pre><code>{\n  \"info\": {\n    \"createdAt\": \"2025-02-11T07:31:59.353232+00:00\",\n    \"version\": \"3.0.0\"\n  },\n  \"summary\": {\n    \"A_wins_total\": 0,\n    \"B_wins_total\": 1\n  },\n  \"results\": [\n    {\n      \"context\": \"A small blue book sitting on a large red book.\",\n      \"winner_index\": 1,\n      \"winner\": \"dalle-3_37_2.jpg\",\n      \"aggregatedResults\": {\n        \"aurora-20-1-25_37_4.png\": 0,\n        \"dalle-3_37_2.jpg\": 3\n      },\n      \"aggregatedResultsRatios\": {\n        \"aurora-20-1-25_37_4.png\": 0.0,\n        \"dalle-3_37_2.jpg\": 1.0\n      },\n      \"summedUserScores\": {\n        \"aurora-20-1-25_37_4.png\": 0.0,\n        \"dalle-3_37_2.jpg\": 1.196\n      },\n      \"summedUserScoresRatios\": {\n        \"aurora-20-1-25_37_4.png\": 0.0,\n        \"dalle-3_37_2.jpg\": 1.0\n      },\n      \"detailedResults\": [\n          {\n              \"votedFor\": \"dalle-3_37_2.jpg\",\n              \"userDetails\": {\n                  \"country\": \"BY\",\n                  \"language\": \"ru\",\n                  \"userScores\": {\n                      \"global\": 0.4469\n                  },\n                  \"age\": \"Unknown\",\n                  \"gender\": \"Unknown\",\n                  \"occupation\": \"Unknown\"\n              }\n          },\n          {\n              \"votedFor\": \"dalle-3_37_2.jpg\",\n              \"userDetails\": {\n                  \"country\": \"LY\",\n                  \"language\": \"ar\",\n                  \"userScores\": {\n                      \"global\": 0.3923\n                  },\n                  \"age\": \"0-17\",\n                  \"gender\": \"Other\",\n                  \"occupation\": \"Other Employment\"\n              }\n          },\n          {\n              \"votedFor\": \"dalle-3_37_2.jpg\",\n              \"userDetails\": {\n                  \"country\": \"BY\",\n                  \"language\": \"ru\",\n                  \"userScores\": {\n                      \"global\": 0.3568\n                  },\n                  \"age\": \"0-17\",\n                  \"gender\": \"Other\",\n                  \"occupation\": \"Healthcare\"\n              }\n          }\n      ]\n    }\n  ]\n}\n</code></pre>","boost":10},{"location":"understanding_the_results/#breakdown-of-the-results","title":"Breakdown of the Results","text":"<ol> <li> <p><code>info</code></p> <ul> <li><code>createdAt</code>: The timestamp indicating when the results overview was generated, in UTC time.</li> <li><code>version</code>: The version of the aggregator system that produced the results.</li> </ul> </li> <li> <p><code>summary</code></p> <ul> <li><code>A_wins_total</code>: The total number of comparisons won by option A (index 0) across all pairs</li> <li><code>B_wins_total</code>: The total number of comparisons won by option B (index 1) across all pairs</li> </ul> </li> <li> <p><code>results</code>: This section contains the actual comparison data collected from the labelers. For comparison jobs, each item includes:</p> <ul> <li><code>context</code>: The prompt or description provided for the comparison task</li> <li><code>winner_index</code>: Index of the winning option (0 for first option, 1 for second option)</li> <li> <p><code>winner</code>: Filename or identifier of the winning option</p> </li> <li> <p><code>aggregatedResults</code>: The total number of responses each option received for this specific comparison.     </p><pre><code>\"aggregatedResults\": {\n    \"aurora-20-1-25_37_4.png\": 0,\n    \"dalle-3_37_2.jpg\": 3\n}\n</code></pre><p></p> </li> <li> <p><code>aggregatedResultsRatios</code>: The proportion of responses each option received, calculated as the number of responses for the option divided by the total number of responses.     </p><pre><code>\"aggregatedResultsRatios\": {\n    \"aurora-20-1-25_37_4.png\": 0.0,\n    \"dalle-3_37_2.jpg\": 1.0\n}\n</code></pre><p></p> </li> <li> <p><code>summedUserScores</code>: The sum of the labelers' global userScore values for each option. This metric accounts for the reliability of each labeler's response.     </p><pre><code>\"summedUserScores\": {\n    \"aurora-20-1-25_37_4.png\": 0.0,\n    \"dalle-3_37_2.jpg\": 1.196\n}\n</code></pre><p></p> </li> <li> <p><code>summedUserScoresRatios</code>: The proportion of the summed global userScores for each option, providing a weighted ratio based on labeler reliability.     </p><pre><code>\"summedUserScoresRatios\": {\n    \"aurora-20-1-25_37_4.png\": 0.0,\n    \"dalle-3_37_2.jpg\": 1.0\n}\n</code></pre><p></p> </li> <li> <p><code>detailedResults</code>: A list of individual responses from each labeler, including:</p> <ul> <li><code>votedFor</code>: The option chosen by the labeler</li> <li><code>userDetails</code>: Information about the labeler<ul> <li><code>country</code>: Country code of the labeler</li> <li><code>language</code>: Language in which the labeler viewed the task</li> <li><code>userScores</code>: A score representing the labeler's reliability across different dimensions<ul> <li><code>global</code>: The global userScore of the labeler, which is a measure of their overall reliability</li> </ul> </li> <li><code>age</code>: Age group of the labeler</li> <li><code>gender</code>: The gender of the labeler</li> <li><code>occupation</code>: The occupation of the labeler</li> </ul> </li> </ul> </li> </ul> </li> </ol>","boost":10},{"location":"understanding_the_results/#understanding-the-user-scores","title":"Understanding the User Scores","text":"<p>The <code>userScore</code> is a value between 0 and 1 (1 can never be reached, but can appear because of rounding) that indicates the reliability or trustworthiness of a labeler's responses. A higher score suggests that the labeler consistently provides accurate and reliable answers.</p>","boost":10},{"location":"understanding_the_results/#how-is-it-calculated","title":"How is it Calculated?","text":"<p>The <code>userScore</code> is derived from the labeler's performance on Qualification Tasks\u2014tasks with known correct answers. By evaluating how accurately a labeler completes these tasks, we assign a score that reflects their understanding and adherence to the task requirements. It is not simply the accuracy, as it also takes into account the difficulties of the tasks, but strongly related to it.</p> <p>For most tasks, the <code>global</code> userScore is the most relevant and can be used per default. If you need more specific information, you may contact us directly at info@rapidata.ai.</p> <p>Qualification tasks are examples with known correct answers that labelers must pass before working on your data.</p>","boost":10},{"location":"understanding_the_results/#why-is-it-important","title":"Why is it Important?","text":"<ul> <li>Weighted Analysis: Responses from labelers with higher <code>userScores</code> can be given more weight, improving the overall quality of the aggregated results.</li> <li>Quality Control: It helps in identifying and filtering for the most reliable responses.</li> <li>Insight into Labeler Performance: Provides transparency into who is contributing to your data and how reliably.</li> </ul>","boost":10},{"location":"understanding_the_results/#utilizing-the-results","title":"Utilizing the Results","text":"<ul> <li>Clear Winners: Use <code>winner</code> and <code>winner_index</code> to quickly identify which option was preferred. It is calculated based on the global userScores.</li> <li>Aggregated Insights: Use <code>aggregatedResults</code> and <code>aggregatedResultsRatios</code> to understand the strength of preference between options</li> <li>Weighted Decisions: Consider <code>summedUserScores</code> and <code>summedUserScoresRatios</code> to make decisions based on annotator reliability</li> <li>Detailed Analysis: Explore <code>detailedResults</code> to see individual responses and gather insights about labeler demographics and performance</li> </ul>","boost":10},{"location":"understanding_the_results/#conclusion","title":"Conclusion","text":"<p>By thoroughly understanding each component of the results, you can effectively interpret the data and make informed decisions. Leveraging the userScore and qualification examples ensures high-quality, reliable data for your projects.</p> \ud83d\udccb","boost":10},{"location":"examples/classify_job/","title":"\ud83c\udff7\ufe0f Classification","text":"","boost":10},{"location":"examples/classify_job/#classification-job-example","title":"Classification Job Example","text":"<p>To learn about the basics of creating a job, please refer to the quickstart guide.</p> <p>In this example, we want to rate different images based on a Likert scale to assess how well generated images match their descriptions. The <code>NoShuffle</code> setting ensures answer options remain in order since they represent a scale.</p> <pre><code>from rapidata import RapidataClient, NoShuffle\n\nIMAGE_URLS = [\n    \"https://assets.rapidata.ai/tshirt-4o.png\",\n    \"https://assets.rapidata.ai/tshirt-aurora.jpg\",\n    \"https://assets.rapidata.ai/teamleader-aurora.jpg\",\n]\n\nCONTEXTS = [\"A t-shirt with the text 'Running on caffeine &amp; dreams'\"] * len(IMAGE_URLS)\n\nclient = RapidataClient()\n\n# Create audience with qualification example\naudience = client.audience.create_audience(name=\"Likert Scale Audience\")\naudience.add_classification_example(\n    instruction=\"How well does the image match the description?\",\n    answer_options=[\"1: Not at all\", \"2: A little\", \"3: Moderately\", \"4: Very well\", \"5: Perfectly\"],\n    datapoint=\"https://assets.rapidata.ai/tshirt-4o.png\",\n    truth=[\"5: Perfectly\"],\n    context=\"A t-shirt with the text 'Running on caffeine &amp; dreams'\"\n)\n\n# Create job definition\njob_definition = client.job.create_classification_job_definition(\n    name=\"Likert Scale Example\",\n    instruction=\"How well does the image match the description?\",\n    answer_options=[\"1: Not at all\", \"2: A little\", \"3: Moderately\", \"4: Very well\", \"5: Perfectly\"],\n    contexts=CONTEXTS,\n    datapoints=IMAGE_URLS,\n    responses_per_datapoint=25,\n    settings=[NoShuffle()]\n)\n\n# Preview the job definition\njob_definition.preview()\n\n# Assign to audience and get results\njob = audience.assign_job(job_definition)\njob.display_progress_bar()\nresults = job.get_results()\nprint(results)\n</code></pre> \ud83d\udccb","boost":10},{"location":"examples/compare_job/","title":"\u2696\ufe0f Compare","text":"","boost":10},{"location":"examples/compare_job/#compare-job-example","title":"Compare Job Example","text":"<p>To learn about the basics of creating a job, please refer to the quickstart guide.</p> <p>In this example, we compare images from two image generation models (Flux and Midjourney) to determine which more accurately follows the given prompts.</p> <pre><code>from rapidata import RapidataClient\n\nPROMPTS = [\n    \"A sign that says 'Diffusion'.\",\n    \"A yellow flower sticking out of a green pot.\",\n    \"hyperrealism render of a surreal alien humanoid.\",\n    \"psychedelic duck\",\n    \"A small blue book sitting on a large red book.\"\n]\n\nIMAGE_PAIRS = [\n    [\"https://assets.rapidata.ai/flux_sign_diffusion.jpg\", \"https://assets.rapidata.ai/mj_sign_diffusion.jpg\"],\n    [\"https://assets.rapidata.ai/flux_flower.jpg\", \"https://assets.rapidata.ai/mj_flower.jpg\"],\n    [\"https://assets.rapidata.ai/flux_alien.jpg\", \"https://assets.rapidata.ai/mj_alien.jpg\"],\n    [\"https://assets.rapidata.ai/flux_duck.jpg\", \"https://assets.rapidata.ai/mj_duck.jpg\"],\n    [\"https://assets.rapidata.ai/flux_book.jpg\", \"https://assets.rapidata.ai/mj_book.jpg\"]\n]\n\nclient = RapidataClient()\n\n# Create audience with qualification example\naudience = client.audience.create_audience(name=\"Prompt Alignment Audience\")\naudience.add_compare_example(\n    instruction=\"Which image follows the prompt more accurately?\",\n    datapoint=[\n        \"https://assets.rapidata.ai/flux_sign_diffusion.jpg\",\n        \"https://assets.rapidata.ai/mj_sign_diffusion.jpg\"\n    ],\n    truth=\"https://assets.rapidata.ai/flux_sign_diffusion.jpg\",\n    context=\"A sign that says 'Diffusion'.\"\n)\n\n# Create job definition\njob_definition = client.job.create_compare_job_definition(\n    name=\"Example Image Prompt Alignment Job\",\n    instruction=\"Which image follows the prompt more accurately?\",\n    datapoints=IMAGE_PAIRS,\n    responses_per_datapoint=25,\n    contexts=PROMPTS\n)\n\n# Preview the job definition\njob_definition.preview()\n\n# Assign to audience and get results\njob = audience.assign_job(job_definition)\njob.display_progress_bar()\nresults = job.get_results()\nprint(results)\n</code></pre> \ud83d\udccb","boost":10},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>rapidata<ul> <li>rapidata_client<ul> <li>api<ul> <li>rapidata_api_client</li> </ul> </li> <li>audience<ul> <li>audience_example_handler</li> <li>rapidata_audience</li> <li>rapidata_audience_manager</li> </ul> </li> <li>benchmark<ul> <li>leaderboard<ul> <li>rapidata_leaderboard</li> </ul> </li> <li>participant<ul> <li>participant</li> </ul> </li> <li>rapidata_benchmark</li> <li>rapidata_benchmark_manager</li> </ul> </li> <li>config<ul> <li>logger</li> <li>logging_config</li> <li>managed_print</li> <li>rapidata_config</li> <li>tracer</li> <li>upload_config</li> </ul> </li> <li>datapoints<ul> <li>assets<ul> <li>constants</li> </ul> </li> </ul> </li> <li>demographic<ul> <li>demographic_manager</li> </ul> </li> <li>exceptions<ul> <li>asset_upload_exception</li> <li>failed_upload</li> <li>failed_upload_exception</li> <li>rapidata_error</li> </ul> </li> <li>filter<ul> <li>age_filter</li> <li>and_filter</li> <li>campaign_filter</li> <li>country_filter</li> <li>custom_filter</li> <li>device_filter</li> <li>gender_filter</li> <li>language_filter</li> <li>models<ul> <li>age_group</li> <li>device_type</li> <li>gender</li> </ul> </li> <li>new_user_filter</li> <li>not_filter</li> <li>or_filter</li> <li>rapidata_filters</li> <li>response_count_filter</li> <li>user_score_filter</li> </ul> </li> <li>flow<ul> <li>flow_item_result</li> <li>rapidata_flow</li> <li>rapidata_flow_item</li> <li>rapidata_flow_manager</li> </ul> </li> <li>job<ul> <li>rapidata_job</li> <li>rapidata_job_definition</li> <li>rapidata_job_manager</li> </ul> </li> <li>order<ul> <li>rapidata_order</li> <li>rapidata_order_manager</li> </ul> </li> <li>rapidata_client</li> <li>results<ul> <li>rapidata_results</li> </ul> </li> <li>selection<ul> <li>ab_test_selection</li> <li>capped_selection</li> <li>conditional_validation_selection</li> <li>demographic_selection</li> <li>effort_selection</li> <li>labeling_selection</li> <li>rapidata_retrieval_modes</li> <li>rapidata_selections</li> <li>shuffling_selection</li> <li>static_selection</li> <li>validation_selection</li> </ul> </li> <li>settings<ul> <li>alert_on_fast_response</li> <li>allow_neither_both</li> <li>custom_setting</li> <li>free_text_minimum_characters</li> <li>models<ul> <li>translation_behaviour_options</li> </ul> </li> <li>mute_video</li> <li>no_shuffle</li> <li>play_video_until_the_end</li> <li>rapidata_settings</li> <li>swap_context_instruction</li> <li>translation_behaviour</li> </ul> </li> <li>utils<ul> <li>threaded_uploader</li> </ul> </li> <li>validation<ul> <li>rapidata_validation_set</li> <li>rapids<ul> <li>box</li> <li>rapids</li> <li>rapids_manager</li> </ul> </li> <li>validation_set_manager</li> </ul> </li> </ul> </li> </ul> </li> </ul>","boost":0.2},{"location":"reference/rapidata/rapidata_client/rapidata_client/","title":"Rapidata client","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/rapidata_client/#rapidata.rapidata_client.rapidata_client.RapidataClient","title":"RapidataClient","text":"<pre><code>RapidataClient(\n    client_id: str | None = None,\n    client_secret: str | None = None,\n    environment: str = \"rapidata.ai\",\n    oauth_scope: str = \"openid roles\",\n    cert_path: str | None = None,\n    token: dict | None = None,\n    leeway: int = 60,\n)\n</code></pre> <p>The Rapidata client is the main entry point for interacting with the Rapidata API. It allows you to create orders and validation sets.</p> <p>Parameters:</p> Name Type Description Default <code>client_id</code> <code>str</code> <p>The client ID for authentication.</p> <code>None</code> <code>client_secret</code> <code>str</code> <p>The client secret for authentication.</p> <code>None</code> <code>environment</code> <code>str</code> <p>The API endpoint.</p> <code>'rapidata.ai'</code> <code>oauth_scope</code> <code>str</code> <p>The scopes to use for authentication. In general this does not need to be changed.</p> <code>'openid roles'</code> <code>cert_path</code> <code>str</code> <p>An optional path to a certificate file useful for development.</p> <code>None</code> <code>token</code> <code>dict</code> <p>If you already have a token that the client should use for authentication. Important, if set, this needs to be the complete token object containing the access token, token type and expiration time.</p> <code>None</code> <code>leeway</code> <code>int</code> <p>An optional leeway to use to determine if a token is expired. Defaults to 60 seconds.</p> <code>60</code> <p>Attributes:</p> Name Type Description <code>order</code> <code>RapidataOrderManager</code> <p>The RapidataOrderManager instance.</p> <code>validation</code> <code>ValidationSetManager</code> <p>The ValidationSetManager instance.</p> <code>flow</code> <code>RapidataFlowManager</code> <p>The RapidataFlowManager instance.</p> <code>audience</code> <code>RapidataAudienceManager</code> <p>The RapidataAudienceManager instance.</p> <code>job</code> <code>JobManager</code> <p>The JobManager instance.</p> <code>mri</code> <code>RapidataBenchmarkManager</code> <p>The RapidataBenchmarkManager instance.</p> Source code in <code>src/rapidata/rapidata_client/rapidata_client.py</code> <pre><code>def __init__(\n    self,\n    client_id: str | None = None,\n    client_secret: str | None = None,\n    environment: str = \"rapidata.ai\",\n    oauth_scope: str = \"openid roles\",\n    cert_path: str | None = None,\n    token: dict | None = None,\n    leeway: int = 60,\n):\n    \"\"\"Initialize the RapidataClient. If both the client_id and client_secret are None, it will try using your credentials under \"~/.config/rapidata/credentials.json\".\n    If this is not successful, it will open a browser window and ask you to log in, then save your new credentials in said json file.\n\n    Args:\n        client_id (str): The client ID for authentication.\n        client_secret (str): The client secret for authentication.\n        environment (str, optional): The API endpoint.\n        oauth_scope (str, optional): The scopes to use for authentication. In general this does not need to be changed.\n        cert_path (str, optional): An optional path to a certificate file useful for development.\n        token (dict, optional): If you already have a token that the client should use for authentication. Important, if set, this needs to be the complete token object containing the access token, token type and expiration time.\n        leeway (int, optional): An optional leeway to use to determine if a token is expired. Defaults to 60 seconds.\n\n    Attributes:\n        order (RapidataOrderManager): The RapidataOrderManager instance.\n        validation (ValidationSetManager): The ValidationSetManager instance.\n        flow (RapidataFlowManager): The RapidataFlowManager instance.\n        audience (RapidataAudienceManager): The RapidataAudienceManager instance.\n        job (JobManager): The JobManager instance.\n        mri (RapidataBenchmarkManager): The RapidataBenchmarkManager instance.\n    \"\"\"\n    tracer.set_session_id(\n        uuid.UUID(int=random.Random().getrandbits(128), version=4).hex\n    )\n\n    with tracer.start_as_current_span(\"RapidataClient.__init__\"):\n        logger.debug(\"Checking version\")\n        self._check_version()\n        if environment != \"rapidata.ai\":\n            rapidata_config.logging.enable_otlp = False\n\n        logger.debug(\"Initializing OpenAPIService\")\n        self._openapi_service = OpenAPIService(\n            client_id=client_id,\n            client_secret=client_secret,\n            environment=environment,\n            oauth_scope=oauth_scope,\n            cert_path=cert_path,\n            token=token,\n            leeway=leeway,\n        )\n\n        self._asset_uploader = AssetUploader(openapi_service=self._openapi_service)\n\n        logger.debug(\"Initializing RapidataOrderManager\")\n        self.order = RapidataOrderManager(openapi_service=self._openapi_service)\n\n        logger.debug(\"Initializing ValidationSetManager\")\n        self.validation = ValidationSetManager(\n            openapi_service=self._openapi_service\n        )\n\n        logger.debug(\"Initializing FlowManager\")\n        self.flow = RapidataFlowManager(openapi_service=self._openapi_service)\n\n        logger.debug(\"Initializing JobManager\")\n        self.job = RapidataJobManager(openapi_service=self._openapi_service)\n\n        logger.debug(\"Initializing RapidataBenchmarkManager\")\n        self.mri = RapidataBenchmarkManager(openapi_service=self._openapi_service)\n\n        logger.debug(\"Initializing RapidataAudienceManager\")\n        self.audience = RapidataAudienceManager(\n            openapi_service=self._openapi_service\n        )\n\n        logger.debug(\"Initializing RapidataDemographicManager\")\n        self._demographic = DemographicManager(\n            openapi_service=self._openapi_service\n        )\n\n    self._check_beta_features()  # can't be in the trace for some reason\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/rapidata_client/#rapidata.rapidata_client.rapidata_client.RapidataClient.reset_credentials","title":"reset_credentials","text":"<pre><code>reset_credentials()\n</code></pre> <p>Reset the credentials saved in the configuration file for the current environment.</p> Source code in <code>src/rapidata/rapidata_client/rapidata_client.py</code> <pre><code>def reset_credentials(self):\n    \"\"\"Reset the credentials saved in the configuration file for the current environment.\"\"\"\n    logger.info(\"Resetting credentials\")\n    self._openapi_service.reset_credentials()\n    logger.info(\"Credentials reset\")\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/rapidata_client/#rapidata.rapidata_client.rapidata_client.RapidataClient.clear_all_caches","title":"clear_all_caches","text":"<pre><code>clear_all_caches()\n</code></pre> <p>Clear all caches for the client.</p> Source code in <code>src/rapidata/rapidata_client/rapidata_client.py</code> <pre><code>def clear_all_caches(self):\n    \"\"\"Clear all caches for the client.\"\"\"\n    self._asset_uploader.clear_cache()\n    logger.info(\"All caches cleared\")\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/api/rapidata_api_client/","title":"Rapidata api client","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/api/rapidata_api_client/#rapidata.rapidata_client.api.rapidata_api_client.RapidataApiClient","title":"RapidataApiClient","text":"<pre><code>RapidataApiClient(*args, **kwargs)\n</code></pre> <p>               Bases: <code>ApiClient</code></p> <p>Custom API client that wraps errors in RapidataError.</p> Source code in <code>src/rapidata/rapidata_client/api/rapidata_api_client.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    super().__init__(*args, **kwargs)\n    self.id_generator = RandomIdGenerator()\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/api/rapidata_api_client/#rapidata.rapidata_client.api.rapidata_api_client.RapidataApiClient.response_deserialize","title":"response_deserialize","text":"<pre><code>response_deserialize(\n    response_data: RESTResponse,\n    response_types_map: Optional[\n        dict[str, ApiResponseT]\n    ] = None,\n) -&gt; ApiResponse[ApiResponseT]\n</code></pre> <p>Override the response_deserialize method to catch and convert exceptions.</p> Source code in <code>src/rapidata/rapidata_client/api/rapidata_api_client.py</code> <pre><code>def response_deserialize(\n    self,\n    response_data: rest.RESTResponse,\n    response_types_map: Optional[dict[str, ApiResponseT]] = None,\n) -&gt; ApiResponse[ApiResponseT]:\n    \"\"\"Override the response_deserialize method to catch and convert exceptions.\"\"\"\n    try:\n        return super().response_deserialize(response_data, response_types_map)\n    except ApiException as e:\n        status_code = getattr(e, \"status\", None)\n        message = str(e)\n        details = None\n\n        # Extract more detailed error message from response body if available\n        if hasattr(e, \"body\") and e.body:\n            try:\n                body_json = json.loads(e.body)\n                if isinstance(body_json, dict):\n                    if \"message\" in body_json:\n                        message = body_json[\"message\"]\n                    elif \"error\" in body_json:\n                        message = body_json[\"error\"]\n\n                    # Store the full error details for debugging\n                    details = body_json\n            except (json.JSONDecodeError, AttributeError):\n                # If we can't parse the body as JSON, use the original message\n                pass\n\n        error_formatted = RapidataError(\n            status_code=status_code,\n            message=message,\n            original_exception=e,\n            details=details,\n        )\n\n        # Only log error if not suppressed\n        if not _should_suppress_error_logging():\n            logger.error(\"Error: %s\", error_formatted)\n        else:\n            logger.debug(\"Suppressed Error: %s\", error_formatted)\n\n        raise error_formatted from None\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/api/rapidata_api_client/#rapidata.rapidata_client.api.rapidata_api_client.suppress_rapidata_error_logging","title":"suppress_rapidata_error_logging","text":"<pre><code>suppress_rapidata_error_logging()\n</code></pre> <p>Context manager to suppress error logging for RapidataApiClient calls.</p> Source code in <code>src/rapidata/rapidata_client/api/rapidata_api_client.py</code> <pre><code>@contextmanager\ndef suppress_rapidata_error_logging():\n    \"\"\"Context manager to suppress error logging for RapidataApiClient calls.\"\"\"\n    old_value = getattr(_thread_local, \"suppress_error_logging\", False)\n    _thread_local.suppress_error_logging = True\n    try:\n        yield\n    finally:\n        _thread_local.suppress_error_logging = old_value\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/audience/audience_example_handler/","title":"Audience example handler","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/audience/audience_example_handler/#rapidata.rapidata_client.audience.audience_example_handler.AudienceExampleHandler","title":"AudienceExampleHandler","text":"<pre><code>AudienceExampleHandler(\n    openapi_service: OpenAPIService, audience_id: str\n)\n</code></pre> <p>Can be used to build different types of examples. That can then be added to Example sets</p> Source code in <code>src/rapidata/rapidata_client/audience/audience_example_handler.py</code> <pre><code>def __init__(self, openapi_service: OpenAPIService, audience_id: str):\n    self._openapi_service = openapi_service\n    self._audience_id = audience_id\n    self._asset_uploader = AssetUploader(openapi_service)\n    self._asset_mapper = AssetMapper()\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/audience/audience_example_handler/#rapidata.rapidata_client.audience.audience_example_handler.AudienceExampleHandler.add_classification_example","title":"add_classification_example","text":"<pre><code>add_classification_example(\n    instruction: str,\n    answer_options: list[str],\n    datapoint: str,\n    truth: list[str],\n    data_type: Literal[\"media\", \"text\"] = \"media\",\n    context: str | None = None,\n    media_context: str | None = None,\n    explanation: str | None = None,\n) -&gt; None\n</code></pre> <p>add a classification example to the audience</p> <p>Parameters:</p> Name Type Description Default <code>instruction</code> <code>str</code> <p>The instruction/question to be shown to the labeler.</p> required <code>answer_options</code> <code>list[str]</code> <p>The options that the labeler can choose from to answer the question.</p> required <code>datapoint</code> <code>str</code> <p>The datapoint that the labeler will be labeling.</p> required <code>truth</code> <code>list[str]</code> <p>The correct answers to the question.</p> required <code>data_type</code> <code>str</code> <p>The type of the datapoint. Defaults to \"media\" (any form of image, video or audio).</p> <code>'media'</code> <code>context</code> <code>str</code> <p>The context is text that will be shown in addition to the instruction. Defaults to None.</p> <code>None</code> <code>media_context</code> <code>str</code> <p>The media context is a link to an image / video that will be shown in addition to the instruction (can be combined with context). Defaults to None.</p> <code>None</code> <code>explanation</code> <code>str</code> <p>The explanation that will be shown to the labeler if the answer is wrong. Defaults to None.</p> <code>None</code> Source code in <code>src/rapidata/rapidata_client/audience/audience_example_handler.py</code> <pre><code>def add_classification_example(\n    self,\n    instruction: str,\n    answer_options: list[str],\n    datapoint: str,\n    truth: list[str],\n    data_type: Literal[\"media\", \"text\"] = \"media\",\n    context: str | None = None,\n    media_context: str | None = None,\n    explanation: str | None = None,\n) -&gt; None:\n    \"\"\"add a classification example to the audience\n\n    Args:\n        instruction (str): The instruction/question to be shown to the labeler.\n        answer_options (list[str]): The options that the labeler can choose from to answer the question.\n        datapoint (str): The datapoint that the labeler will be labeling.\n        truth (list[str]): The correct answers to the question.\n        data_type (str, optional): The type of the datapoint. Defaults to \"media\" (any form of image, video or audio).\n        context (str, optional): The context is text that will be shown in addition to the instruction. Defaults to None.\n        media_context (str, optional): The media context is a link to an image / video that will be shown in addition to the instruction (can be combined with context). Defaults to None.\n        explanation (str, optional): The explanation that will be shown to the labeler if the answer is wrong. Defaults to None.\n    \"\"\"\n    from rapidata.api_client.models.add_rapid_to_audience_model import (\n        AddRapidToAudienceModel,\n    )\n\n    if not isinstance(truth, list):\n        raise ValueError(\"Truth must be a list of strings\")\n\n    if not all(truth in answer_options for truth in truth):\n        raise ValueError(\"Truth must be part of the answer options\")\n\n    if data_type == \"media\":\n        uploaded_name = self._asset_uploader.upload_asset(datapoint)\n        asset_input = self._asset_mapper.create_existing_asset_input(uploaded_name)\n    else:\n        asset_input = self._asset_mapper.create_text_input(datapoint)\n\n    payload = IRapidPayload(\n        actual_instance=IRapidPayloadClassifyPayload(\n            _t=\"ClassifyPayload\",\n            categories=[\n                ClassifyPayloadCategory(label=option, value=option)\n                for option in answer_options\n            ],\n            title=instruction,\n        )\n    )\n    model_truth = IValidationTruth(\n        actual_instance=IValidationTruthAttachCategoryTruth(\n            correctCategories=truth, _t=\"AttachCategoryTruth\"\n        )\n    )\n\n    self._openapi_service.audience_api.audience_audience_id_rapid_post(\n        audience_id=self._audience_id,\n        add_rapid_to_audience_model=AddRapidToAudienceModel(\n            asset=asset_input,\n            payload=payload,\n            truth=model_truth,\n            context=context,\n            contextAsset=(\n                self._asset_mapper.create_existing_asset_input(\n                    self._asset_uploader.upload_asset(media_context)\n                )\n                if media_context\n                else None\n            ),\n            explanation=explanation,\n            randomCorrectProbability=len(truth) / len(answer_options),\n        ),\n    )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/audience/audience_example_handler/#rapidata.rapidata_client.audience.audience_example_handler.AudienceExampleHandler.add_compare_example","title":"add_compare_example","text":"<pre><code>add_compare_example(\n    instruction: str,\n    truth: str,\n    datapoint: list[str],\n    data_type: Literal[\"media\", \"text\"] = \"media\",\n    context: str | None = None,\n    media_context: str | None = None,\n    explanation: str | None = None,\n) -&gt; None\n</code></pre> <p>add a compare example to the audience</p> <p>Parameters:</p> Name Type Description Default <code>instruction</code> <code>str</code> <p>The instruction that the labeler will be comparing the assets on.</p> required <code>truth</code> <code>str</code> <p>The correct answer to the comparison. (has to be one of the assets)</p> required <code>datapoint</code> <code>list[str]</code> <p>The two assets that the labeler will be comparing.</p> required <code>data_type</code> <code>str</code> <p>The type of the datapoint. Defaults to \"media\" (any form of image, video or audio).</p> <code>'media'</code> <code>context</code> <code>str</code> <p>The context is text that will be shown in addition to the instruction. Defaults to None.</p> <code>None</code> <code>media_context</code> <code>str</code> <p>The media context is a link to an image / video that will be shown in addition to the instruction (can be combined with context). Defaults to None.</p> <code>None</code> <code>explanation</code> <code>str</code> <p>The explanation that will be shown to the labeler if the answer is wrong. Defaults to None.</p> <code>None</code> Source code in <code>src/rapidata/rapidata_client/audience/audience_example_handler.py</code> <pre><code>def add_compare_example(\n    self,\n    instruction: str,\n    truth: str,\n    datapoint: list[str],\n    data_type: Literal[\"media\", \"text\"] = \"media\",\n    context: str | None = None,\n    media_context: str | None = None,\n    explanation: str | None = None,\n) -&gt; None:\n    \"\"\"add a compare example to the audience\n\n    Args:\n        instruction (str): The instruction that the labeler will be comparing the assets on.\n        truth (str): The correct answer to the comparison. (has to be one of the assets)\n        datapoint (list[str]): The two assets that the labeler will be comparing.\n        data_type (str, optional): The type of the datapoint. Defaults to \"media\" (any form of image, video or audio).\n        context (str, optional): The context is text that will be shown in addition to the instruction. Defaults to None.\n        media_context (str, optional): The media context is a link to an image / video that will be shown in addition to the instruction (can be combined with context). Defaults to None.\n        explanation (str, optional): The explanation that will be shown to the labeler if the answer is wrong. Defaults to None.\n    \"\"\"\n    from rapidata.api_client.models.add_rapid_to_audience_model import (\n        AddRapidToAudienceModel,\n    )\n\n    payload = IRapidPayload(\n        actual_instance=IRapidPayloadComparePayload(\n            _t=\"ComparePayload\", criteria=instruction\n        )\n    )\n\n    uploaded_names: list[str] = []\n    if data_type == \"media\":\n        uploaded_names = [self._asset_uploader.upload_asset(dp) for dp in datapoint]\n        asset_input = self._asset_mapper.create_existing_asset_input(uploaded_names)\n    else:\n        asset_input = self._asset_mapper.create_text_input(datapoint)\n\n    if truth not in datapoint:\n        raise ValueError(\"Truth must be one of the datapoints\")\n\n    truth_index = datapoint.index(truth)\n    if data_type == \"media\":\n        winner_id = uploaded_names[truth_index]\n    else:\n        winner_id = truth\n    model_truth = IValidationTruth(\n        actual_instance=IValidationTruthCompareTruth(\n            _t=\"CompareTruth\", winnerId=winner_id\n        )\n    )\n\n    if len(datapoint) != 2:\n        raise ValueError(\"Compare rapid requires exactly two media paths\")\n\n    self._openapi_service.audience_api.audience_audience_id_rapid_post(\n        audience_id=self._audience_id,\n        add_rapid_to_audience_model=AddRapidToAudienceModel(\n            asset=asset_input,\n            payload=payload,\n            truth=model_truth,\n            context=context,\n            contextAsset=(\n                self._asset_mapper.create_existing_asset_input(\n                    self._asset_uploader.upload_asset(media_context)\n                )\n                if media_context\n                else None\n            ),\n            explanation=explanation,\n            randomCorrectProbability=0.5,\n        ),\n    )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/audience/rapidata_audience/","title":"Rapidata audience","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/audience/rapidata_audience/#rapidata.rapidata_client.audience.rapidata_audience.RapidataAudience","title":"RapidataAudience","text":"<pre><code>RapidataAudience(\n    id: str,\n    name: str,\n    filters: list[RapidataFilter],\n    openapi_service: OpenAPIService,\n)\n</code></pre> <p>Represents a Rapidata audience.</p> <p>An audience is a group of annotators that can be recruited based on example tasks and assigned jobs.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>The unique identifier of the audience.</p> <code>name</code> <code>str</code> <p>The name of the audience.</p> <code>filters</code> <code>list[RapidataFilter]</code> <p>The list of filters applied to the audience.</p> Source code in <code>src/rapidata/rapidata_client/audience/rapidata_audience.py</code> <pre><code>def __init__(\n    self,\n    id: str,\n    name: str,\n    filters: list[RapidataFilter],\n    openapi_service: OpenAPIService,\n):\n    self.id = id\n    self._name = name\n    self._filters = filters\n    self._openapi_service = openapi_service\n    self._example_handler = AudienceExampleHandler(openapi_service, id)\n    self._recruiting_started = False\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/audience/rapidata_audience/#rapidata.rapidata_client.audience.rapidata_audience.RapidataAudience.name","title":"name  <code>property</code>","text":"<pre><code>name: str\n</code></pre> <p>The name of the audience.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/audience/rapidata_audience/#rapidata.rapidata_client.audience.rapidata_audience.RapidataAudience.filters","title":"filters  <code>property</code>","text":"<pre><code>filters: list[RapidataFilter]\n</code></pre> <p>The list of filters applied to the audience.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/audience/rapidata_audience/#rapidata.rapidata_client.audience.rapidata_audience.RapidataAudience.update_filters","title":"update_filters","text":"<pre><code>update_filters(\n    filters: list[RapidataFilter],\n) -&gt; RapidataAudience\n</code></pre> <p>Update the filters for this audience.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>list[RapidataFilter]</code> <p>The new list of filters to apply to the audience.</p> required <p>Returns:</p> Name Type Description <code>RapidataAudience</code> <code>RapidataAudience</code> <p>The updated audience instance (self) for method chaining.</p> Source code in <code>src/rapidata/rapidata_client/audience/rapidata_audience.py</code> <pre><code>def update_filters(self, filters: list[RapidataFilter]) -&gt; RapidataAudience:\n    \"\"\"Update the filters for this audience.\n\n    Args:\n        filters (list[RapidataFilter]): The new list of filters to apply to the audience.\n\n    Returns:\n        RapidataAudience: The updated audience instance (self) for method chaining.\n    \"\"\"\n    with tracer.start_as_current_span(\"RapidataAudience.update_filters\"):\n        from rapidata.api_client.models.update_audience_request import (\n            UpdateAudienceRequest,\n        )\n\n        logger.debug(f\"Updating filters for audience: {self.id} to {filters}\")\n        self._openapi_service.audience_api.audience_audience_id_patch(\n            audience_id=self.id,\n            update_audience_request=UpdateAudienceRequest(\n                filters=[filter._to_audience_model() for filter in filters],\n            ),\n        )\n        self._filters = filters\n        return self\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/audience/rapidata_audience/#rapidata.rapidata_client.audience.rapidata_audience.RapidataAudience.update_name","title":"update_name","text":"<pre><code>update_name(name: str) -&gt; RapidataAudience\n</code></pre> <p>Update the name of this audience.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The new name for the audience.</p> required <p>Returns:</p> Name Type Description <code>RapidataAudience</code> <code>RapidataAudience</code> <p>The updated audience instance (self) for method chaining.</p> Source code in <code>src/rapidata/rapidata_client/audience/rapidata_audience.py</code> <pre><code>def update_name(self, name: str) -&gt; RapidataAudience:\n    \"\"\"Update the name of this audience.\n\n    Args:\n        name (str): The new name for the audience.\n\n    Returns:\n        RapidataAudience: The updated audience instance (self) for method chaining.\n    \"\"\"\n    with tracer.start_as_current_span(\"RapidataAudience.update_name\"):\n        from rapidata.api_client.models.update_audience_request import (\n            UpdateAudienceRequest,\n        )\n\n        logger.debug(f\"Updating name for audience: {self.id} to {name}\")\n        self._openapi_service.audience_api.audience_audience_id_patch(\n            audience_id=self.id,\n            update_audience_request=UpdateAudienceRequest(name=name),\n        )\n        self._name = name\n        return self\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/audience/rapidata_audience/#rapidata.rapidata_client.audience.rapidata_audience.RapidataAudience.assign_job","title":"assign_job","text":"<pre><code>assign_job(\n    job_definition: RapidataJobDefinition,\n) -&gt; RapidataJob\n</code></pre> <p>Assign a job to this audience.</p> <p>Creates a new job instance from the job definition and assigns it to this audience. The job will be executed by the annotators in this audience.</p> <p>Parameters:</p> Name Type Description Default <code>job_definition</code> <code>JobDefinition</code> <p>The job definition to create and assign to the audience.</p> required <p>Returns:</p> Name Type Description <code>RapidataJob</code> <code>RapidataJob</code> <p>The created job instance.</p> Source code in <code>src/rapidata/rapidata_client/audience/rapidata_audience.py</code> <pre><code>def assign_job(self, job_definition: RapidataJobDefinition) -&gt; RapidataJob:\n    \"\"\"Assign a job to this audience.\n\n    Creates a new job instance from the job definition and assigns it to this audience.\n    The job will be executed by the annotators in this audience.\n\n    Args:\n        job_definition (JobDefinition): The job definition to create and assign to the audience.\n\n    Returns:\n        RapidataJob: The created job instance.\n    \"\"\"\n    with tracer.start_as_current_span(\"RapidataAudience.assign_job\"):\n        from rapidata.api_client.models.create_job_endpoint_input import (\n            CreateJobEndpointInput,\n        )\n        from rapidata.rapidata_client.job.rapidata_job import RapidataJob\n        from datetime import datetime\n\n        logger.debug(f\"Assigning job to audience: {self.id}\")\n        response = self._openapi_service.job_api.job_post(\n            create_job_endpoint_input=CreateJobEndpointInput(\n                audienceId=self.id,\n                jobDefinitionId=job_definition.id,\n            ),\n        )\n        job = RapidataJob(\n            job_id=response.job_id,\n            name=job_definition.name,\n            audience_id=self.id,\n            created_at=datetime.now(),\n            definition_id=job_definition.id,\n            openapi_service=self._openapi_service,\n        )\n        logger.info(f\"Assigned job to audience: {self.id}\")\n        return job\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/audience/rapidata_audience/#rapidata.rapidata_client.audience.rapidata_audience.RapidataAudience.add_classification_example","title":"add_classification_example","text":"<pre><code>add_classification_example(\n    instruction: str,\n    answer_options: list[str],\n    datapoint: str,\n    truth: list[str],\n    data_type: Literal[\"media\", \"text\"] = \"media\",\n    context: str | None = None,\n    media_context: str | None = None,\n    explanation: str | None = None,\n) -&gt; RapidataAudience\n</code></pre> <p>Add a classification training example to this audience.</p> <p>Training examples help annotators understand the task by showing them a sample datapoint with the correct answer before they start labeling.</p> <p>Parameters:</p> Name Type Description Default <code>instruction</code> <code>str</code> <p>The instruction for how the data should be classified.</p> required <code>answer_options</code> <code>list[str]</code> <p>The list of possible answer options for the classification.</p> required <code>datapoint</code> <code>str</code> <p>The datapoint (URL or path) to use as the training example.</p> required <code>truth</code> <code>list[str]</code> <p>The correct answer(s) for this training example.</p> required <code>data_type</code> <code>Literal['media', 'text']</code> <p>The data type of the datapoint. Defaults to \"media\".</p> <code>'media'</code> <code>context</code> <code>str</code> <p>Additional text context to display with the example. Defaults to None.</p> <code>None</code> <code>media_context</code> <code>str</code> <p>Additional media (URL or path) to display with the example. Defaults to None.</p> <code>None</code> <code>explanation</code> <code>str</code> <p>An explanation of why the truth is correct. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>RapidataAudience</code> <code>RapidataAudience</code> <p>The audience instance (self) for method chaining.</p> Source code in <code>src/rapidata/rapidata_client/audience/rapidata_audience.py</code> <pre><code>def add_classification_example(\n    self,\n    instruction: str,\n    answer_options: list[str],\n    datapoint: str,\n    truth: list[str],\n    data_type: Literal[\"media\", \"text\"] = \"media\",\n    context: str | None = None,\n    media_context: str | None = None,\n    explanation: str | None = None,\n) -&gt; RapidataAudience:\n    \"\"\"Add a classification training example to this audience.\n\n    Training examples help annotators understand the task by showing them\n    a sample datapoint with the correct answer before they start labeling.\n\n    Args:\n        instruction (str): The instruction for how the data should be classified.\n        answer_options (list[str]): The list of possible answer options for the classification.\n        datapoint (str): The datapoint (URL or path) to use as the training example.\n        truth (list[str]): The correct answer(s) for this training example.\n        data_type (Literal[\"media\", \"text\"], optional): The data type of the datapoint. Defaults to \"media\".\n        context (str, optional): Additional text context to display with the example. Defaults to None.\n        media_context (str, optional): Additional media (URL or path) to display with the example. Defaults to None.\n        explanation (str, optional): An explanation of why the truth is correct. Defaults to None.\n\n    Returns:\n        RapidataAudience: The audience instance (self) for method chaining.\n    \"\"\"\n    with tracer.start_as_current_span(\n        \"RapidataAudience.add_classification_example\"\n    ):\n        logger.debug(\n            f\"Adding classification example to audience: {self.id} with instruction: {instruction}, answer_options: {answer_options}, datapoint: {datapoint}, truths: {truth}, data_type: {data_type}, context: {context}, media_context: {media_context}, explanation: {explanation}\"\n        )\n        self._example_handler.add_classification_example(\n            instruction,\n            answer_options,\n            datapoint,\n            truth,\n            data_type,\n            context,\n            media_context,\n            explanation,\n        )\n        self._try_start_recruiting()\n        return self\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/audience/rapidata_audience/#rapidata.rapidata_client.audience.rapidata_audience.RapidataAudience.add_compare_example","title":"add_compare_example","text":"<pre><code>add_compare_example(\n    instruction: str,\n    truth: str,\n    datapoint: list[str],\n    data_type: Literal[\"media\", \"text\"] = \"media\",\n    context: str | None = None,\n    media_context: str | None = None,\n    explanation: str | None = None,\n) -&gt; RapidataAudience\n</code></pre> <p>Add a comparison training example to this audience.</p> <p>Training examples help annotators understand the task by showing them a sample comparison with the correct answer before they start labeling.</p> <p>Parameters:</p> Name Type Description Default <code>instruction</code> <code>str</code> <p>The instruction for the comparison task.</p> required <code>truth</code> <code>str</code> <p>The correct answer for this training example (which option should be selected).</p> required <code>datapoint</code> <code>list[str]</code> <p>A list of exactly two datapoints (URLs or paths) to compare.</p> required <code>data_type</code> <code>Literal['media', 'text']</code> <p>The data type of the datapoints. Defaults to \"media\".</p> <code>'media'</code> <code>context</code> <code>str</code> <p>Additional text context to display with the example. Defaults to None.</p> <code>None</code> <code>media_context</code> <code>str</code> <p>Additional media (URL or path) to display with the example. Defaults to None.</p> <code>None</code> <code>explanation</code> <code>str</code> <p>An explanation of why the truth is correct. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>RapidataAudience</code> <code>RapidataAudience</code> <p>The audience instance (self) for method chaining.</p> Source code in <code>src/rapidata/rapidata_client/audience/rapidata_audience.py</code> <pre><code>def add_compare_example(\n    self,\n    instruction: str,\n    truth: str,\n    datapoint: list[str],\n    data_type: Literal[\"media\", \"text\"] = \"media\",\n    context: str | None = None,\n    media_context: str | None = None,\n    explanation: str | None = None,\n) -&gt; RapidataAudience:\n    \"\"\"Add a comparison training example to this audience.\n\n    Training examples help annotators understand the task by showing them\n    a sample comparison with the correct answer before they start labeling.\n\n    Args:\n        instruction (str): The instruction for the comparison task.\n        truth (str): The correct answer for this training example (which option should be selected).\n        datapoint (list[str]): A list of exactly two datapoints (URLs or paths) to compare.\n        data_type (Literal[\"media\", \"text\"], optional): The data type of the datapoints. Defaults to \"media\".\n        context (str, optional): Additional text context to display with the example. Defaults to None.\n        media_context (str, optional): Additional media (URL or path) to display with the example. Defaults to None.\n        explanation (str, optional): An explanation of why the truth is correct. Defaults to None.\n\n    Returns:\n        RapidataAudience: The audience instance (self) for method chaining.\n    \"\"\"\n    with tracer.start_as_current_span(\"RapidataAudience.add_compare_example\"):\n        logger.debug(\n            f\"Adding compare example to audience: {self.id} with instruction: {instruction}, truth: {truth}, datapoint: {datapoint}, data_type: {data_type}, context: {context}, media_context: {media_context}, explanation: {explanation}\"\n        )\n        self._example_handler.add_compare_example(\n            instruction,\n            truth,\n            datapoint,\n            data_type,\n            context,\n            media_context,\n            explanation,\n        )\n        self._try_start_recruiting()\n        return self\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/audience/rapidata_audience/#rapidata.rapidata_client.audience.rapidata_audience.RapidataAudience.find_jobs","title":"find_jobs","text":"<pre><code>find_jobs(\n    name: str = \"\", amount: int = 10\n) -&gt; list[RapidataJob]\n</code></pre> <p>Find jobs assigned to this audience.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Filter jobs by name (matching jobs will contain this string). Defaults to \"\" for any job.</p> <code>''</code> <code>amount</code> <code>int</code> <p>The maximum number of jobs to return. Defaults to 10.</p> <code>10</code> <p>Returns:</p> Type Description <code>list[RapidataJob]</code> <p>list[RapidataJob]: A list of RapidataJob instances assigned to this audience.</p> Source code in <code>src/rapidata/rapidata_client/audience/rapidata_audience.py</code> <pre><code>def find_jobs(self, name: str = \"\", amount: int = 10) -&gt; list[RapidataJob]:\n    \"\"\"Find jobs assigned to this audience.\n\n    Args:\n        name (str, optional): Filter jobs by name (matching jobs will contain this string). Defaults to \"\" for any job.\n        amount (int, optional): The maximum number of jobs to return. Defaults to 10.\n\n    Returns:\n        list[RapidataJob]: A list of RapidataJob instances assigned to this audience.\n    \"\"\"\n    with tracer.start_as_current_span(\"RapidataAudience.find_jobs\"):\n        from rapidata.rapidata_client.job.rapidata_job import RapidataJob\n        from rapidata.api_client.models.query_model import QueryModel\n        from rapidata.api_client.models.root_filter import RootFilter\n        from rapidata.api_client.models.filter import Filter\n        from rapidata.api_client.models.filter_operator import FilterOperator\n        from rapidata.api_client.models.page_info import PageInfo\n        from rapidata.api_client.models.sort_criterion import SortCriterion\n        from rapidata.api_client.models.sort_direction import SortDirection\n\n        response = self._openapi_service.job_api.jobs_get(\n            request=QueryModel(\n                page=PageInfo(index=1, size=amount),\n                filter=RootFilter(\n                    filters=[\n                        Filter(\n                            field=\"AudienceId\",\n                            operator=FilterOperator.EQ,\n                            value=self.id,\n                        ),\n                        Filter(\n                            field=\"Name\",\n                            operator=FilterOperator.CONTAINS,\n                            value=name,\n                        ),\n                    ]\n                ),\n                sortCriteria=[\n                    SortCriterion(\n                        direction=SortDirection.DESC, propertyName=\"CreatedAt\"\n                    )\n                ],\n            ),\n        )\n        return [\n            RapidataJob(\n                job_id=job.job_id,\n                name=job.name,\n                audience_id=job.audience_id,\n                created_at=job.created_at,\n                definition_id=job.definition_id,\n                openapi_service=self._openapi_service,\n                pipeline_id=job.pipeline_id,\n            )\n            for job in response.items\n        ]\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/audience/rapidata_audience_manager/","title":"Rapidata audience manager","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/audience/rapidata_audience_manager/#rapidata.rapidata_client.audience.rapidata_audience_manager.RapidataAudienceManager","title":"RapidataAudienceManager","text":"<pre><code>RapidataAudienceManager(openapi_service: OpenAPIService)\n</code></pre> <p>Handles everything regarding audiences from creation to retrieval.</p> <p>A manager for creating, retrieving, and searching for audiences. Audiences are groups of annotators that can be recruited based on example tasks and assigned jobs.</p> Source code in <code>src/rapidata/rapidata_client/audience/rapidata_audience_manager.py</code> <pre><code>def __init__(self, openapi_service: OpenAPIService):\n    self._openapi_service = openapi_service\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/audience/rapidata_audience_manager/#rapidata.rapidata_client.audience.rapidata_audience_manager.RapidataAudienceManager.create_audience","title":"create_audience","text":"<pre><code>create_audience(\n    name: str, filters: list[RapidataFilter] | None = None\n) -&gt; RapidataAudience\n</code></pre> <p>Create a new audience.</p> <p>Creates a new audience with the specified name and optional filters.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the audience.</p> required <code>filters</code> <code>list[RapidataFilter]</code> <p>The list of filters to apply to the audience. Defaults to None (no filters).</p> <code>None</code> <p>Returns:</p> Name Type Description <code>RapidataAudience</code> <code>RapidataAudience</code> <p>The created audience instance.</p> Source code in <code>src/rapidata/rapidata_client/audience/rapidata_audience_manager.py</code> <pre><code>def create_audience(\n    self,\n    name: str,\n    filters: list[RapidataFilter] | None = None,\n) -&gt; RapidataAudience:\n    \"\"\"Create a new audience.\n\n    Creates a new audience with the specified name and optional filters.\n\n    Args:\n        name (str): The name of the audience.\n        filters (list[RapidataFilter], optional): The list of filters to apply to the audience. Defaults to None (no filters).\n\n    Returns:\n        RapidataAudience: The created audience instance.\n    \"\"\"\n    with tracer.start_as_current_span(\"RapidataAudienceManager.create_audience\"):\n        from rapidata.rapidata_client.audience.rapidata_audience import (\n            RapidataAudience,\n        )\n        from rapidata.api_client.models.create_audience_request import (\n            CreateAudienceRequest,\n        )\n\n        logger.debug(f\"Creating audience: {name}\")\n        if filters is None:\n            filters = []\n        response = self._openapi_service.audience_api.audience_post(\n            create_audience_request=CreateAudienceRequest(\n                name=name,\n                filters=[filter._to_audience_model() for filter in filters],\n            ),\n        )\n        audience = RapidataAudience(\n            id=response.audience_id,\n            name=name,\n            filters=filters,\n            openapi_service=self._openapi_service,\n        )\n        return audience\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/audience/rapidata_audience_manager/#rapidata.rapidata_client.audience.rapidata_audience_manager.RapidataAudienceManager.get_audience_by_id","title":"get_audience_by_id","text":"<pre><code>get_audience_by_id(audience_id: str) -&gt; RapidataAudience\n</code></pre> <p>Get an audience by its ID.</p> <p>Parameters:</p> Name Type Description Default <code>audience_id</code> <code>str</code> <p>The unique identifier of the audience.</p> required <p>Returns:</p> Name Type Description <code>RapidataAudience</code> <code>RapidataAudience</code> <p>The audience instance.</p> Source code in <code>src/rapidata/rapidata_client/audience/rapidata_audience_manager.py</code> <pre><code>def get_audience_by_id(self, audience_id: str) -&gt; RapidataAudience:\n    \"\"\"Get an audience by its ID.\n\n    Args:\n        audience_id (str): The unique identifier of the audience.\n\n    Returns:\n        RapidataAudience: The audience instance.\n    \"\"\"\n    with tracer.start_as_current_span(\"RapidataAudienceManager.get_audience_by_id\"):\n        from rapidata.rapidata_client.filter._backend_filter_mapper import (\n            BackendFilterMapper,\n        )\n        from rapidata.rapidata_client.audience.rapidata_audience import (\n            RapidataAudience,\n        )\n\n        logger.debug(f\"Getting audience by id: {audience_id}\")\n        response = self._openapi_service.audience_api.audience_audience_id_get(\n            audience_id=audience_id,\n        )\n        return RapidataAudience(\n            id=audience_id,\n            name=response.name,\n            filters=[\n                BackendFilterMapper.backend_filter_from_rapidata_filter(filter)\n                for filter in response.filters\n            ],\n            openapi_service=self._openapi_service,\n        )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/audience/rapidata_audience_manager/#rapidata.rapidata_client.audience.rapidata_audience_manager.RapidataAudienceManager.find_audiences","title":"find_audiences","text":"<pre><code>find_audiences(\n    name: str = \"\", amount: int = 10\n) -&gt; list[RapidataAudience]\n</code></pre> <p>Find your audiences by name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Filter audiences by name (matching audiences will contain this string). Defaults to \"\" for any audience.</p> <code>''</code> <code>amount</code> <code>int</code> <p>The maximum number of audiences to return. Defaults to 10.</p> <code>10</code> <p>Returns:</p> Type Description <code>list[RapidataAudience]</code> <p>list[RapidataAudience]: A list of RapidataAudience instances.</p> Source code in <code>src/rapidata/rapidata_client/audience/rapidata_audience_manager.py</code> <pre><code>def find_audiences(\n    self, name: str = \"\", amount: int = 10\n) -&gt; list[RapidataAudience]:\n    \"\"\"Find your audiences by name.\n\n    Args:\n        name (str, optional): Filter audiences by name (matching audiences will contain this string). Defaults to \"\" for any audience.\n        amount (int, optional): The maximum number of audiences to return. Defaults to 10.\n\n    Returns:\n        list[RapidataAudience]: A list of RapidataAudience instances.\n    \"\"\"\n    with tracer.start_as_current_span(\"RapidataAudienceManager.find_audiences\"):\n        from rapidata.rapidata_client.filter._backend_filter_mapper import (\n            BackendFilterMapper,\n        )\n        from rapidata.api_client.models.page_info import PageInfo\n        from rapidata.api_client.models.query_model import QueryModel\n        from rapidata.api_client.models.root_filter import RootFilter\n        from rapidata.api_client.models.filter import Filter\n        from rapidata.api_client.models.filter_operator import FilterOperator\n        from rapidata.api_client.models.sort_criterion import SortCriterion\n        from rapidata.api_client.models.sort_direction import SortDirection\n        from rapidata.rapidata_client.audience.rapidata_audience import (\n            RapidataAudience,\n        )\n\n        logger.debug(f\"Finding audiences: {name}, {amount}\")\n        response = self._openapi_service.audience_api.audiences_get(\n            request=QueryModel(\n                page=PageInfo(index=1, size=amount),\n                filter=RootFilter(\n                    filters=[\n                        Filter(\n                            field=\"Name\",\n                            operator=FilterOperator.CONTAINS,\n                            value=name,\n                        )\n                    ]\n                ),\n                sortCriteria=[\n                    SortCriterion(\n                        direction=SortDirection.DESC, propertyName=\"CreatedAt\"\n                    )\n                ],\n            )\n        )\n        audiences = []\n        for item in response.items:\n            audiences.append(\n                RapidataAudience(\n                    id=item.id,\n                    name=item.name,\n                    filters=[\n                        BackendFilterMapper.backend_filter_from_rapidata_filter(\n                            filter\n                        )\n                        for filter in item.filters\n                    ],\n                    openapi_service=self._openapi_service,\n                )\n            )\n\n        return audiences\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/benchmark/rapidata_benchmark/","title":"Rapidata benchmark","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/benchmark/rapidata_benchmark/#rapidata.rapidata_client.benchmark.rapidata_benchmark.RapidataBenchmark","title":"RapidataBenchmark","text":"<pre><code>RapidataBenchmark(\n    name: str, id: str, openapi_service: OpenAPIService\n)\n</code></pre> <p>An instance of a Rapidata benchmark.</p> <p>Used to interact with a specific benchmark in the Rapidata system, such as retrieving prompts and evaluating models.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name that will be used to identify the benchmark on the overview.</p> required <code>id</code> <code>str</code> <p>The id of the benchmark.</p> required <code>openapi_service</code> <code>OpenAPIService</code> <p>The OpenAPI service to use to interact with the Rapidata API.</p> required Source code in <code>src/rapidata/rapidata_client/benchmark/rapidata_benchmark.py</code> <pre><code>def __init__(self, name: str, id: str, openapi_service: OpenAPIService):\n    from rapidata.rapidata_client.datapoints._asset_uploader import AssetUploader\n\n    self.name = name\n    self.id = id\n    self._openapi_service = openapi_service\n    self.__prompts: list[str | None] = []\n    self.__prompt_assets: list[str | None] = []\n    self.__leaderboards: list[\"RapidataLeaderboard\"] = []\n    self.__identifiers: list[str] = []\n    self.__tags: list[list[str]] = []\n    self.__participants: list[BenchmarkParticipant] = []\n    self.__benchmark_page: str = (\n        f\"https://app.{self._openapi_service.environment}/mri/benchmarks/{self.id}\"\n    )\n    self._asset_uploader = AssetUploader(openapi_service)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/benchmark/rapidata_benchmark/#rapidata.rapidata_client.benchmark.rapidata_benchmark.RapidataBenchmark.prompts","title":"prompts  <code>property</code>","text":"<pre><code>prompts: list[str | None]\n</code></pre> <p>Returns the prompts that are registered for the leaderboard.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/benchmark/rapidata_benchmark/#rapidata.rapidata_client.benchmark.rapidata_benchmark.RapidataBenchmark.prompt_assets","title":"prompt_assets  <code>property</code>","text":"<pre><code>prompt_assets: list[str | None]\n</code></pre> <p>Returns the prompt assets that are registered for the benchmark.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/benchmark/rapidata_benchmark/#rapidata.rapidata_client.benchmark.rapidata_benchmark.RapidataBenchmark.tags","title":"tags  <code>property</code>","text":"<pre><code>tags: list[list[str]]\n</code></pre> <p>Returns the tags that are registered for the benchmark.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/benchmark/rapidata_benchmark/#rapidata.rapidata_client.benchmark.rapidata_benchmark.RapidataBenchmark.leaderboards","title":"leaderboards  <code>property</code>","text":"<pre><code>leaderboards: list[RapidataLeaderboard]\n</code></pre> <p>Returns the leaderboards that are registered for the benchmark.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/benchmark/rapidata_benchmark/#rapidata.rapidata_client.benchmark.rapidata_benchmark.RapidataBenchmark.participants","title":"participants  <code>property</code>","text":"<pre><code>participants: list[BenchmarkParticipant]\n</code></pre> <p>Returns the participants that are registered for the benchmark.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/benchmark/rapidata_benchmark/#rapidata.rapidata_client.benchmark.rapidata_benchmark.RapidataBenchmark.add_prompt","title":"add_prompt","text":"<pre><code>add_prompt(\n    identifier: str | None = None,\n    prompt: str | None = None,\n    prompt_asset: str | None = None,\n    tags: Optional[list[str]] = None,\n)\n</code></pre> <p>Adds a prompt to the benchmark.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>str | None</code> <p>The identifier of the prompt/asset/tags that will be used to match up the media. If not provided, it will use the prompt, asset or prompt + asset as the identifier.</p> <code>None</code> <code>prompt</code> <code>str | None</code> <p>The prompt that will be used to evaluate the model.</p> <code>None</code> <code>prompt_asset</code> <code>str | None</code> <p>The prompt asset that will be used to evaluate the model. Provided as a link to the asset.</p> <code>None</code> <code>tags</code> <code>Optional[list[str]]</code> <p>The tags can be used to filter the leaderboard results. They will NOT be shown to the users.</p> <code>None</code> Source code in <code>src/rapidata/rapidata_client/benchmark/rapidata_benchmark.py</code> <pre><code>def add_prompt(\n    self,\n    identifier: str | None = None,\n    prompt: str | None = None,\n    prompt_asset: str | None = None,\n    tags: Optional[list[str]] = None,\n):\n    \"\"\"\n    Adds a prompt to the benchmark.\n\n    Args:\n        identifier: The identifier of the prompt/asset/tags that will be used to match up the media. If not provided, it will use the prompt, asset or prompt + asset as the identifier.\n        prompt: The prompt that will be used to evaluate the model.\n        prompt_asset: The prompt asset that will be used to evaluate the model. Provided as a link to the asset.\n        tags: The tags can be used to filter the leaderboard results. They will NOT be shown to the users.\n    \"\"\"\n    from rapidata.api_client.models.submit_prompt_model import SubmitPromptModel\n    from rapidata.api_client.models.i_asset_input_existing_asset_input import (\n        IAssetInputExistingAssetInput,\n    )\n\n    from rapidata.api_client.models.i_asset_input import IAssetInput\n\n    with tracer.start_as_current_span(\"RapidataBenchmark.add_prompt_to_benchmark\"):\n        if tags is None:\n            tags = []\n\n        if prompt is None and prompt_asset is None:\n            raise ValueError(\"Prompt or prompt asset must be provided.\")\n\n        if identifier is None and prompt is None:\n            raise ValueError(\"Identifier or prompt must be provided.\")\n\n        if identifier and not isinstance(identifier, str):\n            raise ValueError(\"Identifier must be a string.\")\n\n        if prompt and not isinstance(prompt, str):\n            raise ValueError(\"Prompt must be a string.\")\n\n        if prompt_asset and not isinstance(prompt_asset, str):\n            raise ValueError(\n                \"Asset must be a string. That is the link to the asset.\"\n            )\n\n        if identifier is None:\n            assert prompt is not None\n            if prompt in self.prompts:\n                raise ValueError(\n                    \"Prompts must be unique. Otherwise use identifiers.\"\n                )\n            identifier = prompt\n\n        if identifier in self.identifiers:\n            raise ValueError(\"Identifier already exists in the benchmark.\")\n\n        if tags is not None and (\n            not isinstance(tags, list)\n            or not all(isinstance(tag, str) for tag in tags)\n        ):\n            raise ValueError(\"Tags must be a list of strings.\")\n\n        logger.info(\n            \"Adding identifier %s with prompt %s, prompt asset %s and tags %s to benchmark %s\",\n            identifier,\n            prompt,\n            prompt_asset,\n            tags,\n            self.id,\n        )\n\n        self.__identifiers.append(identifier)\n\n        self.__tags.append(tags)\n        self.__prompts.append(prompt)\n        self.__prompt_assets.append(prompt_asset)\n\n        self._openapi_service.benchmark_api.benchmark_benchmark_id_prompt_post(\n            benchmark_id=self.id,\n            submit_prompt_model=SubmitPromptModel(\n                identifier=identifier,\n                prompt=prompt,\n                promptAsset=(\n                    IAssetInput(\n                        actual_instance=(\n                            IAssetInputExistingAssetInput(\n                                _t=\"ExistingAssetInput\",\n                                name=self._asset_uploader.upload_asset(\n                                    prompt_asset\n                                ),\n                            )\n                            if prompt_asset is not None\n                            else None\n                        )\n                    )\n                    if prompt_asset is not None\n                    else None\n                ),\n                tags=tags,\n            ),\n        )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/benchmark/rapidata_benchmark/#rapidata.rapidata_client.benchmark.rapidata_benchmark.RapidataBenchmark.create_leaderboard","title":"create_leaderboard","text":"<pre><code>create_leaderboard(\n    name: str,\n    instruction: str,\n    show_prompt: bool = False,\n    show_prompt_asset: bool = False,\n    inverse_ranking: bool = False,\n    level_of_detail: LevelOfDetail | None = None,\n    min_responses_per_matchup: int | None = None,\n    validation_set_id: str | None = None,\n    filters: Sequence[\"RapidataFilter\"] | None = None,\n    settings: Sequence[\"RapidataSetting\"] | None = None,\n) -&gt; RapidataLeaderboard\n</code></pre> <p>Creates a new leaderboard for the benchmark.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the leaderboard. (not shown to the users)</p> required <code>instruction</code> <code>str</code> <p>The instruction decides how the models will be evaluated.</p> required <code>show_prompt</code> <code>bool</code> <p>Whether to show the prompt to the users. (default: False)</p> <code>False</code> <code>show_prompt_asset</code> <code>bool</code> <p>Whether to show the prompt asset to the users. (only works if the prompt asset is a URL) (default: False)</p> <code>False</code> <code>inverse_ranking</code> <code>bool</code> <p>Whether to inverse the ranking of the leaderboard. (if the question is inversed, e.g. \"Which video is worse?\")</p> <code>False</code> <code>level_of_detail</code> <code>LevelOfDetail | None</code> <p>The level of detail of the leaderboard. This will effect how many comparisons are done per model evaluation. (default: \"low\")</p> <code>None</code> <code>min_responses_per_matchup</code> <code>int | None</code> <p>The minimum number of responses required to be considered for the leaderboard. (default: 3)</p> <code>None</code> <code>validation_set_id</code> <code>str | None</code> <p>The id of the validation set that should be attached to the leaderboard. (default: None)</p> <code>None</code> <code>filters</code> <code>Sequence['RapidataFilter'] | None</code> <p>The filters that should be applied to the leaderboard. Will determine who can solve answer in the leaderboard. (default: [])</p> <code>None</code> <code>settings</code> <code>Sequence['RapidataSetting'] | None</code> <p>The settings that should be applied to the leaderboard. Will determine the behavior of the tasks on the leaderboard. (default: [])</p> <code>None</code> Source code in <code>src/rapidata/rapidata_client/benchmark/rapidata_benchmark.py</code> <pre><code>def create_leaderboard(\n    self,\n    name: str,\n    instruction: str,\n    show_prompt: bool = False,\n    show_prompt_asset: bool = False,\n    inverse_ranking: bool = False,\n    level_of_detail: LevelOfDetail | None = None,\n    min_responses_per_matchup: int | None = None,\n    validation_set_id: str | None = None,\n    filters: Sequence[\"RapidataFilter\"] | None = None,\n    settings: Sequence[\"RapidataSetting\"] | None = None,\n) -&gt; RapidataLeaderboard:\n    \"\"\"\n    Creates a new leaderboard for the benchmark.\n\n    Args:\n        name: The name of the leaderboard. (not shown to the users)\n        instruction: The instruction decides how the models will be evaluated.\n        show_prompt: Whether to show the prompt to the users. (default: False)\n        show_prompt_asset: Whether to show the prompt asset to the users. (only works if the prompt asset is a URL) (default: False)\n        inverse_ranking: Whether to inverse the ranking of the leaderboard. (if the question is inversed, e.g. \"Which video is worse?\")\n        level_of_detail: The level of detail of the leaderboard. This will effect how many comparisons are done per model evaluation. (default: \"low\")\n        min_responses_per_matchup: The minimum number of responses required to be considered for the leaderboard. (default: 3)\n        validation_set_id: The id of the validation set that should be attached to the leaderboard. (default: None)\n        filters: The filters that should be applied to the leaderboard. Will determine who can solve answer in the leaderboard. (default: [])\n        settings: The settings that should be applied to the leaderboard. Will determine the behavior of the tasks on the leaderboard. (default: [])\n    \"\"\"\n    from rapidata.api_client.models.create_leaderboard_model import (\n        CreateLeaderboardModel,\n    )\n    from rapidata.rapidata_client.benchmark._detail_mapper import DetailMapper\n    from rapidata.rapidata_client.benchmark.leaderboard.rapidata_leaderboard import (\n        RapidataLeaderboard,\n    )\n\n    with tracer.start_as_current_span(\"RapidataBenchmark.create_leaderboard\"):\n        if level_of_detail is not None and (\n            not isinstance(level_of_detail, str)\n            or level_of_detail not in [\"low\", \"medium\", \"high\", \"very high\"]\n        ):\n            raise ValueError(\n                \"Level of detail must be a string and one of: 'low', 'medium', 'high', 'very high'\"\n            )\n\n        if min_responses_per_matchup is not None and (\n            not isinstance(min_responses_per_matchup, int)\n            or min_responses_per_matchup &lt; 3\n        ):\n            raise ValueError(\n                \"Min responses per matchup must be an integer and at least 3\"\n            )\n\n        logger.info(\n            \"Creating leaderboard %s with instruction %s, show_prompt %s, show_prompt_asset %s, inverse_ranking %s, level_of_detail %s, min_responses_per_matchup %s, validation_set_id %s, filters %s, settings %s\",\n            name,\n            instruction,\n            show_prompt,\n            show_prompt_asset,\n            inverse_ranking,\n            level_of_detail,\n            min_responses_per_matchup,\n            validation_set_id,\n            filters,\n            settings,\n        )\n\n        leaderboard_result = self._openapi_service.leaderboard_api.leaderboard_post(\n            create_leaderboard_model=CreateLeaderboardModel(\n                benchmarkId=self.id,\n                name=name,\n                instruction=instruction,\n                showPrompt=show_prompt,\n                showPromptAsset=show_prompt_asset,\n                isInversed=inverse_ranking,\n                minResponses=min_responses_per_matchup,\n                responseBudget=(\n                    DetailMapper.get_budget(level_of_detail)\n                    if level_of_detail is not None\n                    else None\n                ),\n                validationSetId=validation_set_id,\n                filters=(\n                    [filter._to_model() for filter in filters] if filters else None\n                ),\n                featureFlags=(\n                    [setting._to_feature_flag() for setting in settings]  # type: ignore - until backend fixes generation\n                    if settings\n                    else None\n                ),\n            )\n        )\n\n        assert (\n            leaderboard_result.benchmark_id == self.id\n        ), \"The leaderboard was not created for the correct benchmark.\"\n\n        logger.info(\"Leaderboard created with id %s\", leaderboard_result.id)\n\n        return RapidataLeaderboard(\n            name,\n            instruction,\n            show_prompt,\n            show_prompt_asset,\n            inverse_ranking,\n            leaderboard_result.response_budget,\n            leaderboard_result.min_responses,\n            self.id,\n            leaderboard_result.id,\n            self._openapi_service,\n        )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/benchmark/rapidata_benchmark/#rapidata.rapidata_client.benchmark.rapidata_benchmark.RapidataBenchmark.evaluate_model","title":"evaluate_model","text":"<pre><code>evaluate_model(\n    name: str,\n    media: list[str],\n    identifiers: list[str] | None = None,\n    prompts: list[str] | None = None,\n) -&gt; None\n</code></pre> <p>Evaluates a model on the benchmark across all leaderboards.</p> <p>prompts or identifiers must be provided to match the media.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the model.</p> required <code>media</code> <code>list[str]</code> <p>The generated images/videos that will be used to evaluate the model.</p> required <code>identifiers</code> <code>list[str] | None</code> <p>The identifiers that correspond to the media. The order of the identifiers must match the order of the media.</p> <p>The identifiers that are used must be registered for the benchmark. To see the registered identifiers, use the identifiers property.</p> <code>None</code> <code>prompts</code> <code>list[str] | None</code> <p>The prompts that correspond to the media. The order of the prompts must match the order of the media.</p> <code>None</code> Source code in <code>src/rapidata/rapidata_client/benchmark/rapidata_benchmark.py</code> <pre><code>def evaluate_model(\n    self,\n    name: str,\n    media: list[str],\n    identifiers: list[str] | None = None,\n    prompts: list[str] | None = None,\n) -&gt; None:\n    \"\"\"\n    Evaluates a model on the benchmark across all leaderboards.\n\n    prompts or identifiers must be provided to match the media.\n\n    Args:\n        name: The name of the model.\n        media: The generated images/videos that will be used to evaluate the model.\n        identifiers: The identifiers that correspond to the media. The order of the identifiers must match the order of the media.\\n\n            The identifiers that are used must be registered for the benchmark. To see the registered identifiers, use the identifiers property.\n        prompts: The prompts that correspond to the media. The order of the prompts must match the order of the media.\n    \"\"\"\n    with tracer.start_as_current_span(\"RapidataBenchmark.evaluate_model\"):\n        participant = self.add_model(\n            name=name,\n            media=media,\n            identifiers=identifiers,\n            prompts=prompts,\n        )\n        participant.run()\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/benchmark/rapidata_benchmark/#rapidata.rapidata_client.benchmark.rapidata_benchmark.RapidataBenchmark.add_model","title":"add_model","text":"<pre><code>add_model(\n    name: str,\n    media: list[str],\n    identifiers: list[str] | None = None,\n    prompts: list[str] | None = None,\n) -&gt; BenchmarkParticipant\n</code></pre> <p>Adds a model to the benchmark without immediately submitting it for evaluation.</p> <p>This method creates a participant, uploads media, but does NOT submit the participant. Use <code>participant.run()</code> or <code>benchmark.run()</code> to submit afterwards.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the model.</p> required <code>media</code> <code>list[str]</code> <p>The generated images/videos that will be used to evaluate the model.</p> required <code>identifiers</code> <code>list[str] | None</code> <p>The identifiers that correspond to the media. The order of the identifiers must match the order of the media.</p> <p>The identifiers that are used must be registered for the benchmark. To see the registered identifiers, use the identifiers property.</p> <code>None</code> <code>prompts</code> <code>list[str] | None</code> <p>The prompts that correspond to the media. The order of the prompts must match the order of the media.</p> <code>None</code> <p>Returns:</p> Type Description <code>BenchmarkParticipant</code> <p>The created BenchmarkParticipant instance.</p> Source code in <code>src/rapidata/rapidata_client/benchmark/rapidata_benchmark.py</code> <pre><code>def add_model(\n    self,\n    name: str,\n    media: list[str],\n    identifiers: list[str] | None = None,\n    prompts: list[str] | None = None,\n) -&gt; BenchmarkParticipant:\n    \"\"\"Adds a model to the benchmark without immediately submitting it for evaluation.\n\n    This method creates a participant, uploads media, but does NOT submit the participant.\n    Use `participant.run()` or `benchmark.run()` to submit afterwards.\n\n    Args:\n        name: The name of the model.\n        media: The generated images/videos that will be used to evaluate the model.\n        identifiers: The identifiers that correspond to the media. The order of the identifiers must match the order of the media.\\n\n            The identifiers that are used must be registered for the benchmark. To see the registered identifiers, use the identifiers property.\n        prompts: The prompts that correspond to the media. The order of the prompts must match the order of the media.\n\n    Returns:\n        The created BenchmarkParticipant instance.\n    \"\"\"\n    from rapidata.api_client.models.create_benchmark_participant_model import (\n        CreateBenchmarkParticipantModel,\n    )\n    from rapidata.rapidata_client.benchmark.participant.participant import (\n        BenchmarkParticipant,\n    )\n\n    with tracer.start_as_current_span(\"RapidataBenchmark.add_model\"):\n        if not media:\n            raise ValueError(\"Media must be a non-empty list of strings\")\n\n        if not identifiers and not prompts:\n            raise ValueError(\"Identifiers or prompts must be provided.\")\n\n        if identifiers and prompts:\n            raise ValueError(\n                \"Identifiers and prompts cannot be provided at the same time. Use one or the other.\"\n            )\n\n        if not identifiers:\n            assert prompts is not None\n            identifiers = prompts\n\n        if len(media) != len(identifiers):\n            raise ValueError(\n                \"Media and identifiers/prompts must have the same length\"\n            )\n\n        if not all(identifier in self.identifiers for identifier in identifiers):\n            raise ValueError(\n                \"All identifiers/prompts must be in the registered identifiers/prompts list. To see the registered identifiers/prompts, use the identifiers/prompts property.\"\n            )\n\n        participant_result = self._openapi_service.benchmark_api.benchmark_benchmark_id_participants_post(\n            benchmark_id=self.id,\n            create_benchmark_participant_model=CreateBenchmarkParticipantModel(\n                name=name,\n            ),\n        )\n\n        logger.info(f\"Participant created: {participant_result.participant_id}\")\n\n        participant = BenchmarkParticipant(\n            name,\n            participant_result.participant_id,\n            self._openapi_service,\n        )\n\n        with tracer.start_as_current_span(\"upload_media_for_participant\"):\n            logger.info(\n                f\"Uploading {len(media)} media assets to participant {participant.id}\"\n            )\n\n            successful_uploads, failed_uploads = participant.upload_media(\n                media,\n                identifiers,\n            )\n\n            total_uploads = len(media)\n            success_rate = (\n                (len(successful_uploads) / total_uploads * 100)\n                if total_uploads &gt; 0\n                else 0\n            )\n            logger.info(\n                f\"Upload complete: {len(successful_uploads)} successful, {len(failed_uploads)} failed ({success_rate:.1f}% success rate)\"\n            )\n\n            if failed_uploads:\n                logger.error(f\"Failed uploads for media: {failed_uploads}\")\n                logger.warning(\n                    \"Some uploads failed. The model evaluation may be incomplete.\"\n                )\n\n            if len(successful_uploads) == 0:\n                raise RuntimeError(\n                    \"No uploads were successful. The model evaluation will not be completed.\"\n                )\n\n        # Clear cache so next access re-fetches\n        self.__participants = []\n\n        return participant\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/benchmark/rapidata_benchmark/#rapidata.rapidata_client.benchmark.rapidata_benchmark.RapidataBenchmark.run","title":"run","text":"<pre><code>run() -&gt; None\n</code></pre> <p>Submits all participants that are in <code>CREATED</code> state.</p> <p>This is a convenience method to submit all unsubmitted participants at once.</p> Source code in <code>src/rapidata/rapidata_client/benchmark/rapidata_benchmark.py</code> <pre><code>def run(self) -&gt; None:\n    \"\"\"Submits all participants that are in `CREATED` state.\n\n    This is a convenience method to submit all unsubmitted participants at once.\n    \"\"\"\n    from rapidata.api_client.models.participant_status import ParticipantStatus\n\n    with tracer.start_as_current_span(\"RapidataBenchmark.run\"):\n        created = [\n            p for p in self.participants if p.status == ParticipantStatus.CREATED\n        ]\n        logger.info(f\"Submitting {len(created)} participants in CREATED state\")\n        for participant in created:\n            participant.run()\n\n        # Clear cache so next access re-fetches\n        self.__participants = []\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/benchmark/rapidata_benchmark/#rapidata.rapidata_client.benchmark.rapidata_benchmark.RapidataBenchmark.view","title":"view","text":"<pre><code>view() -&gt; None\n</code></pre> <p>Views the benchmark.</p> Source code in <code>src/rapidata/rapidata_client/benchmark/rapidata_benchmark.py</code> <pre><code>def view(self) -&gt; None:\n    \"\"\"\n    Views the benchmark.\n    \"\"\"\n\n    logger.info(\"Opening benchmark page in browser...\")\n    could_open_browser = webbrowser.open(self.__benchmark_page)\n    if not could_open_browser:\n        encoded_url = urllib.parse.quote(\n            self.__benchmark_page, safe=\"%/:=&amp;?~#+!$,;'@()*[]\"\n        )\n        managed_print(\n            Fore.RED\n            + f\"Please open this URL in your browser: '{encoded_url}'\"\n            + Fore.RESET\n        )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/benchmark/rapidata_benchmark/#rapidata.rapidata_client.benchmark.rapidata_benchmark.RapidataBenchmark.get_overall_standings","title":"get_overall_standings","text":"<pre><code>get_overall_standings(\n    tags: Optional[list[str]] = None,\n) -&gt; DataFrame\n</code></pre> <p>Returns an aggregated elo table of all leaderboards in the benchmark.</p> Source code in <code>src/rapidata/rapidata_client/benchmark/rapidata_benchmark.py</code> <pre><code>def get_overall_standings(self, tags: Optional[list[str]] = None) -&gt; pd.DataFrame:\n    \"\"\"\n    Returns an aggregated elo table of all leaderboards in the benchmark.\n    \"\"\"\n    import pandas as pd\n\n    with tracer.start_as_current_span(\"get_overall_standings\"):\n        participants = self._openapi_service.benchmark_api.benchmark_benchmark_id_standings_get(\n            benchmark_id=self.id,\n            tags=tags,\n        )\n\n        standings = []\n        for participant in participants.items:\n            standings.append(\n                {\n                    \"name\": participant.name,\n                    \"wins\": participant.wins,\n                    \"total_matches\": participant.total_matches,\n                    \"score\": (\n                        round(participant.score, 2)\n                        if participant.score is not None\n                        else None\n                    ),\n                }\n            )\n\n        return pd.DataFrame(standings)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/benchmark/rapidata_benchmark/#rapidata.rapidata_client.benchmark.rapidata_benchmark.RapidataBenchmark.get_win_loss_matrix","title":"get_win_loss_matrix","text":"<pre><code>get_win_loss_matrix(\n    tags: Optional[list[str]] = None,\n    participant_ids: Optional[list[str]] = None,\n    leaderboard_ids: Optional[list[str]] = None,\n    use_weighted_scoring: Optional[bool] = None,\n) -&gt; DataFrame\n</code></pre> <p>Returns the win/loss matrix for all participants across all leaderboards in the benchmark.</p> <p>The matrix shows pairwise comparison results where each cell [i, j] represents the number of wins participant i has against participant j.</p> <p>Parameters:</p> Name Type Description Default <code>tags</code> <code>Optional[list[str]]</code> <p>Filter matchups by these tags. If None, all matchups are considered.</p> <code>None</code> <code>participant_ids</code> <code>Optional[list[str]]</code> <p>Filter to only include these participants.</p> <code>None</code> <code>leaderboard_ids</code> <code>Optional[list[str]]</code> <p>Filter to only include matchups from these leaderboards.</p> <code>None</code> <code>use_weighted_scoring</code> <code>Optional[bool]</code> <p>Whether to use weighted scoring for the matrix calculation.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A pandas DataFrame with participants as both index and columns,</p> <code>DataFrame</code> <p>containing the pairwise win counts.</p> Source code in <code>src/rapidata/rapidata_client/benchmark/rapidata_benchmark.py</code> <pre><code>def get_win_loss_matrix(\n    self,\n    tags: Optional[list[str]] = None,\n    participant_ids: Optional[list[str]] = None,\n    leaderboard_ids: Optional[list[str]] = None,\n    use_weighted_scoring: Optional[bool] = None,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Returns the win/loss matrix for all participants across all leaderboards in the benchmark.\n\n    The matrix shows pairwise comparison results where each cell [i, j] represents\n    the number of wins participant i has against participant j.\n\n    Args:\n        tags: Filter matchups by these tags. If None, all matchups are considered.\n        participant_ids: Filter to only include these participants.\n        leaderboard_ids: Filter to only include matchups from these leaderboards.\n        use_weighted_scoring: Whether to use weighted scoring for the matrix calculation.\n\n    Returns:\n        A pandas DataFrame with participants as both index and columns,\n        containing the pairwise win counts.\n    \"\"\"\n    import pandas as pd\n\n    with tracer.start_as_current_span(\"get_win_loss_matrix\"):\n        result = (\n            self._openapi_service.benchmark_api.benchmark_benchmark_id_matrix_get(\n                benchmark_id=self.id,\n                tags=tags,\n                participant_ids=participant_ids,\n                leaderboard_ids=leaderboard_ids,\n                use_weighted_scoring=use_weighted_scoring,\n            )\n        )\n\n        return pd.DataFrame(\n            data=result.data,\n            index=pd.Index(result.index),\n            columns=pd.Index(result.columns),\n        )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/benchmark/rapidata_benchmark_manager/","title":"Rapidata benchmark manager","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/benchmark/rapidata_benchmark_manager/#rapidata.rapidata_client.benchmark.rapidata_benchmark_manager.RapidataBenchmarkManager","title":"RapidataBenchmarkManager","text":"<pre><code>RapidataBenchmarkManager(openapi_service: OpenAPIService)\n</code></pre> <p>A manager for benchmarks.</p> <p>Used to create and retrieve benchmarks.</p> <p>A benchmark is a collection of leaderboards.</p> Source code in <code>src/rapidata/rapidata_client/benchmark/rapidata_benchmark_manager.py</code> <pre><code>def __init__(self, openapi_service: OpenAPIService):\n    self.__openapi_service = openapi_service\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/benchmark/rapidata_benchmark_manager/#rapidata.rapidata_client.benchmark.rapidata_benchmark_manager.RapidataBenchmarkManager.create_new_benchmark","title":"create_new_benchmark","text":"<pre><code>create_new_benchmark(\n    name: str,\n    identifiers: Optional[list[str]] = None,\n    prompts: Optional[list[str | None] | list[str]] = None,\n    prompt_assets: Optional[\n        list[str | None] | list[str]\n    ] = None,\n    tags: Optional[\n        list[list[str] | None] | list[list[str]]\n    ] = None,\n) -&gt; RapidataBenchmark\n</code></pre> <p>Creates a new benchmark with the given name, identifiers, prompts, and media assets. Everything is matched up by the indexes of the lists.</p> <p>prompts or identifiers must be provided, as well as prompts or prompt_assets.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the benchmark.</p> required <code>identifiers</code> <code>Optional[list[str]]</code> <p>The identifiers of the prompts/assets/tags that will be used to match up the media. If not provided, it will use the prompts as the identifiers.</p> <code>None</code> <code>prompts</code> <code>Optional[list[str | None] | list[str]]</code> <p>The prompts that will be registered for the benchmark.</p> <code>None</code> <code>prompt_assets</code> <code>Optional[list[str | None] | list[str]]</code> <p>The prompt assets that will be registered for the benchmark.</p> <code>None</code> <code>tags</code> <code>Optional[list[list[str] | None] | list[list[str]]]</code> <p>The tags that will be associated with the prompts to use for filtering the leaderboard results. They will NOT be shown to the users.</p> <code>None</code> Example <pre><code>name = \"Example Benchmark\"\nidentifiers = [\"id1\", \"id2\", \"id3\"]\nprompts = [\"prompt 1\", \"prompt 2\", \"prompt 3\"]\nprompt_assets = [\"https://assets.rapidata.ai/prompt_1.jpg\", \"https://assets.rapidata.ai/prompt_2.jpg\", \"https://assets.rapidata.ai/prompt_3.jpg\"]\ntags = [[\"tag1\", \"tag2\"], [\"tag2\"], [\"tag2\", \"tag3\"]]\n\nbenchmark = create_new_benchmark(name=name, identifiers=identifiers, prompts=prompts, prompt_assets=prompt_assets, tags=tags)\n</code></pre> Source code in <code>src/rapidata/rapidata_client/benchmark/rapidata_benchmark_manager.py</code> <pre><code>def create_new_benchmark(\n    self,\n    name: str,\n    identifiers: Optional[list[str]] = None,\n    prompts: Optional[list[str | None] | list[str]] = None,\n    prompt_assets: Optional[list[str | None] | list[str]] = None,\n    tags: Optional[list[list[str] | None] | list[list[str]]] = None,\n) -&gt; RapidataBenchmark:\n    \"\"\"\n    Creates a new benchmark with the given name, identifiers, prompts, and media assets.\n    Everything is matched up by the indexes of the lists.\n\n    prompts or identifiers must be provided, as well as prompts or prompt_assets.\n\n    Args:\n        name: The name of the benchmark.\n        identifiers: The identifiers of the prompts/assets/tags that will be used to match up the media. If not provided, it will use the prompts as the identifiers.\n        prompts: The prompts that will be registered for the benchmark.\n        prompt_assets: The prompt assets that will be registered for the benchmark.\n        tags: The tags that will be associated with the prompts to use for filtering the leaderboard results. They will NOT be shown to the users.\n\n    Example:\n        ```python\n        name = \"Example Benchmark\"\n        identifiers = [\"id1\", \"id2\", \"id3\"]\n        prompts = [\"prompt 1\", \"prompt 2\", \"prompt 3\"]\n        prompt_assets = [\"https://assets.rapidata.ai/prompt_1.jpg\", \"https://assets.rapidata.ai/prompt_2.jpg\", \"https://assets.rapidata.ai/prompt_3.jpg\"]\n        tags = [[\"tag1\", \"tag2\"], [\"tag2\"], [\"tag2\", \"tag3\"]]\n\n        benchmark = create_new_benchmark(name=name, identifiers=identifiers, prompts=prompts, prompt_assets=prompt_assets, tags=tags)\n        ```\n    \"\"\"\n    with tracer.start_as_current_span(\n        \"RapidataBenchmarkManager.create_new_benchmark\"\n    ):\n        if not isinstance(name, str):\n            raise ValueError(\"Name must be a string.\")\n\n        if prompts and (\n            not isinstance(prompts, list)\n            or not all(\n                isinstance(prompt, str) or prompt is None for prompt in prompts\n            )\n        ):\n            raise ValueError(\"Prompts must be a list of strings or None.\")\n\n        if prompt_assets and (\n            not isinstance(prompt_assets, list)\n            or not all(\n                isinstance(asset, str) or asset is None for asset in prompt_assets\n            )\n        ):\n            raise ValueError(\"Media assets must be a list of strings or None.\")\n\n        if identifiers and (\n            not isinstance(identifiers, list)\n            or not all(isinstance(identifier, str) for identifier in identifiers)\n        ):\n            raise ValueError(\"Identifiers must be a list of strings.\")\n\n        if identifiers:\n            if not len(set(identifiers)) == len(identifiers):\n                raise ValueError(\"Identifiers must be unique.\")\n\n        if tags is not None:\n            if not isinstance(tags, list):\n                raise ValueError(\"Tags must be a list of lists of strings or None.\")\n\n            for tag in tags:\n                if tag is not None and (\n                    not isinstance(tag, list)\n                    or not all(isinstance(item, str) for item in tag)\n                ):\n                    raise ValueError(\n                        \"Tags must be a list of lists of strings or None.\"\n                    )\n\n        if not identifiers and not prompts:\n            raise ValueError(\n                \"At least one of identifiers or prompts must be provided.\"\n            )\n\n        if not prompts and not prompt_assets:\n            raise ValueError(\n                \"At least one of prompts or media assets must be provided.\"\n            )\n\n        if not identifiers:\n            assert prompts is not None\n            if not len(set(prompts)) == len(prompts):\n                raise ValueError(\n                    \"Prompts must be unique. Otherwise use identifiers.\"\n                )\n            if any(prompt is None for prompt in prompts):\n                raise ValueError(\n                    \"Prompts must not be None. Otherwise use identifiers.\"\n                )\n\n            identifiers = cast(list[str], prompts)\n\n        assert identifiers is not None\n\n        expected_length = len(identifiers)\n\n        if not prompts:\n            prompts = cast(list[str | None], [None] * expected_length)\n\n        if not prompt_assets:\n            prompt_assets = cast(list[str | None], [None] * expected_length)\n\n        if not tags:\n            tags = cast(list[list[str] | None], [None] * expected_length)\n\n        # At this point, all variables are guaranteed to be lists, not None\n        assert prompts is not None\n        assert prompt_assets is not None\n        assert tags is not None\n\n        if not (expected_length == len(prompts) == len(prompt_assets) == len(tags)):\n            raise ValueError(\n                \"Identifiers, prompts, media assets, and tags must have the same length or set to None.\"\n            )\n\n        logger.info(\"Creating new benchmark %s\", name)\n\n        benchmark_result = self.__openapi_service.benchmark_api.benchmark_post(\n            create_benchmark_model=CreateBenchmarkModel(\n                name=name,\n            )\n        )\n\n        logger.info(\"Benchmark created with id %s\", benchmark_result.id)\n\n        benchmark = RapidataBenchmark(\n            name, benchmark_result.id, self.__openapi_service\n        )\n\n        for identifier, prompt, asset, tag in zip(\n            identifiers, prompts, prompt_assets, tags\n        ):\n            benchmark.add_prompt(identifier, prompt, asset, tag)\n\n        return benchmark\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/benchmark/rapidata_benchmark_manager/#rapidata.rapidata_client.benchmark.rapidata_benchmark_manager.RapidataBenchmarkManager.get_benchmark_by_id","title":"get_benchmark_by_id","text":"<pre><code>get_benchmark_by_id(id: str) -&gt; RapidataBenchmark\n</code></pre> <p>Returns a benchmark by its ID.</p> Source code in <code>src/rapidata/rapidata_client/benchmark/rapidata_benchmark_manager.py</code> <pre><code>def get_benchmark_by_id(self, id: str) -&gt; RapidataBenchmark:\n    \"\"\"\n    Returns a benchmark by its ID.\n    \"\"\"\n    with tracer.start_as_current_span(\n        \"RapidataBenchmarkManager.get_benchmark_by_id\"\n    ):\n        benchmark_result = (\n            self.__openapi_service.benchmark_api.benchmark_benchmark_id_get(\n                benchmark_id=id\n            )\n        )\n        return RapidataBenchmark(\n            benchmark_result.name, benchmark_result.id, self.__openapi_service\n        )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/benchmark/rapidata_benchmark_manager/#rapidata.rapidata_client.benchmark.rapidata_benchmark_manager.RapidataBenchmarkManager.find_benchmarks","title":"find_benchmarks","text":"<pre><code>find_benchmarks(\n    name: str = \"\", amount: int = 10\n) -&gt; list[RapidataBenchmark]\n</code></pre> <p>Returns a list of benchmarks by their name.</p> Source code in <code>src/rapidata/rapidata_client/benchmark/rapidata_benchmark_manager.py</code> <pre><code>def find_benchmarks(\n    self, name: str = \"\", amount: int = 10\n) -&gt; list[RapidataBenchmark]:\n    \"\"\"\n    Returns a list of benchmarks by their name.\n    \"\"\"\n    with tracer.start_as_current_span(\"RapidataBenchmarkManager.find_benchmarks\"):\n        benchmark_result = self.__openapi_service.benchmark_api.benchmarks_get(\n            QueryModel(\n                page=PageInfo(index=1, size=amount),\n                filter=RootFilter(\n                    filters=[\n                        Filter(\n                            field=\"Name\",\n                            operator=FilterOperator.CONTAINS,\n                            value=name,\n                        )\n                    ]\n                ),\n                sortCriteria=[\n                    SortCriterion(\n                        direction=SortDirection.DESC, propertyName=\"CreatedAt\"\n                    )\n                ],\n            )\n        )\n        return [\n            RapidataBenchmark(benchmark.name, benchmark.id, self.__openapi_service)\n            for benchmark in benchmark_result.items\n        ]\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/benchmark/leaderboard/rapidata_leaderboard/","title":"Rapidata leaderboard","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/benchmark/leaderboard/rapidata_leaderboard/#rapidata.rapidata_client.benchmark.leaderboard.rapidata_leaderboard.RapidataLeaderboard","title":"RapidataLeaderboard","text":"<pre><code>RapidataLeaderboard(\n    name: str,\n    instruction: str,\n    show_prompt: bool,\n    show_prompt_asset: bool,\n    inverse_ranking: bool,\n    response_budget: int,\n    min_responses_per_matchup: int,\n    benchmark_id: str,\n    id: str,\n    openapi_service: OpenAPIService,\n)\n</code></pre> <p>An instance of a Rapidata leaderboard.</p> <p>Used to interact with a specific leaderboard in the Rapidata system, such as retrieving prompts and evaluating models.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name that will be used to identify the leaderboard on the overview.</p> required <code>instruction</code> <code>str</code> <p>The instruction that will determine what how the models will be evaluated.</p> required <code>show_prompt</code> <code>bool</code> <p>Whether to show the prompt to the users.</p> required <code>id</code> <code>str</code> <p>The ID of the leaderboard.</p> required <code>openapi_service</code> <code>OpenAPIService</code> <p>The OpenAPIService instance for API interaction.</p> required Source code in <code>src/rapidata/rapidata_client/benchmark/leaderboard/rapidata_leaderboard.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    instruction: str,\n    show_prompt: bool,\n    show_prompt_asset: bool,\n    inverse_ranking: bool,\n    response_budget: int,\n    min_responses_per_matchup: int,\n    benchmark_id: str,\n    id: str,\n    openapi_service: OpenAPIService,\n):\n    self.__openapi_service = openapi_service\n    self.__name = name\n    self.__instruction = instruction\n    self.__show_prompt = show_prompt\n    self.__show_prompt_asset = show_prompt_asset\n    self.__inverse_ranking = inverse_ranking\n    self.__response_budget = response_budget\n    self.__min_responses_per_matchup = min_responses_per_matchup\n    self.__benchmark_id = benchmark_id\n    self.id = id\n    self.__leaderboard_page = f\"https://app.{self.__openapi_service.environment}/mri/benchmarks/{self.__benchmark_id}/leaderboard/{self.id}\"\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/benchmark/leaderboard/rapidata_leaderboard/#rapidata.rapidata_client.benchmark.leaderboard.rapidata_leaderboard.RapidataLeaderboard.level_of_detail","title":"level_of_detail  <code>property</code> <code>writable</code>","text":"<pre><code>level_of_detail: LevelOfDetail\n</code></pre> <p>Returns the level of detail of the leaderboard.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/benchmark/leaderboard/rapidata_leaderboard/#rapidata.rapidata_client.benchmark.leaderboard.rapidata_leaderboard.RapidataLeaderboard.min_responses_per_matchup","title":"min_responses_per_matchup  <code>property</code> <code>writable</code>","text":"<pre><code>min_responses_per_matchup: int\n</code></pre> <p>Returns the minimum number of responses required to be considered for the leaderboard.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/benchmark/leaderboard/rapidata_leaderboard/#rapidata.rapidata_client.benchmark.leaderboard.rapidata_leaderboard.RapidataLeaderboard.show_prompt_asset","title":"show_prompt_asset  <code>property</code>","text":"<pre><code>show_prompt_asset: bool\n</code></pre> <p>Returns whether the prompt asset is shown to the users.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/benchmark/leaderboard/rapidata_leaderboard/#rapidata.rapidata_client.benchmark.leaderboard.rapidata_leaderboard.RapidataLeaderboard.inverse_ranking","title":"inverse_ranking  <code>property</code>","text":"<pre><code>inverse_ranking: bool\n</code></pre> <p>Returns whether the ranking is inverse.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/benchmark/leaderboard/rapidata_leaderboard/#rapidata.rapidata_client.benchmark.leaderboard.rapidata_leaderboard.RapidataLeaderboard.show_prompt","title":"show_prompt  <code>property</code>","text":"<pre><code>show_prompt: bool\n</code></pre> <p>Returns whether the prompt is shown to the users.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/benchmark/leaderboard/rapidata_leaderboard/#rapidata.rapidata_client.benchmark.leaderboard.rapidata_leaderboard.RapidataLeaderboard.instruction","title":"instruction  <code>property</code>","text":"<pre><code>instruction: str\n</code></pre> <p>Returns the instruction of the leaderboard.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/benchmark/leaderboard/rapidata_leaderboard/#rapidata.rapidata_client.benchmark.leaderboard.rapidata_leaderboard.RapidataLeaderboard.name","title":"name  <code>property</code> <code>writable</code>","text":"<pre><code>name: str\n</code></pre> <p>Returns the name of the leaderboard.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/benchmark/leaderboard/rapidata_leaderboard/#rapidata.rapidata_client.benchmark.leaderboard.rapidata_leaderboard.RapidataLeaderboard.get_standings","title":"get_standings","text":"<pre><code>get_standings(\n    tags: Optional[list[str]] = None,\n) -&gt; \"pd.DataFrame\"\n</code></pre> <p>Returns the standings of the leaderboard.</p> <p>Parameters:</p> Name Type Description Default <code>tags</code> <code>Optional[list[str]]</code> <p>The matchups with these tags should be used to create the standings. If tags are None, all matchups will be considered. If tags are empty, no matchups will be considered.</p> <code>None</code> <p>Returns:</p> Type Description <code>'pd.DataFrame'</code> <p>A pandas DataFrame containing the standings of the leaderboard.</p> Source code in <code>src/rapidata/rapidata_client/benchmark/leaderboard/rapidata_leaderboard.py</code> <pre><code>def get_standings(self, tags: Optional[list[str]] = None) -&gt; \"pd.DataFrame\":\n    \"\"\"\n    Returns the standings of the leaderboard.\n\n    Args:\n        tags: The matchups with these tags should be used to create the standings.\n            If tags are None, all matchups will be considered.\n            If tags are empty, no matchups will be considered.\n\n    Returns:\n        A pandas DataFrame containing the standings of the leaderboard.\n    \"\"\"\n    with tracer.start_as_current_span(\"RapidataLeaderboard.get_standings\"):\n        participants = self.__openapi_service.leaderboard_api.leaderboard_leaderboard_id_standings_get(\n            leaderboard_id=self.id, tags=tags\n        )\n\n        import pandas as pd\n\n        standings = []\n        for participant in participants.items:\n            standings.append(\n                {\n                    \"name\": participant.name,\n                    \"wins\": participant.wins,\n                    \"total_matches\": participant.total_matches,\n                    \"score\": (\n                        round(participant.score, 2)\n                        if participant.score is not None\n                        else None\n                    ),\n                }\n            )\n\n        return pd.DataFrame(standings)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/benchmark/leaderboard/rapidata_leaderboard/#rapidata.rapidata_client.benchmark.leaderboard.rapidata_leaderboard.RapidataLeaderboard.get_win_loss_matrix","title":"get_win_loss_matrix","text":"<pre><code>get_win_loss_matrix(\n    tags: Optional[list[str]] = None,\n    use_weighted_scoring: Optional[bool] = None,\n) -&gt; DataFrame\n</code></pre> <p>Returns the win/loss matrix for all participants in this leaderboard.</p> <p>The matrix shows pairwise comparison results where each cell [i, j] represents the number of wins participant i has against participant j.</p> <p>Parameters:</p> Name Type Description Default <code>tags</code> <code>Optional[list[str]]</code> <p>Filter matchups by these tags. If None, all matchups are considered.</p> <code>None</code> <code>use_weighted_scoring</code> <code>Optional[bool]</code> <p>Whether to use weighted scoring for the matrix calculation.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A pandas DataFrame with participants as both index and columns,</p> <code>DataFrame</code> <p>containing the pairwise win counts.</p> Source code in <code>src/rapidata/rapidata_client/benchmark/leaderboard/rapidata_leaderboard.py</code> <pre><code>def get_win_loss_matrix(\n    self,\n    tags: Optional[list[str]] = None,\n    use_weighted_scoring: Optional[bool] = None,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Returns the win/loss matrix for all participants in this leaderboard.\n\n    The matrix shows pairwise comparison results where each cell [i, j] represents\n    the number of wins participant i has against participant j.\n\n    Args:\n        tags: Filter matchups by these tags. If None, all matchups are considered.\n        use_weighted_scoring: Whether to use weighted scoring for the matrix calculation.\n\n    Returns:\n        A pandas DataFrame with participants as both index and columns,\n        containing the pairwise win counts.\n    \"\"\"\n    with tracer.start_as_current_span(\"RapidataLeaderboard.get_win_loss_matrix\"):\n        result = self.__openapi_service.leaderboard_api.leaderboard_leaderboard_id_matrix_get(\n            leaderboard_id=self.id,\n            tags=tags,\n            use_weighted_scoring=use_weighted_scoring,\n        )\n\n        import pandas as pd\n\n        return pd.DataFrame(\n            data=result.data,\n            index=pd.Index(result.index),\n            columns=pd.Index(result.columns),\n        )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/benchmark/leaderboard/rapidata_leaderboard/#rapidata.rapidata_client.benchmark.leaderboard.rapidata_leaderboard.RapidataLeaderboard.view","title":"view","text":"<pre><code>view() -&gt; None\n</code></pre> <p>Views the leaderboard.</p> Source code in <code>src/rapidata/rapidata_client/benchmark/leaderboard/rapidata_leaderboard.py</code> <pre><code>def view(self) -&gt; None:\n    \"\"\"\n    Views the leaderboard.\n    \"\"\"\n    logger.info(\"Opening leaderboard page in browser...\")\n    could_open_browser = webbrowser.open(self.__leaderboard_page)\n    if not could_open_browser:\n        encoded_url = urllib.parse.quote(\n            self.__leaderboard_page, safe=\"%/:=&amp;?~#+!$,;'@()*[]\"\n        )\n        managed_print(\n            Fore.RED\n            + f\"Please open this URL in your browser: '{encoded_url}'\"\n            + Fore.RESET\n        )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/benchmark/participant/participant/","title":"Participant","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/benchmark/participant/participant/#rapidata.rapidata_client.benchmark.participant.participant.BenchmarkParticipant","title":"BenchmarkParticipant","text":"<pre><code>BenchmarkParticipant(\n    name: str,\n    id: str,\n    openapi_service: OpenAPIService,\n    status: ParticipantStatus = CREATED,\n)\n</code></pre> <p>A participant (model) in a benchmark evaluation.</p> <p>Represents a model that has been added to a benchmark for evaluation. Provides methods to upload media and submit the participant for evaluation.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the participant/model.</p> required <code>id</code> <code>str</code> <p>The unique identifier of the participant.</p> required <code>openapi_service</code> <code>OpenAPIService</code> <p>The OpenAPI service for API communication.</p> required <code>status</code> <code>ParticipantStatus</code> <p>The current status of the participant.</p> <code>CREATED</code> Source code in <code>src/rapidata/rapidata_client/benchmark/participant/participant.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    id: str,\n    openapi_service: OpenAPIService,\n    status: ParticipantStatus = ParticipantStatus.CREATED,\n):\n    self.name = name\n    self.id = id\n    self._openapi_service = openapi_service\n    self._asset_uploader = AssetUploader(openapi_service)\n    self._status = status\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/benchmark/participant/participant/#rapidata.rapidata_client.benchmark.participant.participant.BenchmarkParticipant.status","title":"status  <code>property</code>","text":"<pre><code>status: ParticipantStatus\n</code></pre> <p>The current status of the participant.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/benchmark/participant/participant/#rapidata.rapidata_client.benchmark.participant.participant.BenchmarkParticipant.run","title":"run","text":"<pre><code>run() -&gt; None\n</code></pre> <p>Submits the participant for evaluation.</p> <p>After uploading media, call this method to submit the participant so that it enters the evaluation pipeline.</p> Source code in <code>src/rapidata/rapidata_client/benchmark/participant/participant.py</code> <pre><code>def run(self) -&gt; None:\n    \"\"\"Submits the participant for evaluation.\n\n    After uploading media, call this method to submit the participant\n    so that it enters the evaluation pipeline.\n    \"\"\"\n    self._openapi_service.participant_api.participants_participant_id_submit_post(\n        participant_id=self.id\n    )\n    self._status = ParticipantStatus.SUBMITTED\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/benchmark/participant/participant/#rapidata.rapidata_client.benchmark.participant.participant.BenchmarkParticipant.upload_media","title":"upload_media","text":"<pre><code>upload_media(\n    assets: list[str], identifiers: list[str]\n) -&gt; tuple[list[str], list[str]]\n</code></pre> <p>Upload samples concurrently with proper error handling and progress tracking.</p> <p>Parameters:</p> Name Type Description Default <code>assets</code> <code>list[str]</code> <p>List of strings to upload</p> required <code>identifiers</code> <code>list[str]</code> <p>List of identifiers matching the assets</p> required <p>Returns:</p> Type Description <code>tuple[list[str], list[str]]</code> <p>tuple[list[str], list[str]]: Lists of successful and failed identifiers</p> Source code in <code>src/rapidata/rapidata_client/benchmark/participant/participant.py</code> <pre><code>def upload_media(\n    self,\n    assets: list[str],\n    identifiers: list[str],\n) -&gt; tuple[list[str], list[str]]:\n    \"\"\"\n    Upload samples concurrently with proper error handling and progress tracking.\n\n    Args:\n        assets: List of strings to upload\n        identifiers: List of identifiers matching the assets\n\n    Returns:\n        tuple[list[str], list[str]]: Lists of successful and failed identifiers\n    \"\"\"\n\n    def upload_with_context(\n        context: otel_context.Context, asset: str, identifier: str\n    ) -&gt; tuple[str | None, str | None]:\n        \"\"\"Wrapper function that runs _process_single_sample_upload with the provided context.\"\"\"\n        token = otel_context.attach(context)\n        try:\n            return self._process_single_sample_upload(asset, identifier)\n        finally:\n            otel_context.detach(token)\n\n    successful_uploads: list[str] = []\n    failed_uploads: list[str] = []\n    total_uploads = len(assets)\n\n    # Capture the current OpenTelemetry context before creating threads\n    current_context = otel_context.get_current()\n\n    with ThreadPoolExecutor(\n        max_workers=rapidata_config.upload.maxWorkers\n    ) as executor:\n        futures = [\n            executor.submit(\n                upload_with_context,\n                current_context,\n                asset,\n                identifier,\n            )\n            for asset, identifier in zip(assets, identifiers)\n        ]\n\n        with tqdm(\n            total=total_uploads,\n            desc=\"Uploading media\",\n            disable=rapidata_config.logging.silent_mode,\n        ) as pbar:\n            for future in as_completed(futures):\n                try:\n                    successful_id, failed_id = future.result()\n                    if successful_id:\n                        successful_uploads.append(successful_id)\n                        pbar.update(1)\n                    if failed_id:\n                        failed_uploads.append(failed_id)\n                except Exception as e:\n                    logger.error(f\"Future execution failed: {str(e)}\")\n\n    return successful_uploads, failed_uploads\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/config/logger/","title":"Logger","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/config/logger/#rapidata.rapidata_client.config.logger.LoggerProtocol","title":"LoggerProtocol","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol that defines the logger interface for type checking.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/config/logger/#rapidata.rapidata_client.config.logger.RapidataLogger","title":"RapidataLogger","text":"<pre><code>RapidataLogger(name: str = 'rapidata')\n</code></pre> <p>Logger implementation that updates when the configuration changes.</p> Source code in <code>src/rapidata/rapidata_client/config/logger.py</code> <pre><code>def __init__(self, name: str = \"rapidata\"):\n    self._logger = logging.getLogger(name)\n    self._otlp_initialized = False\n    self._init_lock = threading.Lock()\n    self._otlp_handler = None\n    self._otlp_enabled = True  # Default to enabled\n    self._otlp_attached = False\n\n    # Register this logger to receive configuration updates\n    register_config_handler(self._handle_config_update)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/config/logging_config/","title":"Logging config","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/config/logging_config/#rapidata.rapidata_client.config.logging_config.LoggingConfig","title":"LoggingConfig","text":"<pre><code>LoggingConfig(**kwargs)\n</code></pre> <p>               Bases: <code>BaseModel</code></p> <p>Holds the configuration for the logging process.</p> <p>Attributes:</p> Name Type Description <code>level</code> <code>str</code> <p>The logging level. Defaults to \"WARNING\".</p> <code>log_file</code> <code>str | None</code> <p>The logging file. Defaults to None.</p> <code>format</code> <code>str</code> <p>The logging format. Defaults to \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\".</p> <code>silent_mode</code> <code>bool</code> <p>Whether to disable the prints and progress bars. Does NOT affect the logging. Defaults to False.</p> <code>enable_otlp</code> <code>bool</code> <p>Whether to enable OpenTelemetry trace logs. Defaults to True. Can also be disabled via the RAPIDATA_DISABLE_OTLP=1 environment variable.</p> Source code in <code>src/rapidata/rapidata_client/config/logging_config.py</code> <pre><code>def __init__(self, **kwargs):\n    super().__init__(**kwargs)\n    self._notify_handlers()\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/config/logging_config/#rapidata.rapidata_client.config.logging_config.register_config_handler","title":"register_config_handler","text":"<pre><code>register_config_handler(\n    handler: ConfigUpdateHandler,\n) -&gt; None\n</code></pre> <p>Register a handler to be called when the logging configuration updates.</p> Source code in <code>src/rapidata/rapidata_client/config/logging_config.py</code> <pre><code>def register_config_handler(handler: ConfigUpdateHandler) -&gt; None:\n    \"\"\"Register a handler to be called when the logging configuration updates.\"\"\"\n    _config_handlers.append(handler)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/config/logging_config/#rapidata.rapidata_client.config.logging_config.unregister_config_handler","title":"unregister_config_handler","text":"<pre><code>unregister_config_handler(\n    handler: ConfigUpdateHandler,\n) -&gt; None\n</code></pre> <p>Unregister a previously registered handler.</p> Source code in <code>src/rapidata/rapidata_client/config/logging_config.py</code> <pre><code>def unregister_config_handler(handler: ConfigUpdateHandler) -&gt; None:\n    \"\"\"Unregister a previously registered handler.\"\"\"\n    if handler in _config_handlers:\n        _config_handlers.remove(handler)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/config/managed_print/","title":"Managed print","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/config/rapidata_config/","title":"Rapidata config","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/config/rapidata_config/#rapidata.rapidata_client.config.rapidata_config.RapidataConfig","title":"RapidataConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Holds the configuration for the Rapidata client.</p> <p>To adjust the configurations used, you can modify the <code>rapidata_config</code> object.</p> <p>Attributes:</p> Name Type Description <code>enableBetaFeatures</code> <code>bool</code> <p>Whether to enable beta features. Defaults to False.</p> <code>upload</code> <code>UploadConfig</code> <p>The configuration for the upload process. Such as the maximum number of worker threads for processing media paths and the maximum number of retries for failed uploads.</p> <code>logging</code> <code>LoggingConfig</code> <p>The configuration for the logging process. Such as the logging level and the logging file.</p> Example <pre><code>from rapidata import rapidata_config\nrapidata_config.upload.maxUploadWorkers = 20\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/config/tracer/","title":"Tracer","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/config/tracer/#rapidata.rapidata_client.config.tracer.TracerProtocol","title":"TracerProtocol","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol that defines the tracer interface for type checking.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/config/tracer/#rapidata.rapidata_client.config.tracer.NoOpSpan","title":"NoOpSpan","text":"<p>A no-op span that does nothing when tracing is disabled.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/config/tracer/#rapidata.rapidata_client.config.tracer.NoOpTracer","title":"NoOpTracer","text":"<p>A no-op tracer that returns no-op spans when tracing is disabled.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/config/tracer/#rapidata.rapidata_client.config.tracer.SpanContextManagerWrapper","title":"SpanContextManagerWrapper","text":"<pre><code>SpanContextManagerWrapper(\n    context_manager: Any, session_id: str | None\n)\n</code></pre> <p>Wrapper for span context managers to add session_id on enter.</p> Source code in <code>src/rapidata/rapidata_client/config/tracer.py</code> <pre><code>def __init__(self, context_manager: Any, session_id: str | None):\n    self._context_manager = context_manager\n    self.session_id = session_id\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/config/tracer/#rapidata.rapidata_client.config.tracer.RapidataTracer","title":"RapidataTracer","text":"<pre><code>RapidataTracer(name: str = __name__)\n</code></pre> <p>Tracer implementation that updates when the configuration changes.</p> Source code in <code>src/rapidata/rapidata_client/config/tracer.py</code> <pre><code>def __init__(self, name: str = __name__):\n    self._name = name\n    self._otlp_initialized = False\n    self._init_lock = threading.Lock()\n    self._tracer_provider = None\n    self._real_tracer = None\n    self._no_op_tracer = NoOpTracer()\n    self._enabled = True  # Default to enabled\n    self.session_id: str | None = None\n\n    # Register this tracer to receive configuration updates\n    register_config_handler(self._handle_config_update)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/config/tracer/#rapidata.rapidata_client.config.tracer.RapidataTracer.start_span","title":"start_span","text":"<pre><code>start_span(name: str, *args, **kwargs) -&gt; Any\n</code></pre> <p>Start a span, or return a no-op span if tracing is disabled.</p> Source code in <code>src/rapidata/rapidata_client/config/tracer.py</code> <pre><code>def start_span(self, name: str, *args, **kwargs) -&gt; Any:\n    \"\"\"Start a span, or return a no-op span if tracing is disabled.\"\"\"\n    if self._enabled:\n        self._ensure_initialized()\n        if self._real_tracer:\n            span = self._real_tracer.start_span(name, *args, **kwargs)\n            return self._add_session_id_to_span(span)\n    return self._no_op_tracer.start_span(name, *args, **kwargs)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/config/tracer/#rapidata.rapidata_client.config.tracer.RapidataTracer.start_as_current_span","title":"start_as_current_span","text":"<pre><code>start_as_current_span(name: str, *args, **kwargs) -&gt; Any\n</code></pre> <p>Start a span as current, or return a no-op span if tracing is disabled.</p> Source code in <code>src/rapidata/rapidata_client/config/tracer.py</code> <pre><code>def start_as_current_span(self, name: str, *args, **kwargs) -&gt; Any:\n    \"\"\"Start a span as current, or return a no-op span if tracing is disabled.\"\"\"\n    if self._enabled:\n        self._ensure_initialized()\n        if self._real_tracer:\n            context_manager = self._real_tracer.start_as_current_span(\n                name, *args, **kwargs\n            )\n            return SpanContextManagerWrapper(context_manager, self.session_id)\n    return self._no_op_tracer.start_as_current_span(name, *args, **kwargs)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/config/tracer/#rapidata.rapidata_client.config.tracer.get_system_attributes","title":"get_system_attributes","text":"<pre><code>get_system_attributes() -&gt; dict[str, str | int | None]\n</code></pre> <p>Gather system telemetry for traces.</p> Source code in <code>src/rapidata/rapidata_client/config/tracer.py</code> <pre><code>def get_system_attributes() -&gt; dict[str, str | int | None]:\n    \"\"\"Gather system telemetry for traces.\"\"\"\n    try:\n        attrs = {\n            \"system.os\": platform.system(),\n            \"system.os.version\": platform.release(),\n            \"system.arch\": platform.machine(),\n            \"python.version\": f\"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\",\n            \"process.cpu_count\": os.cpu_count(),\n        }\n        logger.debug(f\"System attributes: {attrs}\")\n        return attrs\n    except Exception:\n        logger.debug(\"Failed to get system attributes, returning empty dict\")\n        return {}\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/config/upload_config/","title":"Upload config","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/config/upload_config/#rapidata.rapidata_client.config.upload_config.UploadConfig","title":"UploadConfig","text":"<pre><code>UploadConfig(**kwargs)\n</code></pre> <p>               Bases: <code>BaseModel</code></p> <p>Holds the configuration for the upload process.</p> <p>Attributes:</p> Name Type Description <code>maxWorkers</code> <code>int</code> <p>The maximum number of worker threads for concurrent uploads. Defaults to 25.</p> <code>maxRetries</code> <code>int</code> <p>The maximum number of retries for failed uploads. Defaults to 3.</p> <code>cacheToDisk</code> <code>bool</code> <p>Enable disk-based caching for file uploads. If False, uses in-memory cache only. Defaults to True. Note: URL assets are always cached in-memory regardless of this setting. Caching cannot be disabled entirely as it's required for the two-step upload flow.</p> <code>cacheTimeout</code> <code>float</code> <p>Cache operation timeout in seconds. Defaults to 0.1.</p> <code>cacheLocation</code> <code>Path</code> <p>Directory for cache storage. Defaults to ~/.cache/rapidata/upload_cache. This is immutable. Only used for file uploads when cacheToDisk=True.</p> <code>cacheShards</code> <code>int</code> <p>Number of cache shards for parallel access. Defaults to 128. Higher values improve concurrency but increase file handles. Must be positive. This is immutable. Only used for file uploads when cacheToDisk=True.</p> <code>enableBatchUpload</code> <code>bool</code> <p>Enable batch URL uploading (two-step process). Defaults to True.</p> <code>batchSize</code> <code>int</code> <p>Number of URLs per batch (100-5000). Defaults to 1000.</p> <code>batchPollInterval</code> <code>float</code> <p>Polling interval in seconds. Defaults to 0.5.</p> Source code in <code>src/rapidata/rapidata_client/config/upload_config.py</code> <pre><code>def __init__(self, **kwargs):\n    super().__init__(**kwargs)\n    self._migrate_cache()\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/datapoints/assets/constants/","title":"Constants","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/demographic/demographic_manager/","title":"Demographic manager","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/exceptions/asset_upload_exception/","title":"Asset upload exception","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/exceptions/asset_upload_exception/#rapidata.rapidata_client.exceptions.asset_upload_exception.AssetUploadException","title":"AssetUploadException","text":"<pre><code>AssetUploadException(\n    failed_uploads: list[FailedUpload[str]],\n)\n</code></pre> <p>               Bases: <code>Exception</code></p> <p>Exception raised when asset uploads fail in Step 1/2 of the two-step upload process.</p> <p>This exception contains details about which assets failed to upload, allowing users to decide how to proceed (retry, skip, or abort).</p> <p>Attributes:</p> Name Type Description <code>failed_uploads</code> <p>List of FailedUpload instances containing the failed assets and error details.</p> Source code in <code>src/rapidata/rapidata_client/exceptions/asset_upload_exception.py</code> <pre><code>def __init__(self, failed_uploads: list[FailedUpload[str]]):\n    self.failed_uploads = failed_uploads\n    message = (\n        f\"Failed to upload {len(failed_uploads)} asset(s) in Step 1/2. \"\n        f\"See failed_uploads attribute for details.\"\n    )\n    super().__init__(message)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/exceptions/failed_upload/","title":"Failed upload","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/exceptions/failed_upload/#rapidata.rapidata_client.exceptions.failed_upload.FailedUpload","title":"FailedUpload  <code>dataclass</code>","text":"<pre><code>FailedUpload(\n    item: T,\n    error_message: str,\n    error_type: str,\n    timestamp: Optional[datetime] = now(),\n    exception: Optional[Exception] = None,\n)\n</code></pre> <p>               Bases: <code>Generic[T]</code></p> <p>Represents a failed upload with the item and error details.</p> <p>Attributes:</p> Name Type Description <code>item</code> <code>T</code> <p>The item that failed to upload.</p> <code>error_message</code> <code>str</code> <p>The error message describing the failure reason.</p> <code>error_type</code> <code>str</code> <p>The type of the exception (e.g., \"RapidataError\").</p> <code>timestamp</code> <code>Optional[datetime]</code> <p>Optional timestamp when the failure occurred.</p> <code>exception</code> <code>Optional[Exception]</code> <p>Optional original exception for richer error context.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/exceptions/failed_upload/#rapidata.rapidata_client.exceptions.failed_upload.FailedUpload.from_exception","title":"from_exception  <code>classmethod</code>","text":"<pre><code>from_exception(\n    item: T, exception: Exception | None\n) -&gt; FailedUpload[T]\n</code></pre> <p>Create a FailedUpload from an item and exception.</p> <p>For RapidataError exceptions, extracts the clean API error reason. For other exceptions, uses the string representation.</p> <p>Parameters:</p> Name Type Description Default <code>item</code> <code>T</code> <p>The item that failed to upload.</p> required <code>exception</code> <code>Exception | None</code> <p>The exception that occurred.</p> required <p>Returns:</p> Type Description <code>FailedUpload[T]</code> <p>FailedUpload instance with error details extracted from the exception.</p> Source code in <code>src/rapidata/rapidata_client/exceptions/failed_upload.py</code> <pre><code>@classmethod\ndef from_exception(cls, item: T, exception: Exception | None) -&gt; FailedUpload[T]:\n    \"\"\"\n    Create a FailedUpload from an item and exception.\n\n    For RapidataError exceptions, extracts the clean API error reason.\n    For other exceptions, uses the string representation.\n\n    Args:\n        item: The item that failed to upload.\n        exception: The exception that occurred.\n\n    Returns:\n        FailedUpload instance with error details extracted from the exception.\n    \"\"\"\n    if exception is None:\n        return cls(\n            item=item,\n            error_message=\"Unknown error\",\n            error_type=\"Unknown\",\n            exception=None,\n        )\n\n    from rapidata.rapidata_client.exceptions.rapidata_error import RapidataError\n\n    error_type = type(exception).__name__\n\n    if isinstance(exception, RapidataError):\n        error_message = exception.get_reason()\n    else:\n        error_message = str(exception)\n\n    return cls(\n        item=item,\n        error_message=error_message,\n        error_type=error_type,\n        exception=exception,\n    )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/exceptions/failed_upload/#rapidata.rapidata_client.exceptions.failed_upload.FailedUpload.format_error_details","title":"format_error_details","text":"<pre><code>format_error_details() -&gt; str\n</code></pre> <p>Format error details for logging or display.</p> <p>Returns:</p> Type Description <code>str</code> <p>Formatted string with all error details including timestamp.</p> Source code in <code>src/rapidata/rapidata_client/exceptions/failed_upload.py</code> <pre><code>def format_error_details(self) -&gt; str:\n    \"\"\"\n    Format error details for logging or display.\n\n    Returns:\n        Formatted string with all error details including timestamp.\n    \"\"\"\n    details = [\n        f\"Item: {self.item}\",\n        f\"Error Type: {self.error_type}\",\n        f\"Error Message: {self.error_message}\",\n    ]\n\n    if self.timestamp:\n        details.append(f\"Timestamp: {self.timestamp.isoformat()}\")\n\n    return \"\\n\".join(details)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/exceptions/failed_upload_exception/","title":"Failed upload exception","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/exceptions/failed_upload_exception/#rapidata.rapidata_client.exceptions.failed_upload_exception.FailedUploadException","title":"FailedUploadException","text":"<pre><code>FailedUploadException(\n    dataset: RapidataDataset,\n    failed_uploads: list[FailedUpload[Datapoint]],\n    order: Optional[RapidataOrder] = None,\n    job_definition: Optional[RapidataJobDefinition] = None,\n)\n</code></pre> <p>               Bases: <code>Exception</code></p> <p>Custom error class for Failed Uploads to the Rapidata order.</p> Source code in <code>src/rapidata/rapidata_client/exceptions/failed_upload_exception.py</code> <pre><code>def __init__(\n    self,\n    dataset: RapidataDataset,\n    failed_uploads: list[FailedUpload[Datapoint]],\n    order: Optional[RapidataOrder] = None,\n    job_definition: Optional[RapidataJobDefinition] = None,\n):\n    self.dataset = dataset\n    self.order = order\n    self.job_definition = job_definition\n    self._failed_uploads = failed_uploads\n    super().__init__(str(self))\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/exceptions/failed_upload_exception/#rapidata.rapidata_client.exceptions.failed_upload_exception.FailedUploadException.failed_uploads","title":"failed_uploads  <code>property</code>","text":"<pre><code>failed_uploads: list[Datapoint]\n</code></pre> <p>Get list of failed datapoints (backward compatibility).</p> <p>Returns:</p> Type Description <code>list[Datapoint]</code> <p>List of datapoints that failed to upload.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/exceptions/failed_upload_exception/#rapidata.rapidata_client.exceptions.failed_upload_exception.FailedUploadException.detailed_failures","title":"detailed_failures  <code>property</code>","text":"<pre><code>detailed_failures: list[FailedUpload[Datapoint]]\n</code></pre> <p>Get detailed failure information including error messages.</p> <p>Returns:</p> Type Description <code>list[FailedUpload[Datapoint]]</code> <p>List of FailedUpload objects with item and error details.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/exceptions/failed_upload_exception/#rapidata.rapidata_client.exceptions.failed_upload_exception.FailedUploadException.failures_by_reason","title":"failures_by_reason  <code>property</code>","text":"<pre><code>failures_by_reason: dict[str, list[Datapoint]]\n</code></pre> <p>Get failures grouped by error reason.</p> <p>Returns:</p> Type Description <code>dict[str, list[Datapoint]]</code> <p>Dictionary mapping error reasons to lists of failed datapoints.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/exceptions/rapidata_error/","title":"Rapidata error","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/exceptions/rapidata_error/#rapidata.rapidata_client.exceptions.rapidata_error.RapidataError","title":"RapidataError","text":"<pre><code>RapidataError(\n    status_code: Optional[int] = None,\n    message: str | None = None,\n    original_exception: Exception | None = None,\n    details: Any = None,\n)\n</code></pre> <p>               Bases: <code>Exception</code></p> <p>Custom error class for Rapidata API errors.</p> Source code in <code>src/rapidata/rapidata_client/exceptions/rapidata_error.py</code> <pre><code>def __init__(\n    self,\n    status_code: Optional[int] = None,\n    message: str | None = None,\n    original_exception: Exception | None = None,\n    details: Any = None,\n):\n    self.status_code = status_code\n    self.message = message\n    self.original_exception = original_exception\n    self.details = details\n\n    # Create a nice error message\n    error_msg = \"Rapidata API Error\"\n    if status_code:\n        error_msg += f\" ({status_code})\"\n    if message:\n        error_msg += f\": {message}\"\n\n    super().__init__(error_msg)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/exceptions/rapidata_error/#rapidata.rapidata_client.exceptions.rapidata_error.RapidataError.get_reason","title":"get_reason","text":"<pre><code>get_reason() -&gt; str\n</code></pre> <p>Get a concise reason string suitable for grouping and display.</p> <p>Returns the most meaningful error reason extracted from the API response.</p> Source code in <code>src/rapidata/rapidata_client/exceptions/rapidata_error.py</code> <pre><code>def get_reason(self) -&gt; str:\n    \"\"\"Get a concise reason string suitable for grouping and display.\n\n    Returns the most meaningful error reason extracted from the API response.\n    \"\"\"\n    if self.details and isinstance(self.details, dict):\n        title = self.details.get(\"title\")\n        if title:\n            return title\n\n    if self.message:\n        return self.message\n\n    return \"Unknown error\"\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/filter/age_filter/","title":"Age filter","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/filter/age_filter/#rapidata.rapidata_client.filter.age_filter.AgeFilter","title":"AgeFilter","text":"<pre><code>AgeFilter(age_groups: list[AgeGroup])\n</code></pre> <p>               Bases: <code>RapidataFilter</code>, <code>BaseModel</code></p> <p>AgeFilter Class</p> <p>Can be used to filter who to target based on age groups.</p> <p>Parameters:</p> Name Type Description Default <code>age_groups</code> <code>list[AgeGroup]</code> <p>List of age groups to filter by.</p> required Source code in <code>src/rapidata/rapidata_client/filter/age_filter.py</code> <pre><code>def __init__(self, age_groups: list[AgeGroup]):\n    super().__init__(age_groups=age_groups)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/filter/and_filter/","title":"And filter","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/filter/and_filter/#rapidata.rapidata_client.filter.and_filter.AndFilter","title":"AndFilter","text":"<pre><code>AndFilter(filters: list[RapidataFilter])\n</code></pre> <p>               Bases: <code>RapidataFilter</code>, <code>BaseModel</code></p> <p>A filter that combines multiple filters with a logical AND operation. This class implements a logical AND operation on a list of filters, where the condition is met if all of the filters' conditions are met.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>list[RapidataFilter]</code> <p>A list of filters to be combined with AND.</p> required Example <pre><code>from rapidata import AndFilter, LanguageFilter, CountryFilter\n\nAndFilter([LanguageFilter([\"en\"]), CountryFilter([\"US\"])])\n</code></pre> <p>This will match users who have their phone set to English AND are located in the United States.</p> Source code in <code>src/rapidata/rapidata_client/filter/and_filter.py</code> <pre><code>def __init__(self, filters: list[RapidataFilter]):\n    super().__init__(filters=filters)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/filter/campaign_filter/","title":"Campaign filter","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/filter/campaign_filter/#rapidata.rapidata_client.filter.campaign_filter.CampaignFilter","title":"CampaignFilter","text":"<pre><code>CampaignFilter(campaign_ids: list[str])\n</code></pre> <p>               Bases: <code>RapidataFilter</code>, <code>BaseModel</code></p> <p>CampaignFilter Class</p> <p>Can be used to filter who to target based on campaign IDs.</p> <p>This filter can only be used when directly in contact with Rapidata.</p> <p>Parameters:</p> Name Type Description Default <code>campaign_ids</code> <code>list[str]</code> <p>List of campaign IDs to filter by.</p> required Source code in <code>src/rapidata/rapidata_client/filter/campaign_filter.py</code> <pre><code>def __init__(self, campaign_ids: list[str]):\n    super().__init__(campaign_ids=campaign_ids)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/filter/country_filter/","title":"Country filter","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/filter/country_filter/#rapidata.rapidata_client.filter.country_filter.CountryFilter","title":"CountryFilter","text":"<pre><code>CountryFilter(country_codes: list[str])\n</code></pre> <p>               Bases: <code>RapidataFilter</code>, <code>BaseModel</code></p> <p>CountryFilter Class</p> <p>Can be used to filter who to target based on country codes.</p> <p>Parameters:</p> Name Type Description Default <code>country_codes</code> <code>list[str]</code> <p>List of country codes (capitalized) to filter by.</p> required Source code in <code>src/rapidata/rapidata_client/filter/country_filter.py</code> <pre><code>def __init__(self, country_codes: list[str]):\n    super().__init__(country_codes=country_codes)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/filter/custom_filter/","title":"Custom filter","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/filter/custom_filter/#rapidata.rapidata_client.filter.custom_filter.CustomFilter","title":"CustomFilter","text":"<pre><code>CustomFilter(identifier: str, values: list[str])\n</code></pre> <p>               Bases: <code>RapidataFilter</code>, <code>BaseModel</code></p> <p>CustomFilter Class</p> <p>Can be used to filter who to target based on custom filters.</p> <p>Ought to be used with contact to Rapidata.</p> <p>Warning: If identifier does not exist, order will not get any responses.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>str</code> <p>Identifier of the custom filter.</p> required <code>values</code> <code>list[str]</code> <p>List of values to filter by.</p> required Source code in <code>src/rapidata/rapidata_client/filter/custom_filter.py</code> <pre><code>def __init__(self, identifier: str, values: list[str]):\n    super().__init__(identifier=identifier, values=values)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/filter/device_filter/","title":"Device filter","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/filter/device_filter/#rapidata.rapidata_client.filter.device_filter.DeviceFilter","title":"DeviceFilter","text":"<pre><code>DeviceFilter(device_types: list[DeviceType])\n</code></pre> <p>               Bases: <code>RapidataFilter</code>, <code>BaseModel</code></p> <p>DeviceFilter Class</p> <p>Can be used to filter who to target based on their device type.</p> <p>Parameters:</p> Name Type Description Default <code>device_types</code> <code>list[DeviceType]</code> <p>List of device types to filter by.</p> required Source code in <code>src/rapidata/rapidata_client/filter/device_filter.py</code> <pre><code>def __init__(self, device_types: list[DeviceType]):\n    super().__init__(device_types=device_types)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/filter/gender_filter/","title":"Gender filter","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/filter/gender_filter/#rapidata.rapidata_client.filter.gender_filter.GenderFilter","title":"GenderFilter","text":"<pre><code>GenderFilter(genders: list[Gender])\n</code></pre> <p>               Bases: <code>RapidataFilter</code>, <code>BaseModel</code></p> <p>GenderFilter Class</p> <p>Can be used to filter who to target based on their gender.</p> <p>Parameters:</p> Name Type Description Default <code>genders</code> <code>list[Gender]</code> <p>List of genders to filter by.</p> required Source code in <code>src/rapidata/rapidata_client/filter/gender_filter.py</code> <pre><code>def __init__(self, genders: list[Gender]):\n    super().__init__(genders=genders)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/filter/language_filter/","title":"Language filter","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/filter/language_filter/#rapidata.rapidata_client.filter.language_filter.LanguageFilter","title":"LanguageFilter","text":"<pre><code>LanguageFilter(language_codes: list[str])\n</code></pre> <p>               Bases: <code>RapidataFilter</code>, <code>BaseModel</code></p> <p>LanguageFilter Class</p> <p>Can be used to filter who to target based on language codes.</p> <p>Parameters:</p> Name Type Description Default <code>language_codes</code> <code>list[str]</code> <p>List of language codes to filter by.</p> required Example <p></p><pre><code>LanguageFilter([\"en\", \"de\"])\n</code></pre> This will limit the order to be shown to only people who have their phone set to english or german<p></p> Source code in <code>src/rapidata/rapidata_client/filter/language_filter.py</code> <pre><code>def __init__(self, language_codes: list[str]):\n    super().__init__(language_codes=language_codes)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/filter/new_user_filter/","title":"New user filter","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/filter/new_user_filter/#rapidata.rapidata_client.filter.new_user_filter.NewUserFilter","title":"NewUserFilter","text":"<p>               Bases: <code>RapidataFilter</code></p> <p>NewUserFilter Class</p> <p>Can be used to filter new users.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/filter/not_filter/","title":"Not filter","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/filter/not_filter/#rapidata.rapidata_client.filter.not_filter.NotFilter","title":"NotFilter","text":"<pre><code>NotFilter(filter: RapidataFilter)\n</code></pre> <p>               Bases: <code>RapidataFilter</code>, <code>BaseModel</code></p> <p>A filter that negates another filter's condition. This class implements a logical NOT operation on a given filter, inverting its results.</p> <p>Parameters:</p> Name Type Description Default <code>filter</code> <code>RapidataFilter</code> <p>The filter whose condition should be negated.</p> required Example <pre><code>from rapidata import NotFilter, LanguageFilter\n\nNotFilter(LanguageFilter([\"en\"]))\n</code></pre> <p>This will limit the order to be shown to only people who have their phone set to a language other than English.</p> Source code in <code>src/rapidata/rapidata_client/filter/not_filter.py</code> <pre><code>def __init__(self, filter: RapidataFilter):\n    super().__init__(filter=filter)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/filter/or_filter/","title":"Or filter","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/filter/or_filter/#rapidata.rapidata_client.filter.or_filter.OrFilter","title":"OrFilter","text":"<pre><code>OrFilter(filters: list[RapidataFilter])\n</code></pre> <p>               Bases: <code>RapidataFilter</code>, <code>BaseModel</code></p> <p>A filter that combines multiple filters with a logical OR operation. This class implements a logical OR operation on a list of filters, where the condition is met if any of the filters' conditions are met.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>list[RapidataFilter]</code> <p>A list of filters to be combined with OR.</p> required Example <pre><code>from rapidata import OrFilter, LanguageFilter, CountryFilter\n\nOrFilter([LanguageFilter([\"en\"]), CountryFilter([\"US\"])])\n</code></pre> <p>This will match users who either have their phone set to English OR are located in the United States.</p> Source code in <code>src/rapidata/rapidata_client/filter/or_filter.py</code> <pre><code>def __init__(self, filters: list[RapidataFilter]):\n    super().__init__(filters=filters)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/filter/rapidata_filters/","title":"Rapidata filters","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/filter/rapidata_filters/#rapidata.rapidata_client.filter.rapidata_filters.RapidataFilters","title":"RapidataFilters","text":"<p>RapidataFilters Classes</p> <p>These filters can be added to the order to specifically target a certain group of users.</p> <p>Note that adding multiple filters to the same order will result in a logical AND operation between the filters.</p> Warning <p>This might significantly slow down the number of responses you receive.</p> <p>Attributes:</p> Name Type Description <code>country</code> <code>CountryFilter</code> <p>Filters for users with a specific country.</p> <code>language</code> <code>LanguageFilter</code> <p>Filters for users with a specific language.</p> <code>not_filter</code> <code>NotFilter</code> <p>Inverts the filter.</p> <code>or_filter</code> <code>OrFilter</code> <p>Combines multiple filters with a logical OR operation.</p> <code>and_filter</code> <code>AndFilter</code> <p>Combines multiple filters with a logical AND operation.</p> Example <pre><code>from rapidata import CountryFilter, LanguageFilter\nfilters=[CountryFilter([\"US\", \"DE\"]), LanguageFilter([\"en\"])]\n</code></pre> <p>This ensures the order is only shown to users in the US and Germany whose phones are set to English.</p> Info <p>The OR, AND and NOT filter support the |, &amp; and ~ operators respectively. The AND is additionally given by the elements in the list.</p> <pre><code>from rapidata import LanguageFilter, CountryFilter\nfilters=[(CountryFilter([\"US\"]) &amp; ~LanguageFilter([\"fr\"])) | (CountryFilter([\"CA\"]) &amp; LanguageFilter([\"en\"]))]\n</code></pre> <p>This would return users who are from the US and whose phones are not set to French or who are from Canada and whose phones are set to English.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/filter/response_count_filter/","title":"Response count filter","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/filter/response_count_filter/#rapidata.rapidata_client.filter.response_count_filter.ResponseCountFilter","title":"ResponseCountFilter","text":"<pre><code>ResponseCountFilter(\n    response_count: int,\n    dimension: str,\n    operator: ComparisonOperator,\n)\n</code></pre> <p>               Bases: <code>RapidataFilter</code>, <code>BaseModel</code></p> <p>ResponseCountFilter Class Can be used to filter users based on the number of responses they have given on validation tasks with the specified dimension.</p> <pre><code>response_count (int): The number of user responses to filter by.\ndimension (str): The dimension to apply the filter on (e.g. \"default\", \"electrical\", etc.).\noperator (str): The comparison operator to use. Must be one of:\n    - ComparisonOperator.EQUAL\n    - ComparisonOperator.NOTEQUAL\n    - ComparisonOperator.LESSTHAN\n    - ComparisonOperator.LESSTHANOREQUAL\n    - ComparisonOperator.GREATERTHAN\n    - ComparisonOperator.GREATERTHANOREQUAL\n</code></pre> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>response_count</code> is not an integer.</p> <code>ValueError</code> <p>If <code>dimension</code> is not a string.</p> <code>ValueError</code> <p>If <code>operator</code> is not a string or not one of the allowed values.</p> Example <p></p><pre><code>from rapidata import ResponseCountFilter\n\nfilter = ResponseCountFilter(response_count=10, dimension=\"electrical\", operator=ComparisonOperator.GREATERTHAN)\n</code></pre> This will filter users who have a response count greater than 10 for the \"electrical\" dimension.<p></p> Source code in <code>src/rapidata/rapidata_client/filter/response_count_filter.py</code> <pre><code>def __init__(\n    self, response_count: int, dimension: str, operator: ComparisonOperator\n):\n    super().__init__(\n        response_count=response_count, dimension=dimension, operator=operator\n    )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/filter/user_score_filter/","title":"User score filter","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/filter/user_score_filter/#rapidata.rapidata_client.filter.user_score_filter.UserScoreFilter","title":"UserScoreFilter","text":"<pre><code>UserScoreFilter(\n    lower_bound: float = 0.0,\n    upper_bound: float = 1.0,\n    dimension: str | None = None,\n)\n</code></pre> <p>               Bases: <code>RapidataFilter</code>, <code>BaseModel</code></p> <p>UserScoreFilter Class</p> <p>Can be used to filter who to target based on their user score.</p> <p>Parameters:</p> Name Type Description Default <code>lower_bound</code> <code>float</code> <p>The lower bound of the user score.</p> <code>0.0</code> <code>upper_bound</code> <code>float</code> <p>The upper bound of the user score.</p> <code>1.0</code> <code>dimension</code> <code>str</code> <p>The dimension of the userScore to be considerd for the filter.</p> <code>None</code> Example <p></p><pre><code>UserScoreFilter(0.5, 0.9)\n</code></pre> This will only show the order to users that have a UserScore of &gt;=0.5 and &lt;=0.9<p></p> Source code in <code>src/rapidata/rapidata_client/filter/user_score_filter.py</code> <pre><code>def __init__(\n    self,\n    lower_bound: float = 0.0,\n    upper_bound: float = 1.0,\n    dimension: str | None = None,\n):\n    super().__init__(\n        lower_bound=lower_bound, upper_bound=upper_bound, dimension=dimension\n    )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/filter/models/age_group/","title":"Age group","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/filter/models/age_group/#rapidata.rapidata_client.filter.models.age_group.AgeGroup","title":"AgeGroup","text":"<p>               Bases: <code>Enum</code></p> <p>AgeGroup Enum</p> <p>Represents the age group of a user. Used to filter who to target based on age groups.</p> <p>Attributes:</p> Name Type Description <code>UNDER_18</code> <code>AgeGroup</code> <p>Represents the age group of users under 18.</p> <code>BETWEEN_18_29</code> <code>AgeGroup</code> <p>Represents the age group of users between 18 and 29.</p> <code>BETWEEN_30_39</code> <code>AgeGroup</code> <p>Represents the age group of users between 30 and 39.</p> <code>BETWEEN_40_49</code> <code>AgeGroup</code> <p>Represents the age group of users between 40 and 49.</p> <code>BETWEEN_50_64</code> <code>AgeGroup</code> <p>Represents the age group of users between 50 and 64.</p> <code>OVER_65</code> <code>AgeGroup</code> <p>Represents the age group of users over 65.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/filter/models/device_type/","title":"Device type","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/filter/models/device_type/#rapidata.rapidata_client.filter.models.device_type.DeviceType","title":"DeviceType","text":"<p>               Bases: <code>Enum</code></p> <p>DeviceType Enum</p> <p>Represents the device type of a user. Used to filter who to target based on device types.</p> <p>Attributes:</p> Name Type Description <code>UNKNOWN</code> <code>DeviceType</code> <p>Unknown device type.</p> <code>PHONE</code> <code>DeviceType</code> <p>Phone device.</p> <code>TABLET</code> <code>DeviceType</code> <p>Tablet device.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/filter/models/gender/","title":"Gender","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/filter/models/gender/#rapidata.rapidata_client.filter.models.gender.Gender","title":"Gender","text":"<p>               Bases: <code>Enum</code></p> <p>Gender Enum</p> <p>Represents the gender of a user. Used to filter who to target based on genders.</p> <p>Attributes:</p> Name Type Description <code>MALE</code> <code>Gender</code> <p>Represents the Male gender.</p> <code>FEMALE</code> <code>Gender</code> <p>Represents the Female gender.</p> <code>OTHER</code> <code>Gender</code> <p>Represents any other gender.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/flow/flow_item_result/","title":"Flow item result","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/flow/flow_item_result/#rapidata.rapidata_client.flow.flow_item_result.FlowItemResult","title":"FlowItemResult  <code>dataclass</code>","text":"<pre><code>FlowItemResult(\n    datapoints: dict[str, int], total_votes: int\n)\n</code></pre> <p>Result of a flow item containing elo scores and vote count.</p> <p>Attributes:</p> Name Type Description <code>datapoints</code> <code>dict[str, int]</code> <p>Mapping of asset identifier to elo score.</p> <code>total_votes</code> <code>int</code> <p>Total number of votes cast for this flow item.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/flow/rapidata_flow/","title":"Rapidata flow","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/flow/rapidata_flow/#rapidata.rapidata_client.flow.rapidata_flow.RapidataFlow","title":"RapidataFlow","text":"<pre><code>RapidataFlow(\n    id: str, name: str, openapi_service: OpenAPIService\n)\n</code></pre> Source code in <code>src/rapidata/rapidata_client/flow/rapidata_flow.py</code> <pre><code>def __init__(self, id: str, name: str, openapi_service: OpenAPIService):\n    self.id = id\n    self.name = name\n    self._openapi_service = openapi_service\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/flow/rapidata_flow/#rapidata.rapidata_client.flow.rapidata_flow.RapidataFlow.create_new_flow_batch","title":"create_new_flow_batch","text":"<pre><code>create_new_flow_batch(\n    datapoints: list[str],\n    context: str | None = None,\n    data_type: Literal[\"media\", \"text\"] = \"media\",\n    private_metadata: list[dict[str, str]] | None = None,\n    accept_failed_uploads: bool = False,\n    time_to_live: int | None = None,\n) -&gt; RapidataFlowItem\n</code></pre> <p>Create a new flow batch by uploading datapoints to a dataset and submitting it.</p> <p>Parameters:</p> Name Type Description Default <code>datapoints</code> <code>list[str]</code> <p>The list of datapoints (paths or URLs) to upload.</p> required <code>context</code> <code>str | None</code> <p>The context shown alongside the instruction.</p> <code>None</code> <code>data_type</code> <code>Literal['media', 'text']</code> <p>The data type of the datapoints. Defaults to \"media\".</p> <code>'media'</code> <code>private_metadata</code> <code>list[dict[str, str]] | None</code> <p>Optional key-value metadata per datapoint.</p> <code>None</code> <code>accept_failed_uploads</code> <code>bool</code> <p>If True, continues even if some uploads fail.</p> <code>False</code> <code>time_to_live</code> <code>int | None</code> <p>The time to live for the flow item in seconds. If it takes longer than this to complete, the flow item will be stopped and the results will be returned.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>RapidataFlowItem</code> <code>RapidataFlowItem</code> <p>The created flow item.</p> Source code in <code>src/rapidata/rapidata_client/flow/rapidata_flow.py</code> <pre><code>def create_new_flow_batch(\n    self,\n    datapoints: list[str],\n    context: str | None = None,\n    data_type: Literal[\"media\", \"text\"] = \"media\",\n    private_metadata: list[dict[str, str]] | None = None,\n    accept_failed_uploads: bool = False,\n    time_to_live: int | None = None,\n) -&gt; RapidataFlowItem:\n    \"\"\"Create a new flow batch by uploading datapoints to a dataset and submitting it.\n\n    Args:\n        datapoints: The list of datapoints (paths or URLs) to upload.\n        context: The context shown alongside the instruction.\n        data_type: The data type of the datapoints. Defaults to \"media\".\n        private_metadata: Optional key-value metadata per datapoint.\n        accept_failed_uploads: If True, continues even if some uploads fail.\n        time_to_live: The time to live for the flow item in seconds. If it takes longer than this to complete, the flow item will be stopped and the results will be returned.\n\n    Returns:\n        RapidataFlowItem: The created flow item.\n    \"\"\"\n    with tracer.start_as_current_span(\"RapidataFlow.create_new_flow_batch\"):\n        from rapidata.api_client.models.create_dataset_endpoint_input import (\n            CreateDatasetEndpointInput,\n        )\n        from rapidata.api_client.models.create_flow_item_endpoint_input import (\n            CreateFlowItemEndpointInput,\n        )\n        from rapidata.rapidata_client.flow.rapidata_flow_item import (\n            RapidataFlowItem,\n        )\n\n        if time_to_live is not None and time_to_live &lt; 60:\n            raise ValueError(\"Time to live must be at least 60 seconds.\")\n\n        logger.debug(\"Creating flow item for flow '%s'\", self.name)\n\n        datapoints_instances = DatapointsValidator.map_datapoints(\n            datapoints=datapoints,\n            data_type=data_type,\n            private_metadata=private_metadata,\n        )\n        dataset = self._openapi_service.dataset_api.dataset_post(\n            create_dataset_endpoint_input=CreateDatasetEndpointInput(\n                name=self.name + \"_dataset\",\n            ),\n        )\n        rapidata_dataset = RapidataDataset(\n            dataset.dataset_id, self._openapi_service\n        )\n\n        with tracer.start_as_current_span(\"add_datapoints\"):\n            _, failed_uploads = rapidata_dataset.add_datapoints(\n                datapoints_instances\n            )\n\n            if failed_uploads and not accept_failed_uploads:\n                raise FailedUploadException(rapidata_dataset, failed_uploads)\n            elif failed_uploads:\n                logger.warning(\n                    \"Failed to upload %d datapoints\", len(failed_uploads)\n                )\n\n        response = self._openapi_service.ranking_flow_item_api.flow_ranking_flow_id_item_post(\n            flow_id=self.id,\n            create_flow_item_endpoint_input=CreateFlowItemEndpointInput(\n                datasetId=rapidata_dataset.id,\n                context=context,\n                timeToLiveInSeconds=time_to_live,\n            ),\n        )\n\n        logger.debug(\"Flow item created with id: %s\", response.flow_item_id)\n\n        return RapidataFlowItem(\n            id=response.flow_item_id,\n            flow_id=self.id,\n            openapi_service=self._openapi_service,\n        )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/flow/rapidata_flow/#rapidata.rapidata_client.flow.rapidata_flow.RapidataFlow.get_flow_items","title":"get_flow_items","text":"<pre><code>get_flow_items() -&gt; list[RapidataFlowItem]\n</code></pre> <p>Query flow items for this flow, returning up to 100 most recent items sorted by creation date.</p> <p>Returns:</p> Type Description <code>list[RapidataFlowItem]</code> <p>list[RapidataFlowItem]: A list of flow items.</p> Source code in <code>src/rapidata/rapidata_client/flow/rapidata_flow.py</code> <pre><code>def get_flow_items(self) -&gt; list[RapidataFlowItem]:\n    \"\"\"Query flow items for this flow, returning up to 100 most recent items sorted by creation date.\n\n    Returns:\n        list[RapidataFlowItem]: A list of flow items.\n    \"\"\"\n    with tracer.start_as_current_span(\"RapidataFlow.get_flow_items\"):\n        from rapidata.rapidata_client.flow.rapidata_flow_item import (\n            RapidataFlowItem,\n        )\n\n        logger.debug(\"Getting flow items for flow '%s'\", self.name)\n\n        response = self._openapi_service.ranking_flow_item_api.flow_ranking_flow_id_item_get(\n            flow_id=self.id,\n            sort=[\"-created_at\"],\n            page=1,\n            page_size=100,\n        )\n\n        return [\n            RapidataFlowItem(\n                id=item.id,\n                flow_id=self.id,\n                openapi_service=self._openapi_service,\n            )\n            for item in response.items\n        ]\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/flow/rapidata_flow/#rapidata.rapidata_client.flow.rapidata_flow.RapidataFlow.update_config","title":"update_config","text":"<pre><code>update_config(\n    instruction: str | None = None,\n    starting_elo: int | None = None,\n    k_factor: int | None = None,\n    scaling_factor: int | None = None,\n) -&gt; None\n</code></pre> <p>Update the configuration of this ranking flow.</p> <p>Parameters:</p> Name Type Description Default <code>instruction</code> <code>str | None</code> <p>New instruction for comparisons.</p> <code>None</code> <code>starting_elo</code> <code>int | None</code> <p>New starting ELO rating.</p> <code>None</code> <code>k_factor</code> <code>int | None</code> <p>New K-factor for ELO calculations.</p> <code>None</code> <code>scaling_factor</code> <code>int | None</code> <p>New scaling factor for ELO calculations.</p> <code>None</code> Source code in <code>src/rapidata/rapidata_client/flow/rapidata_flow.py</code> <pre><code>def update_config(\n    self,\n    instruction: str | None = None,\n    starting_elo: int | None = None,\n    k_factor: int | None = None,\n    scaling_factor: int | None = None,\n) -&gt; None:\n    \"\"\"Update the configuration of this ranking flow.\n\n    Args:\n        instruction: New instruction for comparisons.\n        starting_elo: New starting ELO rating.\n        k_factor: New K-factor for ELO calculations.\n        scaling_factor: New scaling factor for ELO calculations.\n    \"\"\"\n    with tracer.start_as_current_span(\"RapidataFlow.update_config\"):\n        from rapidata.api_client.models.update_config_endpoint_input import (\n            UpdateConfigEndpointInput,\n        )\n\n        logger.debug(\"Updating config for flow '%s'\", self.name)\n\n        self._openapi_service.ranking_flow_api.flow_ranking_flow_id_config_patch(\n            flow_id=self.id,\n            update_config_endpoint_input=UpdateConfigEndpointInput(\n                criteria=instruction,\n                startingElo=starting_elo,\n                kFactor=k_factor,\n                scalingFactor=scaling_factor,\n                responsesRequired=100,\n            ),\n        )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/flow/rapidata_flow/#rapidata.rapidata_client.flow.rapidata_flow.RapidataFlow.delete","title":"delete","text":"<pre><code>delete() -&gt; None\n</code></pre> <p>Soft delete this flow.</p> Source code in <code>src/rapidata/rapidata_client/flow/rapidata_flow.py</code> <pre><code>def delete(self) -&gt; None:\n    \"\"\"Soft delete this flow.\"\"\"\n    with tracer.start_as_current_span(\"RapidataFlow.delete\"):\n        logger.debug(\"Deleting flow '%s'\", self.name)\n        self._openapi_service.flow_api.flow_flow_id_delete(flow_id=self.id)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/flow/rapidata_flow_item/","title":"Rapidata flow item","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/flow/rapidata_flow_item/#rapidata.rapidata_client.flow.rapidata_flow_item.RapidataFlowItem","title":"RapidataFlowItem","text":"<pre><code>RapidataFlowItem(\n    id: str, flow_id: str, openapi_service: OpenAPIService\n)\n</code></pre> Source code in <code>src/rapidata/rapidata_client/flow/rapidata_flow_item.py</code> <pre><code>def __init__(self, id: str, flow_id: str, openapi_service: OpenAPIService):\n    self.id = id\n    self.flow_id = flow_id\n    self._openapi_service = openapi_service\n    self._response_count: float | int | None = None\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/flow/rapidata_flow_item/#rapidata.rapidata_client.flow.rapidata_flow_item.RapidataFlowItem.get_response_count","title":"get_response_count","text":"<pre><code>get_response_count() -&gt; float | int\n</code></pre> <p>Get the total number of pairwise comparison responses for this flow item.</p> <p>The count is derived from the win/loss matrix by summing all entries. If the matrix hasn't been fetched yet, this will trigger a call to :meth:<code>get_win_loss_matrix</code>, which waits for the flow item to finish.</p> <p>Returns:</p> Type Description <code>float | int</code> <p>float | int: The total number of comparison votes collected.</p> Source code in <code>src/rapidata/rapidata_client/flow/rapidata_flow_item.py</code> <pre><code>def get_response_count(self) -&gt; float | int:\n    \"\"\"Get the total number of pairwise comparison responses for this flow item.\n\n    The count is derived from the win/loss matrix by summing all entries.\n    If the matrix hasn't been fetched yet, this will trigger a call to\n    :meth:`get_win_loss_matrix`, which waits for the flow item to finish.\n\n    Returns:\n        float | int: The total number of comparison votes collected.\n    \"\"\"\n    with tracer.start_as_current_span(\"RapidataFlowItem.get_response_count\"):\n        if self._response_count is None:\n            self.get_win_loss_matrix()\n        assert self._response_count is not None\n        return self._response_count\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/flow/rapidata_flow_item/#rapidata.rapidata_client.flow.rapidata_flow_item.RapidataFlowItem.get_status","title":"get_status","text":"<pre><code>get_status() -&gt; FlowItemState\n</code></pre> <p>Get the current state of this flow item.</p> <p>Returns:</p> Name Type Description <code>FlowItemState</code> <code>FlowItemState</code> <p>The current state (Pending, Running, Completed, Failed, Stopped, or Incomplete).</p> Source code in <code>src/rapidata/rapidata_client/flow/rapidata_flow_item.py</code> <pre><code>def get_status(self) -&gt; FlowItemState:\n    \"\"\"Get the current state of this flow item.\n\n    Returns:\n        FlowItemState: The current state (Pending, Running, Completed, Failed, Stopped, or Incomplete).\n    \"\"\"\n    with tracer.start_as_current_span(\"RapidataFlowItem.get_status\"):\n        logger.debug(\"Getting status for flow item '%s'\", self.id)\n        details = self._get_details()\n        return details.state\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/flow/rapidata_flow_item/#rapidata.rapidata_client.flow.rapidata_flow_item.RapidataFlowItem.get_results","title":"get_results","text":"<pre><code>get_results() -&gt; FlowItemResult\n</code></pre> <p>Get the results of this flow item from the API.</p> <p>Returns:</p> Name Type Description <code>FlowItemResult</code> <code>FlowItemResult</code> <p>Contains a mapping of asset identifier to elo score and the total number of votes.</p> Source code in <code>src/rapidata/rapidata_client/flow/rapidata_flow_item.py</code> <pre><code>def get_results(self) -&gt; FlowItemResult:\n    \"\"\"Get the results of this flow item from the API.\n\n    Returns:\n        FlowItemResult: Contains a mapping of asset identifier to elo score\n            and the total number of votes.\n    \"\"\"\n    with tracer.start_as_current_span(\"RapidataFlowItem.get_results\"):\n        from rapidata.api_client.models.flow_item_state import FlowItemState\n\n        logger.debug(\"Getting results for flow item '%s'\", self.id)\n        self._wait_for_state(\n            target_states=[\n                FlowItemState.COMPLETED,\n                FlowItemState.FAILED,\n                FlowItemState.STOPPED,\n                FlowItemState.INCOMPLETE,\n            ],\n            check_interval=1,\n            status_message=\"Flow item '%s' is in state %s, waiting for completion...\",\n        )\n\n        results = self._openapi_service.ranking_flow_item_api.flow_ranking_item_flow_item_id_results_get(\n            flow_item_id=self.id,\n        )\n\n        datapoints = {\n            self._extract_asset_key(dp): dp.get(\"elo\", 0)\n            for dp in (datapoint.to_dict() for datapoint in results.datapoints)\n        }\n\n        return FlowItemResult(\n            datapoints=datapoints,\n            total_votes=results.total_votes,\n        )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/flow/rapidata_flow_item/#rapidata.rapidata_client.flow.rapidata_flow_item.RapidataFlowItem.get_win_loss_matrix","title":"get_win_loss_matrix","text":"<pre><code>get_win_loss_matrix() -&gt; DataFrame\n</code></pre> <p>Get the win/loss matrix of this flow item from the API.</p> <p>The win/loss matrix shows pairwise comparison counts where <code>data[i][j]</code> is the number of times row <code>i</code> was preferred over column <code>j</code>.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: A DataFrame where rows and columns are asset identifiers, and values are win/loss counts.</p> Source code in <code>src/rapidata/rapidata_client/flow/rapidata_flow_item.py</code> <pre><code>def get_win_loss_matrix(self) -&gt; pd.DataFrame:\n    \"\"\"Get the win/loss matrix of this flow item from the API.\n\n    The win/loss matrix shows pairwise comparison counts where ``data[i][j]`` is\n    the number of times row ``i`` was preferred over column ``j``.\n\n    Returns:\n        pd.DataFrame: A DataFrame where rows and columns are asset identifiers,\n            and values are win/loss counts.\n    \"\"\"\n    with tracer.start_as_current_span(\"RapidataFlowItem.get_win_loss_matrix\"):\n        import pandas as pd\n        from rapidata.api_client.models.flow_item_state import FlowItemState\n\n        logger.debug(\"Getting win/loss matrix for flow item '%s'\", self.id)\n        self._wait_for_state(\n            target_states=[\n                FlowItemState.COMPLETED,\n                FlowItemState.FAILED,\n                FlowItemState.STOPPED,\n                FlowItemState.INCOMPLETE,\n            ],\n            check_interval=1,\n            status_message=\"Flow item '%s' is in state %s, waiting for completion...\",\n        )\n\n        result = self._openapi_service.ranking_flow_item_api.flow_ranking_item_flow_item_id_vote_matrix_get(\n            flow_item_id=self.id,\n        )\n        self._response_count = sum(sum(row) for row in result.data)\n\n        return pd.DataFrame(\n            data=result.data,\n            index=pd.Index(result.index),\n            columns=pd.Index(result.columns),\n        )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/flow/rapidata_flow_manager/","title":"Rapidata flow manager","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/flow/rapidata_flow_manager/#rapidata.rapidata_client.flow.rapidata_flow_manager.RapidataFlowManager","title":"RapidataFlowManager","text":"<pre><code>RapidataFlowManager(openapi_service: OpenAPIService)\n</code></pre> <p>Handles everything regarding flows from creation to retrieval.</p> <p>A manager for creating, retrieving, and searching for flows. Flows are used to add small flow items that can be solved fast without the order creation overhead.</p> Source code in <code>src/rapidata/rapidata_client/flow/rapidata_flow_manager.py</code> <pre><code>def __init__(self, openapi_service: OpenAPIService):\n    self._openapi_service = openapi_service\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/flow/rapidata_flow_manager/#rapidata.rapidata_client.flow.rapidata_flow_manager.RapidataFlowManager.create_ranking_flow","title":"create_ranking_flow","text":"<pre><code>create_ranking_flow(\n    name: str,\n    instruction: str,\n    max_response_threshold: int = 100,\n    min_response_threshold: int | None = None,\n    validation_set_id: str | None = None,\n    settings: Sequence[RapidataSetting] | None = None,\n) -&gt; RapidataFlow\n</code></pre> <p>Create a new ranking flow.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the flow.</p> required <code>instruction</code> <code>str</code> <p>The instruction for the ranking comparisons. Will be shown with each matchup.</p> required <code>max_response_threshold</code> <code>int</code> <p>The maximum number of responses that will be collected per flow item. Defaults to 100.</p> <code>100</code> <code>min_response_threshold</code> <code>int | None</code> <p>The minimum number of responses required for the flow to be considered complete in case of a timeout. Defaults to max_response_threshold.</p> <code>None</code> <code>validation_set_id</code> <code>str | None</code> <p>Optional validation set ID.</p> <code>None</code> <code>settings</code> <code>Sequence[RapidataSetting] | None</code> <p>Optional settings for the flow.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>RapidataFlow</code> <code>RapidataFlow</code> <p>The created flow instance.</p> Source code in <code>src/rapidata/rapidata_client/flow/rapidata_flow_manager.py</code> <pre><code>def create_ranking_flow(\n    self,\n    name: str,\n    instruction: str,\n    max_response_threshold: int = 100,\n    min_response_threshold: int | None = None,\n    validation_set_id: str | None = None,\n    settings: Sequence[RapidataSetting] | None = None,\n) -&gt; RapidataFlow:\n    \"\"\"Create a new ranking flow.\n\n    Args:\n        name: The name of the flow.\n        instruction: The instruction for the ranking comparisons. Will be shown with each matchup.\n        max_response_threshold: The maximum number of responses that will be collected per flow item. Defaults to 100.\n        min_response_threshold: The minimum number of responses required for the flow to be considered complete in case of a timeout. Defaults to max_response_threshold.\n        validation_set_id: Optional validation set ID.\n        settings: Optional settings for the flow.\n\n    Returns:\n        RapidataFlow: The created flow instance.\n    \"\"\"\n    if min_response_threshold is None:\n        min_response_threshold = max_response_threshold\n\n    with tracer.start_as_current_span(\"RapidataFlowManager.create_ranking_flow\"):\n        from rapidata.api_client.models.create_flow_endpoint_input import (\n            CreateFlowEndpointInput,\n        )\n        from rapidata.rapidata_client.flow.rapidata_flow import RapidataFlow\n\n        logger.debug(\"Creating ranking flow: %s\", name)\n\n        response = self._openapi_service.ranking_flow_api.flow_ranking_post(\n            create_flow_endpoint_input=CreateFlowEndpointInput(\n                name=name,\n                criteria=instruction,\n                validationSetId=validation_set_id,\n                minResponses=min_response_threshold,\n                maxResponses=max_response_threshold,\n                featureFlags=(\n                    [setting._to_feature_flag() for setting in settings]\n                    if settings\n                    else None\n                ),\n            ),\n        )\n\n        logger.debug(\"Flow created with id: %s\", response.flow_id)\n\n        return RapidataFlow(\n            id=response.flow_id,\n            name=name,\n            openapi_service=self._openapi_service,\n        )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/flow/rapidata_flow_manager/#rapidata.rapidata_client.flow.rapidata_flow_manager.RapidataFlowManager.get_flow_by_id","title":"get_flow_by_id","text":"<pre><code>get_flow_by_id(flow_id: str) -&gt; RapidataFlow\n</code></pre> <p>Get a flow by its ID.</p> <p>Parameters:</p> Name Type Description Default <code>flow_id</code> <code>str</code> <p>The ID of the flow.</p> required <p>Returns:</p> Name Type Description <code>RapidataFlow</code> <code>RapidataFlow</code> <p>The flow instance.</p> Source code in <code>src/rapidata/rapidata_client/flow/rapidata_flow_manager.py</code> <pre><code>def get_flow_by_id(self, flow_id: str) -&gt; RapidataFlow:\n    \"\"\"Get a flow by its ID.\n\n    Args:\n        flow_id: The ID of the flow.\n\n    Returns:\n        RapidataFlow: The flow instance.\n    \"\"\"\n    with tracer.start_as_current_span(\"RapidataFlowManager.get_flow_by_id\"):\n        from rapidata.rapidata_client.flow.rapidata_flow import RapidataFlow\n\n        logger.debug(\"Getting flow by id: %s\", flow_id)\n\n        response = self._openapi_service.flow_api.flow_flow_id_get(\n            flow_id=flow_id,\n        )\n\n        return RapidataFlow(\n            id=response.id,\n            name=response.name,\n            openapi_service=self._openapi_service,\n        )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/flow/rapidata_flow_manager/#rapidata.rapidata_client.flow.rapidata_flow_manager.RapidataFlowManager.find_flows","title":"find_flows","text":"<pre><code>find_flows(amount: int = 10) -&gt; list[RapidataFlow]\n</code></pre> <p>Find your recent flows.</p> <p>Parameters:</p> Name Type Description Default <code>amount</code> <code>int</code> <p>The maximum number of flows to return. Defaults to 10.</p> <code>10</code> <p>Returns:</p> Type Description <code>list[RapidataFlow]</code> <p>list[RapidataFlow]: A list of RapidataFlow instances.</p> Source code in <code>src/rapidata/rapidata_client/flow/rapidata_flow_manager.py</code> <pre><code>def find_flows(self, amount: int = 10) -&gt; list[RapidataFlow]:\n    \"\"\"Find your recent flows.\n\n    Args:\n        amount: The maximum number of flows to return. Defaults to 10.\n\n    Returns:\n        list[RapidataFlow]: A list of RapidataFlow instances.\n    \"\"\"\n    with tracer.start_as_current_span(\"RapidataFlowManager.find_flows\"):\n        from rapidata.rapidata_client.flow.rapidata_flow import RapidataFlow\n\n        logger.debug(\"Finding flows, amount: %s\", amount)\n\n        response = self._openapi_service.flow_api.flow_get()\n\n        return [\n            RapidataFlow(\n                id=flow.id,\n                name=flow.name,\n                openapi_service=self._openapi_service,\n            )\n            for flow in response.items[:amount]\n        ]\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/job/rapidata_job/","title":"Rapidata job","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/job/rapidata_job/#rapidata.rapidata_client.job.rapidata_job.RapidataJob","title":"RapidataJob","text":"<pre><code>RapidataJob(\n    job_id: str,\n    name: str,\n    audience_id: str,\n    created_at: datetime,\n    definition_id: str,\n    openapi_service: OpenAPIService,\n    pipeline_id: str | None = None,\n)\n</code></pre> <p>An instance of a Rapidata job.</p> <p>Used to interact with a specific job in the Rapidata system, such as getting status and retrieving results.</p> <p>A job is created from a job definition and an audience, and represents a specific run of that definition.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>The ID of the job.</p> required <code>name</code> <code>str</code> <p>The name of the job.</p> required <code>openapi_service</code> <code>OpenAPIService</code> <p>The OpenAPIService instance for API interaction.</p> required Source code in <code>src/rapidata/rapidata_client/job/rapidata_job.py</code> <pre><code>def __init__(\n    self,\n    job_id: str,\n    name: str,\n    audience_id: str,\n    created_at: datetime,\n    definition_id: str,\n    openapi_service: OpenAPIService,\n    pipeline_id: str | None = None,\n):\n    self.id = job_id\n    self.name = name\n    self.audience_id = audience_id\n    self._openapi_service = openapi_service\n    self.created_at = created_at\n    self.definition_id = definition_id\n    self.__pipeline_id = pipeline_id\n    self.__completed_at = None\n    self.job_details_page = f\"https://app.{self._openapi_service.environment}/audiences/{self.audience_id}/job/{self.id}\"\n    logger.debug(\"RapidataJob initialized\")\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/job/rapidata_job/#rapidata.rapidata_client.job.rapidata_job.RapidataJob.completed_at","title":"completed_at  <code>property</code>","text":"<pre><code>completed_at: datetime | None\n</code></pre> <p>Returns the completion date of the job, or None if not completed.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/job/rapidata_job/#rapidata.rapidata_client.job.rapidata_job.RapidataJob.pipeline_id","title":"pipeline_id  <code>property</code>","text":"<pre><code>pipeline_id: str\n</code></pre> <p>Returns the pipeline ID of the job.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/job/rapidata_job/#rapidata.rapidata_client.job.rapidata_job.RapidataJob.get_status","title":"get_status","text":"<pre><code>get_status() -&gt; str\n</code></pre> <p>Gets the status of the job.</p> <p>Returns:</p> Type Description <code>str</code> <p>The current status of the job as a string.</p> Source code in <code>src/rapidata/rapidata_client/job/rapidata_job.py</code> <pre><code>def get_status(self) -&gt; str:\n    \"\"\"\n    Gets the status of the job.\n\n    Returns:\n        The current status of the job as a string.\n    \"\"\"\n    with tracer.start_as_current_span(\"RapidataJob.get_status\"):\n        return self._openapi_service.job_api.job_job_id_get(self.id).status\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/job/rapidata_job/#rapidata.rapidata_client.job.rapidata_job.RapidataJob.get_results","title":"get_results","text":"<pre><code>get_results() -&gt; RapidataResults\n</code></pre> <p>Gets the results of the job.</p> <p>If wait_for_completion is True and the job is still processing, this method will block until the job is completed and then return the results.</p> <p>Returns:</p> Name Type Description <code>RapidataResults</code> <code>RapidataResults</code> <p>The results of the job.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If failed to get job results.</p> Source code in <code>src/rapidata/rapidata_client/job/rapidata_job.py</code> <pre><code>def get_results(self) -&gt; RapidataResults:\n    \"\"\"\n    Gets the results of the job.\n\n    If wait_for_completion is True and the job is still processing, this method\n    will block until the job is completed and then return the results.\n\n    Returns:\n        RapidataResults: The results of the job.\n\n    Raises:\n        Exception: If failed to get job results.\n    \"\"\"\n    with tracer.start_as_current_span(\"RapidataJob.get_results\"):\n        from rapidata.api_client.exceptions import ApiException\n        from rapidata.rapidata_client.results.rapidata_results import (\n            RapidataResults,\n        )\n\n        logger.info(\"Getting results for job '%s'...\", self)\n\n        self._wait_for_status(\n            target_statuses=[\"Completed\", \"Failed\"],\n            status_message=\"Job '%s' is in status %s, waiting for completion...\",\n        )\n\n        try:\n            results = self._openapi_service.job_api.job_job_id_results_get(\n                job_id=self.id\n            )\n            return RapidataResults(json.loads(results))\n        except (ApiException, json.JSONDecodeError) as e:\n            raise Exception(f\"Failed to get job results: {str(e)}\") from e\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/job/rapidata_job/#rapidata.rapidata_client.job.rapidata_job.RapidataJob.display_progress_bar","title":"display_progress_bar","text":"<pre><code>display_progress_bar(refresh_rate: int = 5) -&gt; None\n</code></pre> <p>Displays a progress bar for the job processing using tqdm.</p> <p>Parameters:</p> Name Type Description Default <code>refresh_rate</code> <code>int</code> <p>How often to refresh the progress bar, in seconds.</p> <code>5</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If refresh_rate is less than 1.</p> Source code in <code>src/rapidata/rapidata_client/job/rapidata_job.py</code> <pre><code>def display_progress_bar(self, refresh_rate: int = 5) -&gt; None:\n    \"\"\"\n    Displays a progress bar for the job processing using tqdm.\n\n    Args:\n        refresh_rate: How often to refresh the progress bar, in seconds.\n\n    Raises:\n        ValueError: If refresh_rate is less than 1.\n    \"\"\"\n    if refresh_rate &lt; 1:\n        raise ValueError(\"refresh_rate must be at least 1\")\n\n    current_status = self.get_status()\n    if current_status == \"Completed\":\n        managed_print(f\"Job '{self}' is already completed.\")\n        return\n\n    if current_status == \"Failed\":\n        failure_message = self._get_job_failure_message()\n        raise Exception(f\"Job '{self}' has failed: {failure_message}\")\n\n    # Get progress from pipeline if available\n    with tqdm(\n        total=100,\n        desc=\"Processing job\",\n        unit=\"%\",\n        bar_format=\"{desc}: {percentage:3.0f}%|{bar}| completed [{elapsed}&lt;{remaining}, {rate_fmt}]\",\n        disable=rapidata_config.logging.silent_mode,\n    ) as pbar:\n        last_percentage = 0\n        while True:\n            current_status = self.get_status()\n\n            if current_status == \"Completed\":\n                pbar.update(100 - last_percentage)\n                break\n\n            if current_status == \"Failed\":\n                failure_message = self._get_job_failure_message()\n                raise Exception(f\"Job '{self}' has failed: {failure_message}\")\n\n            # Try to get progress from workflow\n            try:\n                progress = self._get_workflow_progress()\n                current_percentage = (\n                    progress.completion_percentage if progress else 0\n                )\n\n                if current_percentage &gt; last_percentage:\n                    pbar.update(current_percentage - last_percentage)\n                    last_percentage = current_percentage\n            except Exception:\n                pass  # Continue without progress update if we can't get it\n\n            sleep(refresh_rate)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/job/rapidata_job/#rapidata.rapidata_client.job.rapidata_job.RapidataJob.view","title":"view","text":"<pre><code>view() -&gt; None\n</code></pre> <p>Opens the job details page in the browser.</p> Source code in <code>src/rapidata/rapidata_client/job/rapidata_job.py</code> <pre><code>def view(self) -&gt; None:\n    \"\"\"Opens the job details page in the browser.\"\"\"\n    logger.info(\"Opening job details page in browser...\")\n    if not webbrowser.open(self.job_details_page):\n        encoded_url = urllib.parse.quote(\n            self.job_details_page, safe=\"%/:=&amp;?~#+!$,;'@()*[]\"\n        )\n        managed_print(\n            Fore.RED\n            + f\"Please open this URL in your browser: '{encoded_url}'\"\n            + Fore.RESET\n        )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/job/rapidata_job_definition/","title":"Rapidata job definition","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/job/rapidata_job_definition/#rapidata.rapidata_client.job.rapidata_job_definition.RapidataJobDefinition","title":"RapidataJobDefinition","text":"<pre><code>RapidataJobDefinition(\n    id: str, name: str, openapi_service: OpenAPIService\n)\n</code></pre> Source code in <code>src/rapidata/rapidata_client/job/rapidata_job_definition.py</code> <pre><code>def __init__(\n    self,\n    id: str,\n    name: str,\n    openapi_service: OpenAPIService,\n):\n    self.id = id\n    self.name = name\n    self._openapi_service = openapi_service\n    self._job_details_page = (\n        f\"https://app.{self._openapi_service.environment}/definitions/{self.id}\"\n    )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/job/rapidata_job_definition/#rapidata.rapidata_client.job.rapidata_job_definition.RapidataJobDefinition.preview","title":"preview","text":"<pre><code>preview() -&gt; RapidataJobDefinition\n</code></pre> <p>Will open the browser where you can preview the job definition before giving it to an audience.</p> Source code in <code>src/rapidata/rapidata_client/job/rapidata_job_definition.py</code> <pre><code>def preview(self) -&gt; RapidataJobDefinition:\n    \"\"\"Will open the browser where you can preview the job definition before giving it to an audience.\"\"\"\n    logger.info(\"Opening order details page in browser...\")\n    if not webbrowser.open(self._job_details_page):\n        encoded_url = urllib.parse.quote(\n            self._job_details_page, safe=\"%/:=&amp;?~#+!$,;'@()*[]\"\n        )\n        managed_print(\n            Fore.RED\n            + f\"Please open this URL in your browser: '{encoded_url}'\"\n            + Fore.RESET\n        )\n    return self\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/job/rapidata_job_definition/#rapidata.rapidata_client.job.rapidata_job_definition.RapidataJobDefinition.update_dataset","title":"update_dataset","text":"<pre><code>update_dataset(\n    datapoints: list[str] | list[list[str]],\n    data_type: Literal[\"text\", \"media\"] = \"media\",\n    contexts: list[str] | None = None,\n    media_contexts: list[str] | None = None,\n    sentences: list[str] | None = None,\n    private_metadata: list[dict[str, str]] | None = None,\n) -&gt; RapidataJobDefinition\n</code></pre> <p>Update the dataset of the job definition.</p> <p>Parameters:</p> Name Type Description Default <code>datapoints</code> <code>list[str] | list[list[str]]</code> <p>paths to the datapoints or strings for text datapoints.</p> required <code>data_type</code> <code>Literal['text', 'media']</code> <p>The type of the datapoints.</p> <code>'media'</code> Source code in <code>src/rapidata/rapidata_client/job/rapidata_job_definition.py</code> <pre><code>def update_dataset(\n    self,\n    datapoints: list[str] | list[list[str]],\n    data_type: Literal[\"text\", \"media\"] = \"media\",\n    contexts: list[str] | None = None,\n    media_contexts: list[str] | None = None,\n    sentences: list[str] | None = None,\n    private_metadata: list[dict[str, str]] | None = None,\n) -&gt; RapidataJobDefinition:\n    \"\"\"Update the dataset of the job definition.\n\n    Args:\n        datapoints (list[str] | list[list[str]]): paths to the datapoints or strings for text datapoints.\n        data_type (Literal[\"text\", \"media\"]): The type of the datapoints.\n    \"\"\"\n    with tracer.start_as_current_span(\"JobDefinition.update_dataset\"):\n        from rapidata.rapidata_client.datapoints._datapoints_validator import (\n            DatapointsValidator,\n        )\n        from rapidata.api_client.models.create_dataset_endpoint_input import (\n            CreateDatasetEndpointInput,\n        )\n        from rapidata.rapidata_client.dataset._rapidata_dataset import (\n            RapidataDataset,\n        )\n        from rapidata.api_client.models.create_job_revision_endpoint_input import (\n            CreateJobRevisionEndpointInput,\n        )\n\n        datapoints_list = DatapointsValidator.map_datapoints(\n            datapoints=datapoints,\n            contexts=contexts,\n            media_contexts=media_contexts,\n            sentences=sentences,\n            private_metadata=private_metadata,\n            data_type=data_type,\n        )\n\n        dataset = self._openapi_service.dataset_api.dataset_post(\n            create_dataset_endpoint_input=CreateDatasetEndpointInput(\n                name=self.name + \"_dataset\"\n            )\n        )\n\n        rapidata_dataset = RapidataDataset(\n            dataset.dataset_id, self._openapi_service\n        )\n\n        with tracer.start_as_current_span(\"update_datapoints\"):\n            _, failed_uploads = rapidata_dataset.add_datapoints(datapoints_list)\n            if failed_uploads:\n                raise FailedUploadException(\n                    rapidata_dataset, failed_uploads, job_definition=self\n                )\n\n        self._openapi_service.job_api.job_definition_definition_id_revision_post(\n            definition_id=self.id,\n            create_job_revision_endpoint_input=CreateJobRevisionEndpointInput(\n                datasetId=rapidata_dataset.id,\n            ),\n        )\n\n        return self\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/job/rapidata_job_manager/","title":"Rapidata job manager","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/job/rapidata_job_manager/#rapidata.rapidata_client.job.rapidata_job_manager.RapidataJobManager","title":"RapidataJobManager","text":"<pre><code>RapidataJobManager(openapi_service: OpenAPIService)\n</code></pre> <p>A rapidata manager for job definitions. Used to create and retrieve job definitions.</p> Source code in <code>src/rapidata/rapidata_client/job/rapidata_job_manager.py</code> <pre><code>def __init__(self, openapi_service: OpenAPIService):\n    self._openapi_service = openapi_service\n\n    self.__priority: int | None = None\n    self._asset_uploader = AssetUploader(openapi_service)\n    logger.debug(\"JobManager initialized\")\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/job/rapidata_job_manager/#rapidata.rapidata_client.job.rapidata_job_manager.RapidataJobManager.create_classification_job_definition","title":"create_classification_job_definition","text":"<pre><code>create_classification_job_definition(\n    name: str,\n    instruction: str,\n    answer_options: list[str],\n    datapoints: list[str],\n    data_type: Literal[\"media\", \"text\"] = \"media\",\n    responses_per_datapoint: int = 10,\n    contexts: list[str] | None = None,\n    media_contexts: list[str] | None = None,\n    confidence_threshold: float | None = None,\n    settings: Sequence[RapidataSetting] | None = None,\n    private_metadata: list[dict[str, str]] | None = None,\n) -&gt; RapidataJobDefinition\n</code></pre> <p>Create a classification job definition.</p> <p>With this order you can have a datapoint (image, text, video, audio) be classified into one of the answer options. Each response will be exactly one of the answer options.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the job. (Will not be shown to the labeler)</p> required <code>instruction</code> <code>str</code> <p>The instruction for how the data should be classified.</p> required <code>answer_options</code> <code>list[str]</code> <p>The list of options for the classification.</p> required <code>datapoints</code> <code>list[str]</code> <p>The list of datapoints for the classification - each datapoint will be labeled.</p> required <code>data_type</code> <code>str</code> <p>The data type of the datapoints. Defaults to \"media\" (any form of image, video or audio). </p> <p>Other option: \"text\".</p> <code>'media'</code> <code>responses_per_datapoint</code> <code>int</code> <p>The number of responses that will be collected per datapoint. Defaults to 10.</p> <code>10</code> <code>contexts</code> <code>list[str]</code> <p>The list of contexts for the classification. Defaults to None.</p> <p>If provided has to be the same length as datapoints and will be shown in addition to the instruction and options. (Therefore will be different for each datapoint) Will be match up with the datapoints using the list index.</p> <code>None</code> <code>media_contexts</code> <code>list[str]</code> <p>The list of media contexts for the classification i.e links to the images / videos. Defaults to None.</p> <p>If provided has to be the same length as datapoints and will be shown in addition to the instruction and options. (Therefore will be different for each datapoint)</p> <code>None</code> <code>confidence_threshold</code> <code>float</code> <p>The probability threshold for the classification. Defaults to None.</p> <p>If provided, the classification datapoint will stop after the threshold is reached or at the number of responses, whatever happens first.</p> <code>None</code> <code>settings</code> <code>Sequence[RapidataSetting]</code> <p>The list of settings for the classification. Defaults to []. Decides how the tasks should be shown.</p> <code>None</code> <code>private_metadata</code> <code>list[dict[str, str]]</code> <p>Key-value string pairs for each datapoint. Defaults to None. If provided has to be the same length as datapoints.</p> <p>This will NOT be shown to the labelers but will be included in the result purely for your own reference.</p> <code>None</code> Source code in <code>src/rapidata/rapidata_client/job/rapidata_job_manager.py</code> <pre><code>def create_classification_job_definition(\n    self,\n    name: str,\n    instruction: str,\n    answer_options: list[str],\n    datapoints: list[str],\n    data_type: Literal[\"media\", \"text\"] = \"media\",\n    responses_per_datapoint: int = 10,\n    contexts: list[str] | None = None,\n    media_contexts: list[str] | None = None,\n    confidence_threshold: float | None = None,\n    settings: Sequence[RapidataSetting] | None = None,\n    private_metadata: list[dict[str, str]] | None = None,\n) -&gt; RapidataJobDefinition:\n    \"\"\"Create a classification job definition.\n\n    With this order you can have a datapoint (image, text, video, audio) be classified into one of the answer options.\n    Each response will be exactly one of the answer options.\n\n    Args:\n        name (str): The name of the job. (Will not be shown to the labeler)\n        instruction (str): The instruction for how the data should be classified.\n        answer_options (list[str]): The list of options for the classification.\n        datapoints (list[str]): The list of datapoints for the classification - each datapoint will be labeled.\n        data_type (str, optional): The data type of the datapoints. Defaults to \"media\" (any form of image, video or audio). \\n\n            Other option: \"text\".\n        responses_per_datapoint (int, optional): The number of responses that will be collected per datapoint. Defaults to 10.\n        contexts (list[str], optional): The list of contexts for the classification. Defaults to None.\\n\n            If provided has to be the same length as datapoints and will be shown in addition to the instruction and options. (Therefore will be different for each datapoint)\n            Will be match up with the datapoints using the list index.\n        media_contexts (list[str], optional): The list of media contexts for the classification i.e links to the images / videos. Defaults to None.\\n\n            If provided has to be the same length as datapoints and will be shown in addition to the instruction and options. (Therefore will be different for each datapoint)\n        confidence_threshold (float, optional): The probability threshold for the classification. Defaults to None.\\n\n            If provided, the classification datapoint will stop after the threshold is reached or at the number of responses, whatever happens first.\n        settings (Sequence[RapidataSetting], optional): The list of settings for the classification. Defaults to []. Decides how the tasks should be shown.\n        private_metadata (list[dict[str, str]], optional): Key-value string pairs for each datapoint. Defaults to None.\n            If provided has to be the same length as datapoints.\\n\n            This will NOT be shown to the labelers but will be included in the result purely for your own reference.\n    \"\"\"\n    with tracer.start_as_current_span(\"JobManager.create_classification_job\"):\n        if not isinstance(datapoints, list) or not all(\n            isinstance(datapoint, str) for datapoint in datapoints\n        ):\n            raise ValueError(\"Datapoints must be a list of strings\")\n\n        from rapidata.rapidata_client.workflow import ClassifyWorkflow\n\n        datapoints_instances = DatapointsValidator.map_datapoints(\n            datapoints=datapoints,\n            contexts=contexts,\n            media_contexts=media_contexts,\n            private_metadata=private_metadata,\n            data_type=data_type,\n        )\n        return self._create_general_job_definition(\n            name=name,\n            workflow=ClassifyWorkflow(\n                instruction=instruction, answer_options=answer_options\n            ),\n            datapoints=datapoints_instances,\n            responses_per_datapoint=responses_per_datapoint,\n            confidence_threshold=confidence_threshold,\n            settings=settings,\n        )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/job/rapidata_job_manager/#rapidata.rapidata_client.job.rapidata_job_manager.RapidataJobManager.create_compare_job_definition","title":"create_compare_job_definition","text":"<pre><code>create_compare_job_definition(\n    name: str,\n    instruction: str,\n    datapoints: list[list[str]],\n    data_type: Literal[\"media\", \"text\"] = \"media\",\n    responses_per_datapoint: int = 10,\n    contexts: list[str] | None = None,\n    media_contexts: list[str] | None = None,\n    a_b_names: list[str] | None = None,\n    confidence_threshold: float | None = None,\n    settings: Sequence[RapidataSetting] | None = None,\n    private_metadata: list[dict[str, str]] | None = None,\n) -&gt; RapidataJobDefinition\n</code></pre> <p>Create a compare job definition.</p> <p>With this order you compare two datapoints (image, text, video, audio) and the annotators will choose one of the two based on the instruction.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the job. (Will not be shown to the labeler)</p> required <code>instruction</code> <code>str</code> <p>The instruction for the comparison. Will be shown along side each datapoint.</p> required <code>datapoints</code> <code>list[list[str]]</code> <p>Outher list is the datapoints, inner list is the options for the comparison - each datapoint will be labeled.</p> required <code>data_type</code> <code>str</code> <p>The data type of the datapoints. Defaults to \"media\" (any form of image, video or audio). </p> <p>Other option: \"text\".</p> <code>'media'</code> <code>responses_per_datapoint</code> <code>int</code> <p>The number of responses that will be collected per datapoint. Defaults to 10.</p> <code>10</code> <code>contexts</code> <code>list[str]</code> <p>The list of contexts for the comparison. Defaults to None.</p> <p>If provided has to be the same length as datapoints and will be shown in addition to the instruction. (Therefore will be different for each datapoint) Will be matched up with the datapoints using the list index.</p> <code>None</code> <code>media_contexts</code> <code>list[str]</code> <p>The list of media contexts i.e. links to the images / videos for the comparison. Defaults to None.</p> <p>If provided has to be the same length as datapoints and will be shown in addition to the instruction. (Therefore will be different for each datapoint) Will be matched up with the datapoints using the list index.</p> <code>None</code> <code>a_b_names</code> <code>list[str]</code> <p>Custom naming for the two opposing models defined by the index in the datapoints list. Defaults to None.</p> <p>If provided has to be a list of exactly two strings. example: </p><pre><code>datapoints = [[\"path_to_image_A\", \"path_to_image_B\"], [\"path_to_text_A\", \"path_to_text_B\"]]\na_b_naming = [\"Model A\", \"Model B\"]\n</code></pre> The results will then correctly show \"Model A\" and \"Model B\". If not provided, the results will be shown as \"A\" and \"B\".<p></p> <code>None</code> <code>confidence_threshold</code> <code>float</code> <p>The probability threshold for the comparison. Defaults to None.</p> <p>If provided, the comparison datapoint will stop after the threshold is reached or at the number of responses, whatever happens first.</p> <code>None</code> <code>settings</code> <code>Sequence[RapidataSetting]</code> <p>The list of settings for the comparison. Defaults to []. Decides how the tasks should be shown.</p> <code>None</code> <code>private_metadata</code> <code>list[dict[str, str]]</code> <p>Key-value string pairs for each datapoint. Defaults to None.</p> <p>If provided has to be the same length as datapoints.</p> <p>This will NOT be shown to the labelers but will be included in the result purely for your own reference.</p> <code>None</code> Source code in <code>src/rapidata/rapidata_client/job/rapidata_job_manager.py</code> <pre><code>def create_compare_job_definition(\n    self,\n    name: str,\n    instruction: str,\n    datapoints: list[list[str]],\n    data_type: Literal[\"media\", \"text\"] = \"media\",\n    responses_per_datapoint: int = 10,\n    contexts: list[str] | None = None,\n    media_contexts: list[str] | None = None,\n    a_b_names: list[str] | None = None,\n    confidence_threshold: float | None = None,\n    settings: Sequence[RapidataSetting] | None = None,\n    private_metadata: list[dict[str, str]] | None = None,\n) -&gt; RapidataJobDefinition:\n    \"\"\"Create a compare job definition.\n\n    With this order you compare two datapoints (image, text, video, audio) and the annotators will choose one of the two based on the instruction.\n\n    Args:\n        name (str): The name of the job. (Will not be shown to the labeler)\n        instruction (str): The instruction for the comparison. Will be shown along side each datapoint.\n        datapoints (list[list[str]]): Outher list is the datapoints, inner list is the options for the comparison - each datapoint will be labeled.\n        data_type (str, optional): The data type of the datapoints. Defaults to \"media\" (any form of image, video or audio). \\n\n            Other option: \"text\".\n        responses_per_datapoint (int, optional): The number of responses that will be collected per datapoint. Defaults to 10.\n        contexts (list[str], optional): The list of contexts for the comparison. Defaults to None.\\n\n            If provided has to be the same length as datapoints and will be shown in addition to the instruction. (Therefore will be different for each datapoint)\n            Will be matched up with the datapoints using the list index.\n        media_contexts (list[str], optional): The list of media contexts i.e. links to the images / videos for the comparison. Defaults to None.\\n\n            If provided has to be the same length as datapoints and will be shown in addition to the instruction. (Therefore will be different for each datapoint)\n            Will be matched up with the datapoints using the list index.\n        a_b_names (list[str], optional): Custom naming for the two opposing models defined by the index in the datapoints list. Defaults to None.\\n\n            If provided has to be a list of exactly two strings.\n            example:\n            ```python\n            datapoints = [[\"path_to_image_A\", \"path_to_image_B\"], [\"path_to_text_A\", \"path_to_text_B\"]]\n            a_b_naming = [\"Model A\", \"Model B\"]\n            ```\n            The results will then correctly show \"Model A\" and \"Model B\".\n            If not provided, the results will be shown as \"A\" and \"B\".\n        confidence_threshold (float, optional): The probability threshold for the comparison. Defaults to None.\\n\n            If provided, the comparison datapoint will stop after the threshold is reached or at the number of responses, whatever happens first.\n        settings (Sequence[RapidataSetting], optional): The list of settings for the comparison. Defaults to []. Decides how the tasks should be shown.\n        private_metadata (list[dict[str, str]], optional): Key-value string pairs for each datapoint. Defaults to None.\\n\n            If provided has to be the same length as datapoints.\\n\n            This will NOT be shown to the labelers but will be included in the result purely for your own reference.\n    \"\"\"\n    with tracer.start_as_current_span(\"JobManager.create_compare_job\"):\n        if any(not isinstance(datapoint, list) for datapoint in datapoints):\n            raise ValueError(\"Each datapoint must be a list of 2 paths/texts\")\n\n        if any(len(set(datapoint)) != 2 for datapoint in datapoints):\n            raise ValueError(\n                \"Each datapoint must contain exactly two unique options\"\n            )\n\n        if a_b_names is not None and len(a_b_names) != 2:\n            raise ValueError(\n                \"A_B_naming must be a list of exactly two strings or None\"\n            )\n\n        from rapidata.rapidata_client.workflow import CompareWorkflow\n\n        datapoints_instances = DatapointsValidator.map_datapoints(\n            datapoints=datapoints,\n            contexts=contexts,\n            media_contexts=media_contexts,\n            private_metadata=private_metadata,\n            data_type=data_type,\n            multi_asset=True,\n        )\n        return self._create_general_job_definition(\n            name=name,\n            workflow=CompareWorkflow(instruction=instruction, a_b_names=a_b_names),\n            datapoints=datapoints_instances,\n            responses_per_datapoint=responses_per_datapoint,\n            confidence_threshold=confidence_threshold,\n            settings=settings,\n        )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/job/rapidata_job_manager/#rapidata.rapidata_client.job.rapidata_job_manager.RapidataJobManager.get_job_definition_by_id","title":"get_job_definition_by_id","text":"<pre><code>get_job_definition_by_id(\n    job_definition_id: str,\n) -&gt; RapidataJobDefinition\n</code></pre> <p>Get a job definition by ID.</p> <p>Parameters:</p> Name Type Description Default <code>job_definition_id</code> <code>str</code> <p>The ID of the job definition.</p> required <p>Returns:</p> Name Type Description <code>JobDefinition</code> <code>RapidataJobDefinition</code> <p>The JobDefinition instance.</p> Source code in <code>src/rapidata/rapidata_client/job/rapidata_job_manager.py</code> <pre><code>def get_job_definition_by_id(self, job_definition_id: str) -&gt; RapidataJobDefinition:\n    \"\"\"Get a job definition by ID.\n\n    Args:\n        job_definition_id (str): The ID of the job definition.\n\n    Returns:\n        JobDefinition: The JobDefinition instance.\n    \"\"\"\n    with tracer.start_as_current_span(\"JobManager.get_job_definition_by_id\"):\n\n        job_definition = (\n            self._openapi_service.job_api.job_definition_definition_id_get(\n                definition_id=job_definition_id,\n            )\n        )\n\n        return RapidataJobDefinition(\n            id=job_definition.definition_id,\n            name=job_definition.name,\n            openapi_service=self._openapi_service,\n        )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/job/rapidata_job_manager/#rapidata.rapidata_client.job.rapidata_job_manager.RapidataJobManager.find_job_definitions","title":"find_job_definitions","text":"<pre><code>find_job_definitions(\n    name: str = \"\", amount: int = 10\n) -&gt; list[RapidataJobDefinition]\n</code></pre> <p>Find your recent jobs given criteria. If nothing is provided, it will return the most recent job definitions.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the job definition - matching job definition will contain the name. Defaults to \"\" for any job definition.</p> <code>''</code> <code>amount</code> <code>int</code> <p>The amount of job definitions to return. Defaults to 10.</p> <code>10</code> <p>Returns:</p> Type Description <code>list[RapidataJobDefinition]</code> <p>list[JobDefinition]: A list of JobDefinition instances.</p> Source code in <code>src/rapidata/rapidata_client/job/rapidata_job_manager.py</code> <pre><code>def find_job_definitions(\n    self, name: str = \"\", amount: int = 10\n) -&gt; list[RapidataJobDefinition]:\n    \"\"\"Find your recent jobs given criteria. If nothing is provided, it will return the most recent job definitions.\n\n    Args:\n        name (str, optional): The name of the job definition - matching job definition will contain the name. Defaults to \"\" for any job definition.\n        amount (int, optional): The amount of job definitions to return. Defaults to 10.\n\n    Returns:\n        list[JobDefinition]: A list of JobDefinition instances.\n    \"\"\"\n    with tracer.start_as_current_span(\"JobManager.find_job_definitions\"):\n        from rapidata.api_client.models.page_info import PageInfo\n        from rapidata.api_client.models.query_model import QueryModel\n        from rapidata.api_client.models.root_filter import RootFilter\n        from rapidata.api_client.models.filter import Filter\n        from rapidata.api_client.models.filter_operator import FilterOperator\n        from rapidata.api_client.models.sort_criterion import SortCriterion\n        from rapidata.api_client.models.sort_direction import SortDirection\n\n        job_definition_page_result = (\n            self._openapi_service.job_api.job_definitions_get(\n                request=QueryModel(\n                    page=PageInfo(index=1, size=amount),\n                    filter=RootFilter(\n                        filters=[\n                            Filter(\n                                field=\"Name\",\n                                operator=FilterOperator.CONTAINS,\n                                value=name,\n                            )\n                        ]\n                    ),\n                    sortCriteria=[\n                        SortCriterion(\n                            direction=SortDirection.DESC, propertyName=\"CreatedAt\"\n                        )\n                    ],\n                ),\n            )\n        )\n\n        jobs = [\n            RapidataJobDefinition(\n                id=job_def.definition_id,\n                name=job_def.name,\n                openapi_service=self._openapi_service,\n            )\n            for job_def in job_definition_page_result.items\n        ]\n        return jobs\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/job/rapidata_job_manager/#rapidata.rapidata_client.job.rapidata_job_manager.RapidataJobManager.get_job_by_id","title":"get_job_by_id","text":"<pre><code>get_job_by_id(job_id: str) -&gt; RapidataJob\n</code></pre> <p>Get a job by ID.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>The ID of the job.</p> required <p>Returns:</p> Name Type Description <code>RapidataJob</code> <code>RapidataJob</code> <p>The Job instance.</p> Source code in <code>src/rapidata/rapidata_client/job/rapidata_job_manager.py</code> <pre><code>def get_job_by_id(self, job_id: str) -&gt; RapidataJob:\n    \"\"\"Get a job by ID.\n\n    Args:\n        job_id (str): The ID of the job.\n\n    Returns:\n        RapidataJob: The Job instance.\n    \"\"\"\n    with tracer.start_as_current_span(\"JobManager.get_job_by_id\"):\n        from rapidata.rapidata_client.job.rapidata_job import RapidataJob\n\n        job_response = self._openapi_service.job_api.job_job_id_get(\n            job_id=job_id,\n        )\n        return RapidataJob(\n            job_id=job_response.job_id,\n            name=job_response.name,\n            audience_id=job_response.audience_id,\n            created_at=job_response.created_at,\n            definition_id=job_response.definition_id,\n            openapi_service=self._openapi_service,\n            pipeline_id=job_response.pipeline_id,\n        )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/job/rapidata_job_manager/#rapidata.rapidata_client.job.rapidata_job_manager.RapidataJobManager.find_jobs","title":"find_jobs","text":"<pre><code>find_jobs(\n    name: str = \"\", amount: int = 10\n) -&gt; list[RapidataJob]\n</code></pre> <p>Find your recent jobs given criteria. If nothing is provided, it will return the most recent jobs.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the job - matching job will contain the name. Defaults to \"\" for any job.</p> <code>''</code> <code>amount</code> <code>int</code> <p>The amount of jobs to return. Defaults to 10.</p> <code>10</code> <p>Returns:</p> Type Description <code>list[RapidataJob]</code> <p>list[RapidataJob]: A list of RapidataJob instances.</p> Source code in <code>src/rapidata/rapidata_client/job/rapidata_job_manager.py</code> <pre><code>def find_jobs(self, name: str = \"\", amount: int = 10) -&gt; list[RapidataJob]:\n    \"\"\"Find your recent jobs given criteria. If nothing is provided, it will return the most recent jobs.\n\n    Args:\n        name (str, optional): The name of the job - matching job will contain the name. Defaults to \"\" for any job.\n        amount (int, optional): The amount of jobs to return. Defaults to 10.\n\n    Returns:\n        list[RapidataJob]: A list of RapidataJob instances.\n    \"\"\"\n    with tracer.start_as_current_span(\"JobManager.find_jobs\"):\n        from rapidata.api_client.models.query_model import QueryModel\n        from rapidata.api_client.models.root_filter import RootFilter\n        from rapidata.api_client.models.filter import Filter\n        from rapidata.api_client.models.filter_operator import FilterOperator\n        from rapidata.api_client.models.page_info import PageInfo\n        from rapidata.api_client.models.sort_criterion import SortCriterion\n        from rapidata.api_client.models.sort_direction import SortDirection\n        from rapidata.rapidata_client.job.rapidata_job import RapidataJob\n\n        response = self._openapi_service.job_api.jobs_get(\n            request=QueryModel(\n                page=PageInfo(index=1, size=amount),\n                filter=RootFilter(\n                    filters=[\n                        Filter(\n                            field=\"Name\",\n                            operator=FilterOperator.CONTAINS,\n                            value=name,\n                        )\n                    ]\n                ),\n                sortCriteria=[\n                    SortCriterion(\n                        direction=SortDirection.DESC, propertyName=\"CreatedAt\"\n                    )\n                ],\n            ),\n        )\n        jobs = [\n            RapidataJob(\n                job_id=job.job_id,\n                name=job.name,\n                audience_id=job.audience_id,\n                created_at=job.created_at,\n                definition_id=job.definition_id,\n                openapi_service=self._openapi_service,\n                pipeline_id=job.pipeline_id,\n            )\n            for job in response.items\n        ]\n        return jobs\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/order/rapidata_order/","title":"Rapidata order","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/order/rapidata_order/#rapidata.rapidata_client.order.rapidata_order.RapidataOrder","title":"RapidataOrder","text":"<pre><code>RapidataOrder(\n    name: str,\n    order_id: str,\n    openapi_service: OpenAPIService,\n)\n</code></pre> <p>An instance of a Rapidata order.</p> <p>Used to interact with a specific order in the Rapidata system, such as starting, pausing, and retrieving results.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the order.</p> required <code>order_id</code> <code>str</code> <p>The ID of the order.</p> required <code>openapi_service</code> <code>OpenAPIService</code> <p>The OpenAPIService instance for API interaction.</p> required Source code in <code>src/rapidata/rapidata_client/order/rapidata_order.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    order_id: str,\n    openapi_service: OpenAPIService,\n):\n    self.id = order_id\n    self.name = name\n    self.__created_at: datetime | None = None\n    self._openapi_service = openapi_service\n    self.__workflow_id: str = \"\"\n    self.__campaign_id: str = \"\"\n    self.__pipeline_id: str = \"\"\n    self.order_details_page = (\n        f\"https://app.{self._openapi_service.environment}/order/detail/{self.id}\"\n    )\n    logger.debug(\"RapidataOrder initialized\")\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/order/rapidata_order/#rapidata.rapidata_client.order.rapidata_order.RapidataOrder.created_at","title":"created_at  <code>property</code>","text":"<pre><code>created_at: datetime\n</code></pre> <p>Returns the creation date of the order.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/order/rapidata_order/#rapidata.rapidata_client.order.rapidata_order.RapidataOrder.run","title":"run","text":"<pre><code>run(\n    after: RapidataOrder | str | None = None,\n) -&gt; RapidataOrder\n</code></pre> <p>Runs the order to start collecting responses. Args:     after: The order to set as the preceding order. So order will only start collecting responses after the preceding order is completed.         Can be a RapidataOrder instance, a string order ID, or None.         If None, the order will start collecting responses immediately. Returns:     The order itself.</p> Source code in <code>src/rapidata/rapidata_client/order/rapidata_order.py</code> <pre><code>def run(self, after: RapidataOrder | str | None = None) -&gt; RapidataOrder:\n    \"\"\"Runs the order to start collecting responses.\n    Args:\n        after: The order to set as the preceding order. So order will only start collecting responses after the preceding order is completed.\n            Can be a RapidataOrder instance, a string order ID, or None.\n            If None, the order will start collecting responses immediately.\n    Returns:\n        The order itself.\n    \"\"\"\n    with tracer.start_as_current_span(\"RapidataOrder.run\"):\n        from rapidata.api_client.models.submit_order_model import SubmitOrderModel\n\n        if after:\n            logger.info(\n                \"Setting preceding order for order '%s' to '%s'\", self, after\n            )\n            from rapidata.api_client.models.update_order_model import (\n                UpdateOrderModel,\n            )\n\n            self._openapi_service.order_api.order_order_id_patch(\n                self.id,\n                UpdateOrderModel(\n                    precedingOrderId=(\n                        after.id if isinstance(after, RapidataOrder) else after\n                    )\n                ),\n            )\n\n        logger.info(\"Starting order '%s'\", self)\n        self._openapi_service.order_api.order_order_id_submit_post(\n            self.id, SubmitOrderModel(ignoreFailedDatapoints=True)\n        )\n        logger.debug(\"Order '%s' has been started.\", self)\n        managed_print(\n            f\"Order '{self.name}' is now viewable under: {self.order_details_page}\"\n        )\n        return self\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/order/rapidata_order/#rapidata.rapidata_client.order.rapidata_order.RapidataOrder.pause","title":"pause","text":"<pre><code>pause() -&gt; None\n</code></pre> <p>Pauses the order.</p> Source code in <code>src/rapidata/rapidata_client/order/rapidata_order.py</code> <pre><code>def pause(self) -&gt; None:\n    \"\"\"Pauses the order.\"\"\"\n    with tracer.start_as_current_span(\"RapidataOrder.pause\"):\n        logger.info(\"Pausing order '%s'\", self)\n        self._openapi_service.order_api.order_order_id_pause_post(self.id)\n        logger.debug(\"Order '%s' has been paused.\", self)\n        managed_print(f\"Order '{self}' has been paused.\")\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/order/rapidata_order/#rapidata.rapidata_client.order.rapidata_order.RapidataOrder.unpause","title":"unpause","text":"<pre><code>unpause() -&gt; None\n</code></pre> <p>Unpauses/resumes the order.</p> Source code in <code>src/rapidata/rapidata_client/order/rapidata_order.py</code> <pre><code>def unpause(self) -&gt; None:\n    \"\"\"Unpauses/resumes the order.\"\"\"\n    with tracer.start_as_current_span(\"RapidataOrder.unpause\"):\n        logger.info(\"Unpausing order '%s'\", self)\n        self._openapi_service.order_api.order_order_id_resume_post(self.id)\n        logger.debug(\"Order '%s' has been unpaused.\", self)\n        managed_print(f\"Order '{self}' has been unpaused.\")\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/order/rapidata_order/#rapidata.rapidata_client.order.rapidata_order.RapidataOrder.delete","title":"delete","text":"<pre><code>delete() -&gt; None\n</code></pre> <p>Deletes the order.</p> Source code in <code>src/rapidata/rapidata_client/order/rapidata_order.py</code> <pre><code>def delete(self) -&gt; None:\n    \"\"\"Deletes the order.\"\"\"\n    with tracer.start_as_current_span(\"RapidataOrder.delete\"):\n        logger.info(\"Deleting order '%s'\", self)\n        self._openapi_service.order_api.order_order_id_delete(self.id)\n        logger.debug(\"Order '%s' has been deleted.\", self)\n        managed_print(f\"Order '{self}' has been deleted.\")\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/order/rapidata_order/#rapidata.rapidata_client.order.rapidata_order.RapidataOrder.get_status","title":"get_status","text":"<pre><code>get_status() -&gt; str\n</code></pre> <p>Gets the status of the order.</p> States <p>Created: The order has been created but not started yet.</p> <p>Preview: The order has been set up and ready but not collecting responses yet.</p> <p>Submitted: The order has been submitted and is being reviewed.</p> <p>ManualReview: The order is in manual review - something went wrong with the automatic approval.</p> <p>Processing: The order is actively being processed.</p> <p>Paused: The order has been paused.</p> <p>Completed: The order has been completed.</p> <p>Failed: The order has failed.</p> Source code in <code>src/rapidata/rapidata_client/order/rapidata_order.py</code> <pre><code>def get_status(self) -&gt; str:\n    \"\"\"\n    Gets the status of the order.\n\n    States:\n        Created: The order has been created but not started yet.\\n\n        Preview: The order has been set up and ready but not collecting responses yet.\\n\n        Submitted: The order has been submitted and is being reviewed.\\n\n        ManualReview: The order is in manual review - something went wrong with the automatic approval.\\n\n        Processing: The order is actively being processed.\\n\n        Paused: The order has been paused.\\n\n        Completed: The order has been completed.\\n\n        Failed: The order has failed.\n    \"\"\"\n    with tracer.start_as_current_span(\"RapidataOrder.get_status\"):\n        return self._openapi_service.order_api.order_order_id_get(self.id).state\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/order/rapidata_order/#rapidata.rapidata_client.order.rapidata_order.RapidataOrder.display_progress_bar","title":"display_progress_bar","text":"<pre><code>display_progress_bar(refresh_rate: int = 5) -&gt; None\n</code></pre> <p>Displays a progress bar for the order processing using tqdm.</p> <p>Parameters:</p> Name Type Description Default <code>refresh_rate</code> <code>int</code> <p>How often to refresh the progress bar, in seconds.</p> <code>5</code> Source code in <code>src/rapidata/rapidata_client/order/rapidata_order.py</code> <pre><code>def display_progress_bar(self, refresh_rate: int = 5) -&gt; None:\n    \"\"\"\n    Displays a progress bar for the order processing using tqdm.\n\n    Args:\n        refresh_rate: How often to refresh the progress bar, in seconds.\n    \"\"\"\n    from rapidata.api_client.models.order_state import OrderState\n\n    if refresh_rate &lt; 1:\n        raise ValueError(\"refresh_rate must be at least 1\")\n\n    if self.get_status() == OrderState.CREATED:\n        raise Exception(\"Order has not been started yet. Please start it first.\")\n\n    # Wait for submission review\n    while self.get_status() == OrderState.SUBMITTED:\n        managed_print(\n            f\"Order '{self}' is submitted and being reviewed. Standby...\", end=\"\\r\"\n        )\n        sleep(1)\n\n    if self.get_status() == OrderState.MANUALREVIEW:\n        raise Exception(\n            f\"Order '{self}' is in manual review. It might take some time to start. \"\n            f\"To speed up the process, contact support (info@rapidata.ai).\\n\"\n            f\"Once started, run this method again to display the progress bar.\"\n        )\n\n    with tqdm(\n        total=100,\n        desc=\"Processing order\",\n        unit=\"%\",\n        bar_format=\"{desc}: {percentage:3.0f}%|{bar}| completed [{elapsed}&lt;{remaining}, {rate_fmt}]\",\n        disable=rapidata_config.logging.silent_mode,\n    ) as pbar:\n        last_percentage = 0\n        while True:\n            current_percentage = (\n                self.__get_workflow_progress().completion_percentage\n            )\n\n            if current_percentage &gt; last_percentage:\n                pbar.update(current_percentage - last_percentage)\n                last_percentage = current_percentage\n\n            if current_percentage &gt;= 100:\n                break\n\n            sleep(refresh_rate)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/order/rapidata_order/#rapidata.rapidata_client.order.rapidata_order.RapidataOrder.get_results","title":"get_results","text":"<pre><code>get_results(\n    preliminary_results: bool = False,\n) -&gt; RapidataResults\n</code></pre> <p>Gets the results of the order. If the order is still processing, this method will block until the order is completed and then return the results.</p> <p>Parameters:</p> Name Type Description Default <code>preliminary_results</code> <code>bool</code> <p>If True, returns the preliminary results of the order. Defaults to False. Note that preliminary results are not final and may not contain all the datapoints &amp; responses. Only the ones that are already available.</p> <code>False</code> Source code in <code>src/rapidata/rapidata_client/order/rapidata_order.py</code> <pre><code>def get_results(self, preliminary_results: bool = False) -&gt; RapidataResults:\n    \"\"\"\n    Gets the results of the order.\n    If the order is still processing, this method will block until the order is completed and then return the results.\n\n    Args:\n        preliminary_results: If True, returns the preliminary results of the order. Defaults to False.\n            Note that preliminary results are not final and may not contain all the datapoints &amp; responses. Only the ones that are already available.\n    \"\"\"\n    with tracer.start_as_current_span(\"RapidataOrder.get_results\"):\n        from rapidata.api_client.models.order_state import OrderState\n        from rapidata.api_client.exceptions import ApiException\n        from rapidata.rapidata_client.results.rapidata_results import (\n            RapidataResults,\n        )\n\n        logger.info(\"Getting results for order '%s'...\", self)\n\n        if preliminary_results and self.get_status() not in [OrderState.COMPLETED]:\n            return self._get_preliminary_results()\n\n        if preliminary_results and self.get_status() == OrderState.COMPLETED:\n            managed_print(\"Order is already completed. Returning final results.\")\n\n        self._wait_for_state(\n            target_states=[\n                OrderState.COMPLETED,\n                OrderState.PAUSED,\n                OrderState.MANUALREVIEW,\n                OrderState.FAILED,\n            ],\n            status_message=\"Order '%s' is in state %s, waiting for completion...\",\n        )\n\n        try:\n            results = (\n                self._openapi_service.order_api.order_order_id_download_results_get(\n                    order_id=self.id\n                )\n            )\n            return RapidataResults(json.loads(results))\n        except (ApiException, json.JSONDecodeError) as e:\n            raise Exception(f\"Failed to get order results: {str(e)}\") from e\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/order/rapidata_order/#rapidata.rapidata_client.order.rapidata_order.RapidataOrder.view","title":"view","text":"<pre><code>view() -&gt; None\n</code></pre> <p>Opens the order details page in the browser.</p> Source code in <code>src/rapidata/rapidata_client/order/rapidata_order.py</code> <pre><code>def view(self) -&gt; None:\n    \"\"\"Opens the order details page in the browser.\"\"\"\n    logger.info(\"Opening order details page in browser...\")\n    if not webbrowser.open(self.order_details_page):\n        encoded_url = urllib.parse.quote(\n            self.order_details_page, safe=\"%/:=&amp;?~#+!$,;'@()*[]\"\n        )\n        managed_print(\n            Fore.RED\n            + f\"Please open this URL in your browser: '{encoded_url}'\"\n            + Fore.RESET\n        )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/order/rapidata_order/#rapidata.rapidata_client.order.rapidata_order.RapidataOrder.preview","title":"preview","text":"<pre><code>preview() -&gt; None\n</code></pre> <p>Opens a preview of the order in the browser.</p> Source code in <code>src/rapidata/rapidata_client/order/rapidata_order.py</code> <pre><code>def preview(self) -&gt; None:\n    \"\"\"Opens a preview of the order in the browser.\"\"\"\n    from rapidata.api_client.models.order_state import OrderState\n    from rapidata.api_client.models.preview_order_model import PreviewOrderModel\n\n    logger.info(\"Opening order preview in browser...\")\n\n    if self.get_status() == OrderState.CREATED:\n        logger.info(\"Order is still in state created. Setting it to preview.\")\n        self._openapi_service.order_api.order_order_id_preview_post(\n            self.id, PreviewOrderModel(ignoreFailedDatapoints=True)\n        )\n        logger.info(\"Order is now in preview state.\")\n\n    campaign_id = self.__get_campaign_id()\n    auth_url = f\"https://app.{self._openapi_service.environment}/order/detail/{self.id}/preview?campaignId={campaign_id}\"\n\n    if not webbrowser.open(auth_url):\n        encoded_url = urllib.parse.quote(auth_url, safe=\"%/:=&amp;?~#+!$,;'@()*[]\")\n        managed_print(\n            Fore.RED\n            + f\"Please open this URL in your browser: '{encoded_url}'\"\n            + Fore.RESET\n        )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/order/rapidata_order_manager/","title":"Rapidata order manager","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/order/rapidata_order_manager/#rapidata.rapidata_client.order.rapidata_order_manager.RapidataOrderManager","title":"RapidataOrderManager","text":"<pre><code>RapidataOrderManager(openapi_service: OpenAPIService)\n</code></pre> <p>Handels everything regarding the orders from creation to retrieval.</p> <p>Attributes:</p> Name Type Description <code>filters</code> <code>RapidataFilters</code> <p>The RapidataFilters instance.</p> <code>settings</code> <code>RapidataSettings</code> <p>The RapidataSettings instance.</p> <code>selections</code> <code>RapidataSelections</code> <p>The RapidataSelections instance.</p> Source code in <code>src/rapidata/rapidata_client/order/rapidata_order_manager.py</code> <pre><code>def __init__(self, openapi_service: OpenAPIService):\n    self.__openapi_service = openapi_service\n    self.filters = RapidataFilters\n    self.settings = RapidataSettings\n    self.selections = RapidataSelections\n    from rapidata.rapidata_client.order._rapidata_order_builder import (\n        StickyStateLiteral,\n    )\n\n    self.__priority: int | None = None\n    self.__sticky_state: StickyStateLiteral | None = None\n    self._asset_uploader = AssetUploader(openapi_service)\n    logger.debug(\"RapidataOrderManager initialized\")\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/order/rapidata_order_manager/#rapidata.rapidata_client.order.rapidata_order_manager.RapidataOrderManager.create_classification_order","title":"create_classification_order","text":"<pre><code>create_classification_order(\n    name: str,\n    instruction: str,\n    answer_options: list[str],\n    datapoints: list[str],\n    data_type: Literal[\"media\", \"text\"] = \"media\",\n    responses_per_datapoint: int = 10,\n    contexts: list[str] | None = None,\n    media_contexts: list[str] | None = None,\n    validation_set_id: str | None = None,\n    confidence_threshold: float | None = None,\n    filters: Sequence[RapidataFilter] | None = None,\n    settings: Sequence[RapidataSetting] | None = None,\n    selections: Sequence[RapidataSelection] | None = None,\n    private_metadata: list[dict[str, str]] | None = None,\n) -&gt; RapidataOrder\n</code></pre> <p>Create a classification order.</p> <p>With this order you can have a datapoint (image, text, video, audio) be classified into one of the answer options. Each response will be exactly one of the answer options.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the order. (Will not be shown to the labeler)</p> required <code>instruction</code> <code>str</code> <p>The instruction for how the data should be classified.</p> required <code>answer_options</code> <code>list[str]</code> <p>The list of options for the classification.</p> required <code>datapoints</code> <code>list[str]</code> <p>The list of datapoints for the classification - each datapoint will be labeled.</p> required <code>data_type</code> <code>str</code> <p>The data type of the datapoints. Defaults to \"media\" (any form of image, video or audio). </p> <p>Other option: \"text\".</p> <code>'media'</code> <code>responses_per_datapoint</code> <code>int</code> <p>The number of responses that will be collected per datapoint. Defaults to 10.</p> <code>10</code> <code>contexts</code> <code>list[str]</code> <p>The list of contexts for the classification. Defaults to None.</p> <p>If provided has to be the same length as datapoints and will be shown in addition to the instruction and options. (Therefore will be different for each datapoint) Will be match up with the datapoints using the list index.</p> <code>None</code> <code>media_contexts</code> <code>list[str]</code> <p>The list of media contexts for the classification i.e links to the images / videos. Defaults to None.</p> <p>If provided has to be the same length as datapoints and will be shown in addition to the instruction and options. (Therefore will be different for each datapoint)</p> <code>None</code> <code>validation_set_id</code> <code>str</code> <p>The ID of the validation set. Defaults to None.</p> <p>If provided, one validation task will be shown infront of the datapoints that will be labeled.</p> <code>None</code> <code>confidence_threshold</code> <code>float</code> <p>The probability threshold for the classification. Defaults to None.</p> <p>If provided, the classification datapoint will stop after the threshold is reached or at the number of responses, whatever happens first.</p> <code>None</code> <code>filters</code> <code>Sequence[RapidataFilter]</code> <p>The list of filters for the classification. Defaults to []. Decides who the tasks should be shown to.</p> <code>None</code> <code>settings</code> <code>Sequence[RapidataSetting]</code> <p>The list of settings for the classification. Defaults to []. Decides how the tasks should be shown.</p> <code>None</code> <code>selections</code> <code>Sequence[RapidataSelection]</code> <p>The list of selections for the classification. Defaults to []. Decides in what order the tasks should be shown.</p> <code>None</code> <code>private_metadata</code> <code>list[dict[str, str]]</code> <p>Key-value string pairs for each datapoint. Defaults to None. If provided has to be the same length as datapoints.</p> <p>This will NOT be shown to the labelers but will be included in the result purely for your own reference.</p> <code>None</code> Example <pre><code>from rapidata import RapidataClient, NoShuffle\n\nrapi = RapidataClient()\norder = rapi.order.create_classification_order(\n    name=\"Image Quality Rating\",\n    instruction=\"How would you rate the quality of this image?\",\n    answer_options=[\"1: Poor\", \"2: Fair\", \"3: Good\", \"4: Excellent\"],\n    datapoints=[\"https://example.com/image1.jpg\", \"https://example.com/image2.jpg\"],\n    responses_per_datapoint=15,\n    settings=[NoShuffle()],  # Keep options in order for Likert scale\n).run()\n\nresults = order.get_results()\n</code></pre> Source code in <code>src/rapidata/rapidata_client/order/rapidata_order_manager.py</code> <pre><code>def create_classification_order(\n    self,\n    name: str,\n    instruction: str,\n    answer_options: list[str],\n    datapoints: list[str],\n    data_type: Literal[\"media\", \"text\"] = \"media\",\n    responses_per_datapoint: int = 10,\n    contexts: list[str] | None = None,\n    media_contexts: list[str] | None = None,\n    validation_set_id: str | None = None,\n    confidence_threshold: float | None = None,\n    filters: Sequence[RapidataFilter] | None = None,\n    settings: Sequence[RapidataSetting] | None = None,\n    selections: Sequence[RapidataSelection] | None = None,\n    private_metadata: list[dict[str, str]] | None = None,\n) -&gt; RapidataOrder:\n    \"\"\"Create a classification order.\n\n    With this order you can have a datapoint (image, text, video, audio) be classified into one of the answer options.\n    Each response will be exactly one of the answer options.\n\n    Args:\n        name (str): The name of the order. (Will not be shown to the labeler)\n        instruction (str): The instruction for how the data should be classified.\n        answer_options (list[str]): The list of options for the classification.\n        datapoints (list[str]): The list of datapoints for the classification - each datapoint will be labeled.\n        data_type (str, optional): The data type of the datapoints. Defaults to \"media\" (any form of image, video or audio). \\n\n            Other option: \"text\".\n        responses_per_datapoint (int, optional): The number of responses that will be collected per datapoint. Defaults to 10.\n        contexts (list[str], optional): The list of contexts for the classification. Defaults to None.\\n\n            If provided has to be the same length as datapoints and will be shown in addition to the instruction and options. (Therefore will be different for each datapoint)\n            Will be match up with the datapoints using the list index.\n        media_contexts (list[str], optional): The list of media contexts for the classification i.e links to the images / videos. Defaults to None.\\n\n            If provided has to be the same length as datapoints and will be shown in addition to the instruction and options. (Therefore will be different for each datapoint)\n        validation_set_id (str, optional): The ID of the validation set. Defaults to None.\\n\n            If provided, one validation task will be shown infront of the datapoints that will be labeled.\n        confidence_threshold (float, optional): The probability threshold for the classification. Defaults to None.\\n\n            If provided, the classification datapoint will stop after the threshold is reached or at the number of responses, whatever happens first.\n        filters (Sequence[RapidataFilter], optional): The list of filters for the classification. Defaults to []. Decides who the tasks should be shown to.\n        settings (Sequence[RapidataSetting], optional): The list of settings for the classification. Defaults to []. Decides how the tasks should be shown.\n        selections (Sequence[RapidataSelection], optional): The list of selections for the classification. Defaults to []. Decides in what order the tasks should be shown.\n        private_metadata (list[dict[str, str]], optional): Key-value string pairs for each datapoint. Defaults to None.\n            If provided has to be the same length as datapoints.\\n\n            This will NOT be shown to the labelers but will be included in the result purely for your own reference.\n\n    Example:\n        ```python\n        from rapidata import RapidataClient, NoShuffle\n\n        rapi = RapidataClient()\n        order = rapi.order.create_classification_order(\n            name=\"Image Quality Rating\",\n            instruction=\"How would you rate the quality of this image?\",\n            answer_options=[\"1: Poor\", \"2: Fair\", \"3: Good\", \"4: Excellent\"],\n            datapoints=[\"https://example.com/image1.jpg\", \"https://example.com/image2.jpg\"],\n            responses_per_datapoint=15,\n            settings=[NoShuffle()],  # Keep options in order for Likert scale\n        ).run()\n\n        results = order.get_results()\n        ```\n    \"\"\"\n    with tracer.start_as_current_span(\n        \"RapidataOrderManager.create_classification_order\"\n    ):\n        if not isinstance(datapoints, list) or not all(\n            isinstance(datapoint, str) for datapoint in datapoints\n        ):\n            raise ValueError(\"Datapoints must be a list of strings\")\n\n        from rapidata.rapidata_client.workflow import ClassifyWorkflow\n\n        datapoints_instances = DatapointsValidator.map_datapoints(\n            datapoints=datapoints,\n            contexts=contexts,\n            media_contexts=media_contexts,\n            private_metadata=private_metadata,\n            data_type=data_type,\n        )\n        return self._create_general_order(\n            name=name,\n            workflow=ClassifyWorkflow(\n                instruction=instruction, answer_options=answer_options\n            ),\n            datapoints=datapoints_instances,\n            responses_per_datapoint=responses_per_datapoint,\n            validation_set_id=validation_set_id,\n            confidence_threshold=confidence_threshold,\n            filters=filters,\n            selections=selections,\n            settings=settings,\n        )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/order/rapidata_order_manager/#rapidata.rapidata_client.order.rapidata_order_manager.RapidataOrderManager.create_compare_order","title":"create_compare_order","text":"<pre><code>create_compare_order(\n    name: str,\n    instruction: str,\n    datapoints: list[list[str]],\n    data_type: Literal[\"media\", \"text\"] = \"media\",\n    responses_per_datapoint: int = 10,\n    contexts: list[str] | None = None,\n    media_contexts: list[str] | None = None,\n    a_b_names: list[str] | None = None,\n    validation_set_id: str | None = None,\n    confidence_threshold: float | None = None,\n    quorum_threshold: int | None = None,\n    filters: Sequence[RapidataFilter] | None = None,\n    settings: Sequence[RapidataSetting] | None = None,\n    selections: Sequence[RapidataSelection] | None = None,\n    private_metadata: list[dict[str, str]] | None = None,\n) -&gt; RapidataOrder\n</code></pre> <p>Create a compare order.</p> <p>With this order you compare two datapoints (image, text, video, audio) and the annotators will choose one of the two based on the instruction.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the order. (Will not be shown to the labeler)</p> required <code>instruction</code> <code>str</code> <p>The instruction for the comparison. Will be shown along side each datapoint.</p> required <code>datapoints</code> <code>list[list[str]]</code> <p>Outher list is the datapoints, inner list is the options for the comparison - each datapoint will be labeled.</p> required <code>data_type</code> <code>str</code> <p>The data type of the datapoints. Defaults to \"media\" (any form of image, video or audio). </p> <p>Other option: \"text\".</p> <code>'media'</code> <code>responses_per_datapoint</code> <code>int</code> <p>The number of responses that will be collected per datapoint. Defaults to 10.</p> <code>10</code> <code>contexts</code> <code>list[str]</code> <p>The list of contexts for the comparison. Defaults to None.</p> <p>If provided has to be the same length as datapoints and will be shown in addition to the instruction. (Therefore will be different for each datapoint) Will be matched up with the datapoints using the list index.</p> <code>None</code> <code>media_contexts</code> <code>list[str]</code> <p>The list of media contexts i.e. links to the images / videos for the comparison. Defaults to None.</p> <p>If provided has to be the same length as datapoints and will be shown in addition to the instruction. (Therefore will be different for each datapoint) Will be matched up with the datapoints using the list index.</p> <code>None</code> <code>a_b_names</code> <code>list[str]</code> <p>Custom naming for the two opposing models defined by the index in the datapoints list. Defaults to None.</p> <p>If provided has to be a list of exactly two strings. example: </p><pre><code>datapoints = [[\"path_to_image_A\", \"path_to_image_B\"], [\"path_to_text_A\", \"path_to_text_B\"]]\na_b_naming = [\"Model A\", \"Model B\"]\n</code></pre> The results will then correctly show \"Model A\" and \"Model B\". If not provided, the results will be shown as \"A\" and \"B\".<p></p> <code>None</code> <code>validation_set_id</code> <code>str</code> <p>The ID of the validation set. Defaults to None.</p> <p>If provided, one validation task will be shown infront of the datapoints that will be labeled.</p> <code>None</code> <code>confidence_threshold</code> <code>float</code> <p>The probability threshold for the comparison. Defaults to None.</p> <p>If provided, the comparison datapoint will stop after the threshold is reached or at the number of responses, whatever happens first.</p> <code>None</code> <code>quorum_threshold</code> <code>int</code> <p>The number of matching responses required to reach quorum. Defaults to None.</p> <p>If provided, the comparison datapoint will stop when this many responses agree or that quorum can't be reached anymore or after responses_per_datapoint votes. Cannot be used together with confidence_threshold. Example: </p><pre><code>responses_per_datapoint = 10\nquorum_threshold = 7\n</code></pre> This will stop at 7 responses for one side or if both sides have at least 4 responses.<p></p> <code>None</code> <code>filters</code> <code>Sequence[RapidataFilter]</code> <p>The list of filters for the comparison. Defaults to []. Decides who the tasks should be shown to.</p> <code>None</code> <code>settings</code> <code>Sequence[RapidataSetting]</code> <p>The list of settings for the comparison. Defaults to []. Decides how the tasks should be shown.</p> <code>None</code> <code>selections</code> <code>Sequence[RapidataSelection]</code> <p>The list of selections for the comparison. Defaults to []. Decides in what order the tasks should be shown.</p> <code>None</code> <code>private_metadata</code> <code>list[dict[str, str]]</code> <p>Key-value string pairs for each datapoint. Defaults to None.</p> <p>If provided has to be the same length as datapoints.</p> <p>This will NOT be shown to the labelers but will be included in the result purely for your own reference.</p> <code>None</code> Example <pre><code>from rapidata import RapidataClient\n\nrapi = RapidataClient()\norder = rapi.order.create_compare_order(\n    name=\"Image Prompt Alignment\",\n    instruction=\"Which image follows the prompt more accurately?\",\n    datapoints=[\n        [\"https://example.com/model_a_img1.jpg\", \"https://example.com/model_b_img1.jpg\"],\n        [\"https://example.com/model_a_img2.jpg\", \"https://example.com/model_b_img2.jpg\"],\n    ],\n    contexts=[\"A cat sitting on a red couch\", \"A blue car in the rain\"],\n    responses_per_datapoint=25,\n    a_b_names=[\"Flux\", \"Midjourney\"],  # Optional: label the models in results\n).run()\n\nresults = order.get_results()\n</code></pre> Source code in <code>src/rapidata/rapidata_client/order/rapidata_order_manager.py</code> <pre><code>def create_compare_order(\n    self,\n    name: str,\n    instruction: str,\n    datapoints: list[list[str]],\n    data_type: Literal[\"media\", \"text\"] = \"media\",\n    responses_per_datapoint: int = 10,\n    contexts: list[str] | None = None,\n    media_contexts: list[str] | None = None,\n    a_b_names: list[str] | None = None,\n    validation_set_id: str | None = None,\n    confidence_threshold: float | None = None,\n    quorum_threshold: int | None = None,\n    filters: Sequence[RapidataFilter] | None = None,\n    settings: Sequence[RapidataSetting] | None = None,\n    selections: Sequence[RapidataSelection] | None = None,\n    private_metadata: list[dict[str, str]] | None = None,\n) -&gt; RapidataOrder:\n    \"\"\"Create a compare order.\n\n    With this order you compare two datapoints (image, text, video, audio) and the annotators will choose one of the two based on the instruction.\n\n    Args:\n        name (str): The name of the order. (Will not be shown to the labeler)\n        instruction (str): The instruction for the comparison. Will be shown along side each datapoint.\n        datapoints (list[list[str]]): Outher list is the datapoints, inner list is the options for the comparison - each datapoint will be labeled.\n        data_type (str, optional): The data type of the datapoints. Defaults to \"media\" (any form of image, video or audio). \\n\n            Other option: \"text\".\n        responses_per_datapoint (int, optional): The number of responses that will be collected per datapoint. Defaults to 10.\n        contexts (list[str], optional): The list of contexts for the comparison. Defaults to None.\\n\n            If provided has to be the same length as datapoints and will be shown in addition to the instruction. (Therefore will be different for each datapoint)\n            Will be matched up with the datapoints using the list index.\n        media_contexts (list[str], optional): The list of media contexts i.e. links to the images / videos for the comparison. Defaults to None.\\n\n            If provided has to be the same length as datapoints and will be shown in addition to the instruction. (Therefore will be different for each datapoint)\n            Will be matched up with the datapoints using the list index.\n        a_b_names (list[str], optional): Custom naming for the two opposing models defined by the index in the datapoints list. Defaults to None.\\n\n            If provided has to be a list of exactly two strings.\n            example:\n            ```python\n            datapoints = [[\"path_to_image_A\", \"path_to_image_B\"], [\"path_to_text_A\", \"path_to_text_B\"]]\n            a_b_naming = [\"Model A\", \"Model B\"]\n            ```\n            The results will then correctly show \"Model A\" and \"Model B\".\n            If not provided, the results will be shown as \"A\" and \"B\".\n        validation_set_id (str, optional): The ID of the validation set. Defaults to None.\\n\n            If provided, one validation task will be shown infront of the datapoints that will be labeled.\n        confidence_threshold (float, optional): The probability threshold for the comparison. Defaults to None.\\n\n            If provided, the comparison datapoint will stop after the threshold is reached or at the number of responses, whatever happens first.\n        quorum_threshold (int, optional): The number of matching responses required to reach quorum. Defaults to None.\\n\n            If provided, the comparison datapoint will stop when this many responses agree or that quorum can't be reached anymore or after responses_per_datapoint votes.\n            Cannot be used together with confidence_threshold.\n            Example:\n            ```python\n            responses_per_datapoint = 10\n            quorum_threshold = 7\n            ```\n            This will stop at 7 responses for one side or if both sides have at least 4 responses.\n        filters (Sequence[RapidataFilter], optional): The list of filters for the comparison. Defaults to []. Decides who the tasks should be shown to.\n        settings (Sequence[RapidataSetting], optional): The list of settings for the comparison. Defaults to []. Decides how the tasks should be shown.\n        selections (Sequence[RapidataSelection], optional): The list of selections for the comparison. Defaults to []. Decides in what order the tasks should be shown.\n        private_metadata (list[dict[str, str]], optional): Key-value string pairs for each datapoint. Defaults to None.\\n\n            If provided has to be the same length as datapoints.\\n\n            This will NOT be shown to the labelers but will be included in the result purely for your own reference.\n\n    Example:\n        ```python\n        from rapidata import RapidataClient\n\n        rapi = RapidataClient()\n        order = rapi.order.create_compare_order(\n            name=\"Image Prompt Alignment\",\n            instruction=\"Which image follows the prompt more accurately?\",\n            datapoints=[\n                [\"https://example.com/model_a_img1.jpg\", \"https://example.com/model_b_img1.jpg\"],\n                [\"https://example.com/model_a_img2.jpg\", \"https://example.com/model_b_img2.jpg\"],\n            ],\n            contexts=[\"A cat sitting on a red couch\", \"A blue car in the rain\"],\n            responses_per_datapoint=25,\n            a_b_names=[\"Flux\", \"Midjourney\"],  # Optional: label the models in results\n        ).run()\n\n        results = order.get_results()\n        ```\n    \"\"\"\n    with tracer.start_as_current_span(\"RapidataOrderManager.create_compare_order\"):\n        if any(not isinstance(datapoint, list) for datapoint in datapoints):\n            raise ValueError(\"Each datapoint must be a list of 2 paths/texts\")\n\n        if any(len(set(datapoint)) != 2 for datapoint in datapoints):\n            raise ValueError(\n                \"Each datapoint must contain exactly two unique options\"\n            )\n\n        if a_b_names is not None and len(a_b_names) != 2:\n            raise ValueError(\n                \"A_B_naming must be a list of exactly two strings or None\"\n            )\n\n        from rapidata.rapidata_client.workflow import CompareWorkflow\n\n        datapoints_instances = DatapointsValidator.map_datapoints(\n            datapoints=datapoints,\n            contexts=contexts,\n            media_contexts=media_contexts,\n            private_metadata=private_metadata,\n            data_type=data_type,\n            multi_asset=True,\n        )\n        return self._create_general_order(\n            name=name,\n            workflow=CompareWorkflow(instruction=instruction, a_b_names=a_b_names),\n            datapoints=datapoints_instances,\n            responses_per_datapoint=responses_per_datapoint,\n            validation_set_id=validation_set_id,\n            confidence_threshold=confidence_threshold,\n            quorum_threshold=quorum_threshold,\n            filters=filters,\n            selections=selections,\n            settings=settings,\n        )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/order/rapidata_order_manager/#rapidata.rapidata_client.order.rapidata_order_manager.RapidataOrderManager.create_ranking_order","title":"create_ranking_order","text":"<pre><code>create_ranking_order(\n    name: str,\n    instruction: str,\n    datapoints: list[list[str]],\n    comparison_budget_per_ranking: int,\n    responses_per_comparison: int = 1,\n    data_type: Literal[\"media\", \"text\"] = \"media\",\n    random_comparisons_ratio: float = 0.5,\n    contexts: Optional[list[str]] = None,\n    media_contexts: Optional[list[str]] = None,\n    validation_set_id: Optional[str] = None,\n    filters: Sequence[RapidataFilter] | None = None,\n    settings: Sequence[RapidataSetting] | None = None,\n    selections: Sequence[RapidataSelection] | None = None,\n) -&gt; RapidataOrder\n</code></pre> <p>Create a ranking order.</p> <p>With this order you can have a multiple lists of datapoints (image, text, video, audio) be ranked based on the instruction. Each list will be ranked independently, based on comparison matchups.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the order.</p> required <code>instruction</code> <code>str</code> <p>The instruction for the ranking. Will be shown with each matchup.</p> required <code>datapoints</code> <code>list[list[str]]</code> <p>The outer list is determines the independent rankings, the inner list is the datapoints for each ranking.</p> required <code>comparison_budget_per_ranking</code> <code>int</code> <p>The number of comparisons that will be collected per ranking (outer list of datapoints).</p> required <code>responses_per_comparison</code> <code>int</code> <p>The number of responses that will be collected per comparison. Defaults to 1.</p> <code>1</code> <code>data_type</code> <code>str</code> <p>The data type of the datapoints. Defaults to \"media\" (any form of image, video or audio). </p> <p>Other option: \"text\".</p> <code>'media'</code> <code>random_comparisons_ratio</code> <code>float</code> <p>The ratio of random comparisons to the total number of comparisons. Defaults to 0.5.</p> <code>0.5</code> <code>contexts</code> <code>list[str]</code> <p>The list of contexts for the ranking. Defaults to None.</p> <p>If provided has to be the same length as the outer list of datapoints and will be shown in addition to the instruction. (Therefore will be different for each ranking) Will be matched up with the datapoints using the list index.</p> <code>None</code> <code>media_contexts</code> <code>list[str]</code> <p>The list of media contexts for the ranking i.e links to the images / videos. Defaults to None.</p> <p>If provided has to be the same length as the outer list of datapoints and will be shown in addition to the instruction. (Therefore will be different for each ranking) Will be matched up with the datapoints using the list index.</p> <code>None</code> <code>validation_set_id</code> <code>str</code> <p>The ID of the validation set. Defaults to None.</p> <p>If provided, one validation task will be shown infront of the datapoints that will be labeled.</p> <code>None</code> <code>filters</code> <code>Sequence[RapidataFilter]</code> <p>The list of filters for the ranking. Defaults to []. Decides who the tasks should be shown to.</p> <code>None</code> <code>settings</code> <code>Sequence[RapidataSetting]</code> <p>The list of settings for the ranking. Defaults to []. Decides how the tasks should be shown.</p> <code>None</code> <code>selections</code> <code>Sequence[RapidataSelection]</code> <p>The list of selections for the ranking. Defaults to []. Decides in what order the tasks should be shown.</p> <code>None</code> Example <pre><code>from rapidata import RapidataClient\n\nrapi = RapidataClient()\n# Rank 12 images by preference using 50 pairwise comparisons\norder = rapi.order.create_ranking_order(\n    name=\"Image Quality Ranking\",\n    instruction=\"Which image looks better?\",\n    datapoints=[[\"img1.jpg\", \"img2.jpg\", \"img3.jpg\", \"img4.jpg\", \"img5.jpg\",\n                \"img6.jpg\", \"img7.jpg\", \"img8.jpg\", \"img9.jpg\", \"img10.jpg\",\n                \"img11.jpg\", \"img12.jpg\"]],\n    comparison_budget_per_ranking=50,\n    random_comparisons_ratio=0.5,  # 50% random, 50% close matchups\n).run()\n\nresults = order.get_results()  # Returns ranked list with scores\n</code></pre> Source code in <code>src/rapidata/rapidata_client/order/rapidata_order_manager.py</code> <pre><code>def create_ranking_order(\n    self,\n    name: str,\n    instruction: str,\n    datapoints: list[list[str]],\n    comparison_budget_per_ranking: int,\n    responses_per_comparison: int = 1,\n    data_type: Literal[\"media\", \"text\"] = \"media\",\n    random_comparisons_ratio: float = 0.5,\n    contexts: Optional[list[str]] = None,\n    media_contexts: Optional[list[str]] = None,\n    validation_set_id: Optional[str] = None,\n    filters: Sequence[RapidataFilter] | None = None,\n    settings: Sequence[RapidataSetting] | None = None,\n    selections: Sequence[RapidataSelection] | None = None,\n) -&gt; RapidataOrder:\n    \"\"\"\n    Create a ranking order.\n\n    With this order you can have a multiple lists of datapoints (image, text, video, audio) be ranked based on the instruction.\n    Each list will be ranked independently, based on comparison matchups.\n\n    Args:\n        name (str): The name of the order.\n        instruction (str): The instruction for the ranking. Will be shown with each matchup.\n        datapoints (list[list[str]]): The outer list is determines the independent rankings, the inner list is the datapoints for each ranking.\n        comparison_budget_per_ranking (int): The number of comparisons that will be collected per ranking (outer list of datapoints).\n        responses_per_comparison (int, optional): The number of responses that will be collected per comparison. Defaults to 1.\n        data_type (str, optional): The data type of the datapoints. Defaults to \"media\" (any form of image, video or audio). \\n\n            Other option: \"text\".\n        random_comparisons_ratio (float, optional): The ratio of random comparisons to the total number of comparisons. Defaults to 0.5.\n        contexts (list[str], optional): The list of contexts for the ranking. Defaults to None.\\n\n            If provided has to be the same length as the outer list of datapoints and will be shown in addition to the instruction. (Therefore will be different for each ranking)\n            Will be matched up with the datapoints using the list index.\n        media_contexts (list[str], optional): The list of media contexts for the ranking i.e links to the images / videos. Defaults to None.\\n\n            If provided has to be the same length as the outer list of datapoints and will be shown in addition to the instruction. (Therefore will be different for each ranking)\n            Will be matched up with the datapoints using the list index.\n        validation_set_id (str, optional): The ID of the validation set. Defaults to None.\\n\n            If provided, one validation task will be shown infront of the datapoints that will be labeled.\n        filters (Sequence[RapidataFilter], optional): The list of filters for the ranking. Defaults to []. Decides who the tasks should be shown to.\n        settings (Sequence[RapidataSetting], optional): The list of settings for the ranking. Defaults to []. Decides how the tasks should be shown.\n        selections (Sequence[RapidataSelection], optional): The list of selections for the ranking. Defaults to []. Decides in what order the tasks should be shown.\n\n    Example:\n        ```python\n        from rapidata import RapidataClient\n\n        rapi = RapidataClient()\n        # Rank 12 images by preference using 50 pairwise comparisons\n        order = rapi.order.create_ranking_order(\n            name=\"Image Quality Ranking\",\n            instruction=\"Which image looks better?\",\n            datapoints=[[\"img1.jpg\", \"img2.jpg\", \"img3.jpg\", \"img4.jpg\", \"img5.jpg\",\n                        \"img6.jpg\", \"img7.jpg\", \"img8.jpg\", \"img9.jpg\", \"img10.jpg\",\n                        \"img11.jpg\", \"img12.jpg\"]],\n            comparison_budget_per_ranking=50,\n            random_comparisons_ratio=0.5,  # 50% random, 50% close matchups\n        ).run()\n\n        results = order.get_results()  # Returns ranked list with scores\n        ```\n    \"\"\"\n    with tracer.start_as_current_span(\"RapidataOrderManager.create_ranking_order\"):\n        if contexts and len(contexts) != len(datapoints):\n            raise ValueError(\n                \"Number of contexts must match the number of sets that will be ranked\"\n            )\n        if media_contexts and len(media_contexts) != len(datapoints):\n            raise ValueError(\n                \"Number of media contexts must match the number of sets that will be ranked\"\n            )\n        if not isinstance(datapoints, list) or not all(\n            isinstance(dp, list) for dp in datapoints\n        ):\n            raise ValueError(\n                \"Datapoints must be a list of lists. Outer list is the independent rankings, inner list is the datapoints for each ranking.\"\n            )\n        if not all(len(set(dp)) == len(dp) for dp in datapoints):\n            raise ValueError(\"Each inner list must contain unique datapoints.\")\n\n        if not all(len(inner_list) &gt;= 2 for inner_list in datapoints):\n            raise ValueError(\n                \"Each ranking must contain at least two unique datapoints.\"\n            )\n\n        from rapidata.rapidata_client.workflow import MultiRankingWorkflow\n        from rapidata.api_client.models.i_asset_input import IAssetInput\n        from rapidata.api_client.models.i_asset_input_existing_asset_input import (\n            IAssetInputExistingAssetInput,\n        )\n\n        datapoints_instances = []\n        for i, datapoint in enumerate(datapoints):\n            for d in datapoint:\n                datapoints_instances.append(\n                    Datapoint(\n                        asset=d,\n                        data_type=data_type,\n                        context=contexts[i] if contexts else None,\n                        media_context=media_contexts[i] if media_contexts else None,\n                        group=str(i),\n                    )\n                )\n\n        contexts_dict = (\n            {str(i): context for i, context in enumerate(contexts)}\n            if contexts\n            else None\n        )\n\n        media_contexts_dict = (\n            {\n                str(i): IAssetInput(\n                    actual_instance=IAssetInputExistingAssetInput(\n                        _t=\"ExistingAssetInput\",\n                        name=self._asset_uploader.upload_asset(media_context),\n                    )\n                )\n                for i, media_context in enumerate(media_contexts)\n            }\n            if media_contexts\n            else None\n        )\n\n        return self._create_general_order(\n            name=name,\n            workflow=MultiRankingWorkflow(\n                instruction=instruction,\n                comparison_budget_per_ranking=comparison_budget_per_ranking,\n                random_comparisons_ratio=random_comparisons_ratio,\n                contexts=contexts_dict,\n                media_contexts=media_contexts_dict,\n            ),\n            datapoints=datapoints_instances,\n            responses_per_datapoint=responses_per_comparison,\n            validation_set_id=validation_set_id,\n            filters=filters,\n            selections=selections,\n            settings=settings,\n        )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/order/rapidata_order_manager/#rapidata.rapidata_client.order.rapidata_order_manager.RapidataOrderManager.create_free_text_order","title":"create_free_text_order","text":"<pre><code>create_free_text_order(\n    name: str,\n    instruction: str,\n    datapoints: list[str],\n    data_type: Literal[\"media\", \"text\"] = \"media\",\n    responses_per_datapoint: int = 10,\n    contexts: list[str] | None = None,\n    media_contexts: list[str] | None = None,\n    filters: Sequence[RapidataFilter] | None = None,\n    settings: Sequence[RapidataSetting] | None = None,\n    selections: Sequence[RapidataSelection] | None = None,\n    private_metadata: list[dict[str, str]] | None = None,\n) -&gt; RapidataOrder\n</code></pre> <p>Create a free text order.</p> <p>With this order you can have a datapoint (image, text, video, audio) be labeled with free text. The annotators will be shown a datapoint and will be asked to answer a question with free text.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the order.</p> required <code>instruction</code> <code>str</code> <p>The instruction to answer with free text. Will be shown along side each datapoint.</p> required <code>datapoints</code> <code>list[str]</code> <p>The list of datapoints for the free text - each datapoint will be labeled.</p> required <code>data_type</code> <code>str</code> <p>The data type of the datapoints. Defaults to \"media\" (any form of image, video or audio). </p> <p>Other option: \"text\".</p> <code>'media'</code> <code>responses_per_datapoint</code> <code>int</code> <p>The number of responses that will be collected per datapoint. Defaults to 10.</p> <code>10</code> <code>contexts</code> <code>list[str]</code> <p>The list of contexts for the free text. Defaults to None.</p> <p>If provided has to be the same length as datapoints and will be shown in addition to the instruction. (Therefore will be different for each datapoint) Will be matched up with the datapoints using the list index.</p> <code>None</code> <code>media_contexts</code> <code>list[str]</code> <p>The list of media contexts for the free text i.e links to the images / videos. Defaults to None.</p> <p>If provided has to be the same length as datapoints and will be shown in addition to the instruction. (Therefore will be different for each datapoint) Will be matched up with the datapoints using the list index.</p> <code>None</code> <code>filters</code> <code>Sequence[RapidataFilter]</code> <p>The list of filters for the free text. Defaults to []. Decides who the tasks should be shown to.</p> <code>None</code> <code>settings</code> <code>Sequence[RapidataSetting]</code> <p>The list of settings for the free text. Defaults to []. Decides how the tasks should be shown.</p> <code>None</code> <code>selections</code> <code>Sequence[RapidataSelection]</code> <p>The list of selections for the free text. Defaults to []. Decides in what order the tasks should be shown.</p> <code>None</code> <code>private_metadata</code> <code>list[dict[str, str]]</code> <p>Key-value string pairs for each datapoint. Defaults to None.</p> <p>If provided has to be the same length as datapoints.</p> <p>This will NOT be shown to the labelers but will be included in the result purely for your own reference.</p> <code>None</code> Example <pre><code>from rapidata import RapidataClient, FreeTextMinimumCharacters\n\nrapi = RapidataClient()\norder = rapi.order.create_free_text_order(\n    name=\"Image Captioning\",\n    instruction=\"Describe what you see in this image in detail\",\n    datapoints=[\"https://example.com/image1.jpg\", \"https://example.com/image2.jpg\"],\n    responses_per_datapoint=5,\n    settings=[FreeTextMinimumCharacters(20)],  # Require at least 20 characters\n).run()\n\nresults = order.get_results()\n</code></pre> Source code in <code>src/rapidata/rapidata_client/order/rapidata_order_manager.py</code> <pre><code>def create_free_text_order(\n    self,\n    name: str,\n    instruction: str,\n    datapoints: list[str],\n    data_type: Literal[\"media\", \"text\"] = \"media\",\n    responses_per_datapoint: int = 10,\n    contexts: list[str] | None = None,\n    media_contexts: list[str] | None = None,\n    filters: Sequence[RapidataFilter] | None = None,\n    settings: Sequence[RapidataSetting] | None = None,\n    selections: Sequence[RapidataSelection] | None = None,\n    private_metadata: list[dict[str, str]] | None = None,\n) -&gt; RapidataOrder:\n    \"\"\"Create a free text order.\n\n    With this order you can have a datapoint (image, text, video, audio) be labeled with free text.\n    The annotators will be shown a datapoint and will be asked to answer a question with free text.\n\n    Args:\n        name (str): The name of the order.\n        instruction (str): The instruction to answer with free text. Will be shown along side each datapoint.\n        datapoints (list[str]): The list of datapoints for the free text - each datapoint will be labeled.\n        data_type (str, optional): The data type of the datapoints. Defaults to \"media\" (any form of image, video or audio). \\n\n            Other option: \"text\".\n        responses_per_datapoint (int, optional): The number of responses that will be collected per datapoint. Defaults to 10.\n        contexts (list[str], optional): The list of contexts for the free text. Defaults to None.\\n\n            If provided has to be the same length as datapoints and will be shown in addition to the instruction. (Therefore will be different for each datapoint)\n            Will be matched up with the datapoints using the list index.\n        media_contexts (list[str], optional): The list of media contexts for the free text i.e links to the images / videos. Defaults to None.\\n\n            If provided has to be the same length as datapoints and will be shown in addition to the instruction. (Therefore will be different for each datapoint)\n            Will be matched up with the datapoints using the list index.\n        filters (Sequence[RapidataFilter], optional): The list of filters for the free text. Defaults to []. Decides who the tasks should be shown to.\n        settings (Sequence[RapidataSetting], optional): The list of settings for the free text. Defaults to []. Decides how the tasks should be shown.\n        selections (Sequence[RapidataSelection], optional): The list of selections for the free text. Defaults to []. Decides in what order the tasks should be shown.\n        private_metadata (list[dict[str, str]], optional): Key-value string pairs for each datapoint. Defaults to None.\\n\n            If provided has to be the same length as datapoints.\\n\n            This will NOT be shown to the labelers but will be included in the result purely for your own reference.\n\n    Example:\n        ```python\n        from rapidata import RapidataClient, FreeTextMinimumCharacters\n\n        rapi = RapidataClient()\n        order = rapi.order.create_free_text_order(\n            name=\"Image Captioning\",\n            instruction=\"Describe what you see in this image in detail\",\n            datapoints=[\"https://example.com/image1.jpg\", \"https://example.com/image2.jpg\"],\n            responses_per_datapoint=5,\n            settings=[FreeTextMinimumCharacters(20)],  # Require at least 20 characters\n        ).run()\n\n        results = order.get_results()\n        ```\n    \"\"\"\n    with tracer.start_as_current_span(\n        \"RapidataOrderManager.create_free_text_order\"\n    ):\n        from rapidata.rapidata_client.workflow import FreeTextWorkflow\n\n        datapoints_instances = DatapointsValidator.map_datapoints(\n            datapoints=datapoints,\n            contexts=contexts,\n            media_contexts=media_contexts,\n            private_metadata=private_metadata,\n            data_type=data_type,\n        )\n        return self._create_general_order(\n            name=name,\n            workflow=FreeTextWorkflow(instruction=instruction),\n            datapoints=datapoints_instances,\n            responses_per_datapoint=responses_per_datapoint,\n            filters=filters,\n            selections=selections,\n            settings=settings,\n        )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/order/rapidata_order_manager/#rapidata.rapidata_client.order.rapidata_order_manager.RapidataOrderManager.create_select_words_order","title":"create_select_words_order","text":"<pre><code>create_select_words_order(\n    name: str,\n    instruction: str,\n    datapoints: list[str],\n    sentences: list[str],\n    responses_per_datapoint: int = 10,\n    validation_set_id: str | None = None,\n    filters: Sequence[RapidataFilter] | None = None,\n    settings: Sequence[RapidataSetting] | None = None,\n    selections: Sequence[RapidataSelection] | None = None,\n    private_metadata: list[dict[str, str]] | None = None,\n) -&gt; RapidataOrder\n</code></pre> <p>Create a select words order.</p> <p>With this order you can have a datapoint (image, text, video, audio) be labeled with a list of words. The annotators will be shown a datapoint as well as a list of sentences split up by spaces. They will then select specific words based on the instruction.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the order.</p> required <code>instruction</code> <code>str</code> <p>The instruction for how the words should be selected. Will be shown along side each datapoint.</p> required <code>datapoints</code> <code>list[str]</code> <p>The list of datapoints for the select words - each datapoint will be labeled.</p> required <code>sentences</code> <code>list[str]</code> <p>The list of sentences for the select words - Will be split up by spaces and shown along side each datapoint.</p> <p>Must be the same length as datapoints.</p> required <code>responses_per_datapoint</code> <code>int</code> <p>The number of responses that will be collected per datapoint. Defaults to 10.</p> <code>10</code> <code>validation_set_id</code> <code>str</code> <p>The ID of the validation set. Defaults to None.</p> <p>If provided, one validation task will be shown infront of the datapoints that will be labeled.</p> <code>None</code> <code>filters</code> <code>Sequence[RapidataFilter]</code> <p>The list of filters for the select words. Defaults to []. Decides who the tasks should be shown to.</p> <code>None</code> <code>settings</code> <code>Sequence[RapidataSetting]</code> <p>The list of settings for the select words. Defaults to []. Decides how the tasks should be shown.</p> <code>None</code> <code>selections</code> <code>Sequence[RapidataSelection]</code> <p>The list of selections for the select words. Defaults to []. Decides in what order the tasks should be shown.</p> <code>None</code> <code>private_metadata</code> <code>list[dict[str, str]]</code> <p>Key-value string pairs for each datapoint. Defaults to None.</p> <p>If provided has to be the same length as datapoints.</p> <p>This will NOT be shown to the labelers but will be included in the result purely for your own reference.</p> <code>None</code> Example <pre><code>from rapidata import RapidataClient\n\nrapi = RapidataClient()\norder = rapi.order.create_select_words_order(\n    name=\"Find Text-Image Mismatches\",\n    instruction=\"Select words that don't match what's shown in the image\",\n    datapoints=[\"https://example.com/image1.jpg\", \"https://example.com/image2.jpg\"],\n    sentences=[\"A red car on a blue road\", \"Two cats playing with yarn\"],\n    responses_per_datapoint=15,\n).run()\n\nresults = order.get_results()\n</code></pre> Source code in <code>src/rapidata/rapidata_client/order/rapidata_order_manager.py</code> <pre><code>def create_select_words_order(\n    self,\n    name: str,\n    instruction: str,\n    datapoints: list[str],\n    sentences: list[str],\n    responses_per_datapoint: int = 10,\n    validation_set_id: str | None = None,\n    filters: Sequence[RapidataFilter] | None = None,\n    settings: Sequence[RapidataSetting] | None = None,\n    selections: Sequence[RapidataSelection] | None = None,\n    private_metadata: list[dict[str, str]] | None = None,\n) -&gt; RapidataOrder:\n    \"\"\"Create a select words order.\n\n    With this order you can have a datapoint (image, text, video, audio) be labeled with a list of words.\n    The annotators will be shown a datapoint as well as a list of sentences split up by spaces.\n    They will then select specific words based on the instruction.\n\n    Args:\n        name (str): The name of the order.\n        instruction (str): The instruction for how the words should be selected. Will be shown along side each datapoint.\n        datapoints (list[str]): The list of datapoints for the select words - each datapoint will be labeled.\n        sentences (list[str]): The list of sentences for the select words - Will be split up by spaces and shown along side each datapoint.\\n\n            Must be the same length as datapoints.\n        responses_per_datapoint (int, optional): The number of responses that will be collected per datapoint. Defaults to 10.\n        validation_set_id (str, optional): The ID of the validation set. Defaults to None.\\n\n            If provided, one validation task will be shown infront of the datapoints that will be labeled.\n        filters (Sequence[RapidataFilter], optional): The list of filters for the select words. Defaults to []. Decides who the tasks should be shown to.\n        settings (Sequence[RapidataSetting], optional): The list of settings for the select words. Defaults to []. Decides how the tasks should be shown.\n        selections (Sequence[RapidataSelection], optional): The list of selections for the select words. Defaults to []. Decides in what order the tasks should be shown.\n        private_metadata (list[dict[str, str]], optional): Key-value string pairs for each datapoint. Defaults to None.\\n\n            If provided has to be the same length as datapoints.\\n\n            This will NOT be shown to the labelers but will be included in the result purely for your own reference.\n\n    Example:\n        ```python\n        from rapidata import RapidataClient\n\n        rapi = RapidataClient()\n        order = rapi.order.create_select_words_order(\n            name=\"Find Text-Image Mismatches\",\n            instruction=\"Select words that don't match what's shown in the image\",\n            datapoints=[\"https://example.com/image1.jpg\", \"https://example.com/image2.jpg\"],\n            sentences=[\"A red car on a blue road\", \"Two cats playing with yarn\"],\n            responses_per_datapoint=15,\n        ).run()\n\n        results = order.get_results()\n        ```\n    \"\"\"\n    with tracer.start_as_current_span(\n        \"RapidataOrderManager.create_select_words_order\"\n    ):\n        from rapidata.rapidata_client.workflow import SelectWordsWorkflow\n\n        datapoints_instances = DatapointsValidator.map_datapoints(\n            datapoints=datapoints,\n            sentences=sentences,\n            private_metadata=private_metadata,\n        )\n        return self._create_general_order(\n            name=name,\n            workflow=SelectWordsWorkflow(\n                instruction=instruction,\n            ),\n            datapoints=datapoints_instances,\n            responses_per_datapoint=responses_per_datapoint,\n            validation_set_id=validation_set_id,\n            filters=filters,\n            selections=selections,\n            settings=settings,\n        )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/order/rapidata_order_manager/#rapidata.rapidata_client.order.rapidata_order_manager.RapidataOrderManager.create_locate_order","title":"create_locate_order","text":"<pre><code>create_locate_order(\n    name: str,\n    instruction: str,\n    datapoints: list[str],\n    responses_per_datapoint: int = 10,\n    contexts: list[str] | None = None,\n    media_contexts: list[str] | None = None,\n    validation_set_id: str | None = None,\n    filters: Sequence[RapidataFilter] | None = None,\n    settings: Sequence[RapidataSetting] | None = None,\n    selections: Sequence[RapidataSelection] | None = None,\n    private_metadata: list[dict[str, str]] | None = None,\n) -&gt; RapidataOrder\n</code></pre> <p>Create a locate order.</p> <p>With this order you can have people locate specific objects in a datapoint (image, text, video, audio). The annotators will be shown a datapoint and will be asked to select locations based on the instruction.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the order.</p> required <code>instruction</code> <code>str</code> <p>The instruction what should be located. Will be shown along side each datapoint.</p> required <code>datapoints</code> <code>list[str]</code> <p>The list of datapoints for the locate - each datapoint will be labeled.</p> required <code>responses_per_datapoint</code> <code>int</code> <p>The number of responses that will be collected per datapoint. Defaults to 10.</p> <code>10</code> <code>contexts</code> <code>list[str]</code> <p>The list of contexts for the locate. Defaults to None.</p> <p>If provided has to be the same length as datapoints and will be shown in addition to the instruction. (Therefore will be different for each datapoint) Will be match up with the datapoints using the list index.</p> <code>None</code> <code>media_contexts</code> <code>list[str]</code> <p>The list of media contexts for the locate i.e links to the images / videos. Defaults to None.</p> <p>If provided has to be the same length as datapoints and will be shown in addition to the instruction. (Therefore will be different for each datapoint)</p> <code>None</code> <code>validation_set_id</code> <code>str</code> <p>The ID of the validation set. Defaults to None.</p> <p>If provided, one validation task will be shown infront of the datapoints that will be labeled.</p> <code>None</code> <code>filters</code> <code>Sequence[RapidataFilter]</code> <p>The list of filters for the locate. Defaults to []. Decides who the tasks should be shown to.</p> <code>None</code> <code>settings</code> <code>Sequence[RapidataSetting]</code> <p>The list of settings for the locate. Defaults to []. Decides how the tasks should be shown.</p> <code>None</code> <code>selections</code> <code>Sequence[RapidataSelection]</code> <p>The list of selections for the locate. Defaults to []. Decides in what order the tasks should be shown.</p> <code>None</code> <code>private_metadata</code> <code>list[dict[str, str]]</code> <p>Key-value string pairs for each datapoint. Defaults to None.</p> <p>If provided has to be the same length as datapoints.</p> <p>This will NOT be shown to the labelers but will be included in the result purely for your own reference.</p> <code>None</code> Example <pre><code>from rapidata import RapidataClient\n\nrapi = RapidataClient()\norder = rapi.order.create_locate_order(\n    name=\"Find Artifacts\",\n    instruction=\"Tap on any visual glitches or errors in the image\",\n    datapoints=[\"https://example.com/ai_generated1.jpg\", \"https://example.com/ai_generated2.jpg\"],\n    responses_per_datapoint=35,\n).run()\n\nresults = order.get_results()\n</code></pre> Source code in <code>src/rapidata/rapidata_client/order/rapidata_order_manager.py</code> <pre><code>def create_locate_order(\n    self,\n    name: str,\n    instruction: str,\n    datapoints: list[str],\n    responses_per_datapoint: int = 10,\n    contexts: list[str] | None = None,\n    media_contexts: list[str] | None = None,\n    validation_set_id: str | None = None,\n    filters: Sequence[RapidataFilter] | None = None,\n    settings: Sequence[RapidataSetting] | None = None,\n    selections: Sequence[RapidataSelection] | None = None,\n    private_metadata: list[dict[str, str]] | None = None,\n) -&gt; RapidataOrder:\n    \"\"\"Create a locate order.\n\n    With this order you can have people locate specific objects in a datapoint (image, text, video, audio).\n    The annotators will be shown a datapoint and will be asked to select locations based on the instruction.\n\n    Args:\n        name (str): The name of the order.\n        instruction (str): The instruction what should be located. Will be shown along side each datapoint.\n        datapoints (list[str]): The list of datapoints for the locate - each datapoint will be labeled.\n        responses_per_datapoint (int, optional): The number of responses that will be collected per datapoint. Defaults to 10.\n        contexts (list[str], optional): The list of contexts for the locate. Defaults to None.\\n\n            If provided has to be the same length as datapoints and will be shown in addition to the instruction. (Therefore will be different for each datapoint)\n            Will be match up with the datapoints using the list index.\n        media_contexts (list[str], optional): The list of media contexts for the locate i.e links to the images / videos. Defaults to None.\\n\n            If provided has to be the same length as datapoints and will be shown in addition to the instruction. (Therefore will be different for each datapoint)\n        validation_set_id (str, optional): The ID of the validation set. Defaults to None.\\n\n            If provided, one validation task will be shown infront of the datapoints that will be labeled.\n        filters (Sequence[RapidataFilter], optional): The list of filters for the locate. Defaults to []. Decides who the tasks should be shown to.\n        settings (Sequence[RapidataSetting], optional): The list of settings for the locate. Defaults to []. Decides how the tasks should be shown.\n        selections (Sequence[RapidataSelection], optional): The list of selections for the locate. Defaults to []. Decides in what order the tasks should be shown.\n        private_metadata (list[dict[str, str]], optional): Key-value string pairs for each datapoint. Defaults to None.\\n\n            If provided has to be the same length as datapoints.\\n\n            This will NOT be shown to the labelers but will be included in the result purely for your own reference.\n\n    Example:\n        ```python\n        from rapidata import RapidataClient\n\n        rapi = RapidataClient()\n        order = rapi.order.create_locate_order(\n            name=\"Find Artifacts\",\n            instruction=\"Tap on any visual glitches or errors in the image\",\n            datapoints=[\"https://example.com/ai_generated1.jpg\", \"https://example.com/ai_generated2.jpg\"],\n            responses_per_datapoint=35,\n        ).run()\n\n        results = order.get_results()\n        ```\n    \"\"\"\n    with tracer.start_as_current_span(\"RapidataOrderManager.create_locate_order\"):\n        from rapidata.rapidata_client.workflow import LocateWorkflow\n\n        datapoints_instances = DatapointsValidator.map_datapoints(\n            datapoints=datapoints,\n            contexts=contexts,\n            media_contexts=media_contexts,\n            private_metadata=private_metadata,\n        )\n        return self._create_general_order(\n            name=name,\n            workflow=LocateWorkflow(target=instruction),\n            datapoints=datapoints_instances,\n            responses_per_datapoint=responses_per_datapoint,\n            validation_set_id=validation_set_id,\n            filters=filters,\n            selections=selections,\n            settings=settings,\n        )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/order/rapidata_order_manager/#rapidata.rapidata_client.order.rapidata_order_manager.RapidataOrderManager.create_draw_order","title":"create_draw_order","text":"<pre><code>create_draw_order(\n    name: str,\n    instruction: str,\n    datapoints: list[str],\n    responses_per_datapoint: int = 10,\n    contexts: list[str] | None = None,\n    media_contexts: list[str] | None = None,\n    validation_set_id: str | None = None,\n    filters: Sequence[RapidataFilter] | None = None,\n    settings: Sequence[RapidataSetting] | None = None,\n    selections: Sequence[RapidataSelection] | None = None,\n    private_metadata: list[dict[str, str]] | None = None,\n) -&gt; RapidataOrder\n</code></pre> <p>Create a draw order.</p> <p>With this order you can have people draw lines on a datapoint (image, text, video, audio). The annotators will be shown a datapoint and will be asked to draw lines based on the instruction.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the order.</p> required <code>instruction</code> <code>str</code> <p>The instruction for how the lines should be drawn. Will be shown along side each datapoint.</p> required <code>datapoints</code> <code>list[str]</code> <p>The list of datapoints for the draw lines - each datapoint will be labeled.</p> required <code>responses_per_datapoint</code> <code>int</code> <p>The number of responses that will be collected per datapoint. Defaults to 10.</p> <code>10</code> <code>contexts</code> <code>list[str]</code> <p>The list of contexts for the comparison. Defaults to None.</p> <p>If provided has to be the same length as datapoints and will be shown in addition to the instruction. (Therefore will be different for each datapoint) Will be match up with the datapoints using the list index.</p> <code>None</code> <code>media_contexts</code> <code>list[str]</code> <p>The list of media contexts for the draw lines i.e links to the images / videos. Defaults to None.</p> <p>If provided has to be the same length as datapoints and will be shown in addition to the instruction. (Therefore will be different for each datapoint)</p> <code>None</code> <code>validation_set_id</code> <code>str</code> <p>The ID of the validation set. Defaults to None.</p> <p>If provided, one validation task will be shown infront of the datapoints that will be labeled.</p> <code>None</code> <code>filters</code> <code>Sequence[RapidataFilter]</code> <p>The list of filters for the draw lines. Defaults to []. Decides who the tasks should be shown to.</p> <code>None</code> <code>settings</code> <code>Sequence[RapidataSetting]</code> <p>The list of settings for the draw lines. Defaults to []. Decides how the tasks should be shown.</p> <code>None</code> <code>selections</code> <code>Sequence[RapidataSelection]</code> <p>The list of selections for the draw lines. Defaults to []. Decides in what order the tasks should be shown.</p> <code>None</code> <code>private_metadata</code> <code>list[dict[str, str]]</code> <p>Key-value string pairs for each datapoint. Defaults to None.</p> <p>If provided has to be the same length as datapoints.</p> <p>This will NOT be shown to the labelers but will be included in the result purely for your own reference.</p> <code>None</code> Example <pre><code>from rapidata import RapidataClient\n\nrapi = RapidataClient()\norder = rapi.order.create_draw_order(\n    name=\"Segment Objects\",\n    instruction=\"Color in all the cars in the image\",\n    datapoints=[\"https://example.com/street1.jpg\", \"https://example.com/street2.jpg\"],\n    responses_per_datapoint=35,\n).run()\n\nresults = order.get_results()\n</code></pre> Source code in <code>src/rapidata/rapidata_client/order/rapidata_order_manager.py</code> <pre><code>def create_draw_order(\n    self,\n    name: str,\n    instruction: str,\n    datapoints: list[str],\n    responses_per_datapoint: int = 10,\n    contexts: list[str] | None = None,\n    media_contexts: list[str] | None = None,\n    validation_set_id: str | None = None,\n    filters: Sequence[RapidataFilter] | None = None,\n    settings: Sequence[RapidataSetting] | None = None,\n    selections: Sequence[RapidataSelection] | None = None,\n    private_metadata: list[dict[str, str]] | None = None,\n) -&gt; RapidataOrder:\n    \"\"\"Create a draw order.\n\n    With this order you can have people draw lines on a datapoint (image, text, video, audio).\n    The annotators will be shown a datapoint and will be asked to draw lines based on the instruction.\n\n    Args:\n        name (str): The name of the order.\n        instruction (str): The instruction for how the lines should be drawn. Will be shown along side each datapoint.\n        datapoints (list[str]): The list of datapoints for the draw lines - each datapoint will be labeled.\n        responses_per_datapoint (int, optional): The number of responses that will be collected per datapoint. Defaults to 10.\n        contexts (list[str], optional): The list of contexts for the comparison. Defaults to None.\\n\n            If provided has to be the same length as datapoints and will be shown in addition to the instruction. (Therefore will be different for each datapoint)\n            Will be match up with the datapoints using the list index.\n        media_contexts (list[str], optional): The list of media contexts for the draw lines i.e links to the images / videos. Defaults to None.\\n\n            If provided has to be the same length as datapoints and will be shown in addition to the instruction. (Therefore will be different for each datapoint)\n        validation_set_id (str, optional): The ID of the validation set. Defaults to None.\\n\n            If provided, one validation task will be shown infront of the datapoints that will be labeled.\n        filters (Sequence[RapidataFilter], optional): The list of filters for the draw lines. Defaults to []. Decides who the tasks should be shown to.\n        settings (Sequence[RapidataSetting], optional): The list of settings for the draw lines. Defaults to []. Decides how the tasks should be shown.\n        selections (Sequence[RapidataSelection], optional): The list of selections for the draw lines. Defaults to []. Decides in what order the tasks should be shown.\n        private_metadata (list[dict[str, str]], optional): Key-value string pairs for each datapoint. Defaults to None.\\n\n            If provided has to be the same length as datapoints.\\n\n            This will NOT be shown to the labelers but will be included in the result purely for your own reference.\n\n    Example:\n        ```python\n        from rapidata import RapidataClient\n\n        rapi = RapidataClient()\n        order = rapi.order.create_draw_order(\n            name=\"Segment Objects\",\n            instruction=\"Color in all the cars in the image\",\n            datapoints=[\"https://example.com/street1.jpg\", \"https://example.com/street2.jpg\"],\n            responses_per_datapoint=35,\n        ).run()\n\n        results = order.get_results()\n        ```\n    \"\"\"\n    with tracer.start_as_current_span(\"RapidataOrderManager.create_draw_order\"):\n        from rapidata.rapidata_client.workflow import DrawWorkflow\n\n        datapoints_instances = DatapointsValidator.map_datapoints(\n            datapoints=datapoints,\n            contexts=contexts,\n            media_contexts=media_contexts,\n            private_metadata=private_metadata,\n        )\n        return self._create_general_order(\n            name=name,\n            workflow=DrawWorkflow(target=instruction),\n            datapoints=datapoints_instances,\n            responses_per_datapoint=responses_per_datapoint,\n            validation_set_id=validation_set_id,\n            filters=filters,\n            selections=selections,\n            settings=settings,\n        )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/order/rapidata_order_manager/#rapidata.rapidata_client.order.rapidata_order_manager.RapidataOrderManager.create_timestamp_order","title":"create_timestamp_order","text":"<pre><code>create_timestamp_order(\n    name: str,\n    instruction: str,\n    datapoints: list[str],\n    responses_per_datapoint: int = 10,\n    contexts: list[str] | None = None,\n    media_contexts: list[str] | None = None,\n    validation_set_id: str | None = None,\n    filters: Sequence[RapidataFilter] | None = None,\n    settings: Sequence[RapidataSetting] | None = None,\n    selections: Sequence[RapidataSelection] | None = None,\n    private_metadata: list[dict[str, str]] | None = None,\n) -&gt; RapidataOrder\n</code></pre> <p>Create a timestamp order.</p> Warning <p>This order is currently not fully supported and may give unexpected results.</p> <p>With this order you can have people mark specific timestamps in a datapoint (video, audio). The annotators will be shown a datapoint and will be asked to select a timestamp based on the instruction.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the order.</p> required <code>instruction</code> <code>str</code> <p>The instruction for the timestamp task. Will be shown along side each datapoint.</p> required <code>datapoints</code> <code>list[str]</code> <p>The list of datapoints for the timestamp - each datapoint will be labeled.</p> required <code>responses_per_datapoint</code> <code>int</code> <p>The number of responses that will be collected per datapoint. Defaults to 10.</p> <code>10</code> <code>contexts</code> <code>list[str]</code> <p>The list of contexts for the comparison. Defaults to None.</p> <p>If provided has to be the same length as datapoints and will be shown in addition to the instruction. (Therefore will be different for each datapoint) Will be match up with the datapoints using the list index.</p> <code>None</code> <code>media_contexts</code> <code>list[str]</code> <p>The list of media contexts for the timestamp i.e links to the images / videos. Defaults to None.</p> <p>If provided has to be the same length as datapoints and will be shown in addition to the instruction. (Therefore will be different for each datapoint)</p> <code>None</code> <code>validation_set_id</code> <code>str</code> <p>The ID of the validation set. Defaults to None.</p> <p>If provided, one validation task will be shown infront of the datapoints that will be labeled.</p> <code>None</code> <code>filters</code> <code>Sequence[RapidataFilter]</code> <p>The list of filters for the timestamp. Defaults to []. Decides who the tasks should be shown to.</p> <code>None</code> <code>settings</code> <code>Sequence[RapidataSetting]</code> <p>The list of settings for the timestamp. Defaults to []. Decides how the tasks should be shown.</p> <code>None</code> <code>selections</code> <code>Sequence[RapidataSelection]</code> <p>The list of selections for the timestamp. Defaults to []. Decides in what order the tasks should be shown.</p> <code>None</code> <code>private_metadata</code> <code>list[dict[str, str]]</code> <p>Key-value string pairs for each datapoint. Defaults to None.</p> <p>If provided has to be the same length as datapoints.</p> <p>This will NOT be shown to the labelers but will be included in the result purely for your own reference.</p> <code>None</code> Source code in <code>src/rapidata/rapidata_client/order/rapidata_order_manager.py</code> <pre><code>def create_timestamp_order(\n    self,\n    name: str,\n    instruction: str,\n    datapoints: list[str],\n    responses_per_datapoint: int = 10,\n    contexts: list[str] | None = None,\n    media_contexts: list[str] | None = None,\n    validation_set_id: str | None = None,\n    filters: Sequence[RapidataFilter] | None = None,\n    settings: Sequence[RapidataSetting] | None = None,\n    selections: Sequence[RapidataSelection] | None = None,\n    private_metadata: list[dict[str, str]] | None = None,\n) -&gt; RapidataOrder:\n    \"\"\"Create a timestamp order.\n\n    Warning:\n        This order is currently not fully supported and may give unexpected results.\n\n    With this order you can have people mark specific timestamps in a datapoint (video, audio).\n    The annotators will be shown a datapoint and will be asked to select a timestamp based on the instruction.\n\n    Args:\n        name (str): The name of the order.\n        instruction (str): The instruction for the timestamp task. Will be shown along side each datapoint.\n        datapoints (list[str]): The list of datapoints for the timestamp - each datapoint will be labeled.\n        responses_per_datapoint (int, optional): The number of responses that will be collected per datapoint. Defaults to 10.\n        contexts (list[str], optional): The list of contexts for the comparison. Defaults to None.\\n\n            If provided has to be the same length as datapoints and will be shown in addition to the instruction. (Therefore will be different for each datapoint)\n            Will be match up with the datapoints using the list index.\n        media_contexts (list[str], optional): The list of media contexts for the timestamp i.e links to the images / videos. Defaults to None.\\n\n            If provided has to be the same length as datapoints and will be shown in addition to the instruction. (Therefore will be different for each datapoint)\n        validation_set_id (str, optional): The ID of the validation set. Defaults to None.\\n\n            If provided, one validation task will be shown infront of the datapoints that will be labeled.\n        filters (Sequence[RapidataFilter], optional): The list of filters for the timestamp. Defaults to []. Decides who the tasks should be shown to.\n        settings (Sequence[RapidataSetting], optional): The list of settings for the timestamp. Defaults to []. Decides how the tasks should be shown.\n        selections (Sequence[RapidataSelection], optional): The list of selections for the timestamp. Defaults to []. Decides in what order the tasks should be shown.\n        private_metadata (list[dict[str, str]], optional): Key-value string pairs for each datapoint. Defaults to None.\\n\n            If provided has to be the same length as datapoints.\\n\n            This will NOT be shown to the labelers but will be included in the result purely for your own reference.\n    \"\"\"\n\n    with tracer.start_as_current_span(\n        \"RapidataOrderManager.create_timestamp_order\"\n    ):\n        from rapidata.rapidata_client.workflow import TimestampWorkflow\n\n        datapoints_instances = DatapointsValidator.map_datapoints(\n            datapoints=datapoints,\n            contexts=contexts,\n            media_contexts=media_contexts,\n            private_metadata=private_metadata,\n        )\n        return self._create_general_order(\n            name=name,\n            workflow=TimestampWorkflow(instruction=instruction),\n            datapoints=datapoints_instances,\n            responses_per_datapoint=responses_per_datapoint,\n            validation_set_id=validation_set_id,\n            filters=filters,\n            selections=selections,\n            settings=settings,\n        )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/order/rapidata_order_manager/#rapidata.rapidata_client.order.rapidata_order_manager.RapidataOrderManager.get_order_by_id","title":"get_order_by_id","text":"<pre><code>get_order_by_id(order_id: str) -&gt; RapidataOrder\n</code></pre> <p>Get an order by ID.</p> <p>Parameters:</p> Name Type Description Default <code>order_id</code> <code>str</code> <p>The ID of the order.</p> required <p>Returns:</p> Name Type Description <code>RapidataOrder</code> <code>RapidataOrder</code> <p>The Order instance.</p> Source code in <code>src/rapidata/rapidata_client/order/rapidata_order_manager.py</code> <pre><code>def get_order_by_id(self, order_id: str) -&gt; RapidataOrder:\n    \"\"\"Get an order by ID.\n\n    Args:\n        order_id (str): The ID of the order.\n\n    Returns:\n        RapidataOrder: The Order instance.\n    \"\"\"\n    with tracer.start_as_current_span(\"RapidataOrderManager.get_order_by_id\"):\n        from rapidata.rapidata_client.order.rapidata_order import RapidataOrder\n\n        order = self.__openapi_service.order_api.order_order_id_get(order_id)\n\n        return RapidataOrder(\n            order_id=order_id,\n            name=order.order_name,\n            openapi_service=self.__openapi_service,\n        )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/order/rapidata_order_manager/#rapidata.rapidata_client.order.rapidata_order_manager.RapidataOrderManager.find_orders","title":"find_orders","text":"<pre><code>find_orders(\n    name: str = \"\", amount: int = 10\n) -&gt; list[RapidataOrder]\n</code></pre> <p>Find your recent orders given criteria. If nothing is provided, it will return the most recent order.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the order - matching order will contain the name. Defaults to \"\" for any order.</p> <code>''</code> <code>amount</code> <code>int</code> <p>The amount of orders to return. Defaults to 10.</p> <code>10</code> <p>Returns:</p> Type Description <code>list[RapidataOrder]</code> <p>list[RapidataOrder]: A list of RapidataOrder instances.</p> Source code in <code>src/rapidata/rapidata_client/order/rapidata_order_manager.py</code> <pre><code>def find_orders(self, name: str = \"\", amount: int = 10) -&gt; list[RapidataOrder]:\n    \"\"\"Find your recent orders given criteria. If nothing is provided, it will return the most recent order.\n\n    Args:\n        name (str, optional): The name of the order - matching order will contain the name. Defaults to \"\" for any order.\n        amount (int, optional): The amount of orders to return. Defaults to 10.\n\n    Returns:\n        list[RapidataOrder]: A list of RapidataOrder instances.\n    \"\"\"\n    with tracer.start_as_current_span(\"RapidataOrderManager.find_orders\"):\n        from rapidata.api_client.models.page_info import PageInfo\n        from rapidata.api_client.models.query_model import QueryModel\n        from rapidata.api_client.models.root_filter import RootFilter\n        from rapidata.api_client.models.filter import Filter\n        from rapidata.api_client.models.filter_operator import FilterOperator\n        from rapidata.api_client.models.sort_criterion import SortCriterion\n        from rapidata.api_client.models.sort_direction import SortDirection\n\n        order_page_result = self.__openapi_service.order_api.orders_get(\n            QueryModel(\n                page=PageInfo(index=1, size=amount),\n                filter=RootFilter(\n                    filters=[\n                        Filter(\n                            field=\"OrderName\",\n                            operator=FilterOperator.CONTAINS,\n                            value=name,\n                        )\n                    ]\n                ),\n                sortCriteria=[\n                    SortCriterion(\n                        direction=SortDirection.DESC, propertyName=\"OrderDate\"\n                    )\n                ],\n            )\n        )\n\n        orders = [\n            self.get_order_by_id(order.id) for order in order_page_result.items\n        ]\n        return orders\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/results/rapidata_results/","title":"Rapidata results","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/results/rapidata_results/#rapidata.rapidata_client.results.rapidata_results.RapidataResults","title":"RapidataResults","text":"<p>               Bases: <code>dict</code></p> <p>A specialized dictionary class for handling Rapidata API results. Extends the built-in dict class with specialized methods.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/results/rapidata_results/#rapidata.rapidata_client.results.rapidata_results.RapidataResults.to_pandas","title":"to_pandas","text":"<pre><code>to_pandas(split_details: bool = False) -&gt; DataFrame\n</code></pre> Warning <p>This method is currently under development. The structure of the results may change in the future.</p> <p>Converts the results to a pandas DataFrame.</p> <p>For Compare results, creates standardized A/B columns for metrics. For regular results, flattens nested dictionaries into columns with underscore-separated names.</p> <p>Parameters:</p> Name Type Description Default <code>split_details</code> <code>bool</code> <p>If True, splits each datapoint by its detailed results,           creating a row for each response with global metrics copied.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: A DataFrame containing the processed results</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If split_details is True but no detailed results are found</p> Source code in <code>src/rapidata/rapidata_client/results/rapidata_results.py</code> <pre><code>def to_pandas(self, split_details: bool = False) -&gt; \"pd.DataFrame\":\n    \"\"\"\n    Warning:\n        This method is currently under development. The structure of the results may change in the future.\n\n    Converts the results to a pandas DataFrame.\n\n    For Compare results, creates standardized A/B columns for metrics.\n    For regular results, flattens nested dictionaries into columns with underscore-separated names.\n\n    Args:\n        split_details: If True, splits each datapoint by its detailed results,\n                      creating a row for each response with global metrics copied.\n\n    Returns:\n        pd.DataFrame: A DataFrame containing the processed results\n\n    Raises:\n        ValueError: If split_details is True but no detailed results are found\n    \"\"\"\n    import pandas as pd\n    from pandas.core.indexes.base import Index\n\n    if \"results\" not in self or not self[\"results\"]:\n        return pd.DataFrame()\n\n    if self[\"info\"].get(\"orderType\") is None:\n        managed_print(\n            \"Warning: Results are old and Order type is not specified. Dataframe might be wrong.\"\n        )\n\n    # Check for detailed results if split_details is True\n    if split_details:\n        if not self._has_detailed_results():\n            raise ValueError(\"No detailed results found in the data\")\n        return self._to_pandas_with_detailed_results()\n\n    if (\n        self[\"info\"].get(\"orderType\") == \"Compare\"\n        or self[\"info\"].get(\"orderType\") == \"Ranking\"\n    ):\n        return self._compare_to_pandas()\n\n    # Get the structure from first item\n    first_item = self[\"results\"][0]\n    columns = []\n    path_map = {}  # Maps flattened column names to paths to reach the values\n\n    # Build the column structure once\n    self._build_column_structure(first_item, columns, path_map)\n\n    # Extract data using the known structure\n    data = []\n    for item in self[\"results\"]:\n        row = []\n        for path in path_map.values():\n            value = self._get_value_from_path(item, path)\n            row.append(value)\n        data.append(row)\n\n    return pd.DataFrame(data, columns=Index(columns))\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/results/rapidata_results/#rapidata.rapidata_client.results.rapidata_results.RapidataResults.to_json","title":"to_json","text":"<pre><code>to_json(path: str = './results.json') -&gt; None\n</code></pre> <p>Saves the results to a JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The file path where the JSON should be saved. Defaults to \"./results.json\".</p> <code>'./results.json'</code> Source code in <code>src/rapidata/rapidata_client/results/rapidata_results.py</code> <pre><code>def to_json(self, path: str = \"./results.json\") -&gt; None:\n    \"\"\"\n    Saves the results to a JSON file.\n\n    Args:\n        path: The file path where the JSON should be saved. Defaults to \"./results.json\".\n    \"\"\"\n    with open(path, \"w\") as f:\n        json.dump(self, f)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/selection/ab_test_selection/","title":"Ab test selection","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/selection/ab_test_selection/#rapidata.rapidata_client.selection.ab_test_selection.AbTestSelection","title":"AbTestSelection","text":"<pre><code>AbTestSelection(\n    a_selections: Sequence[RapidataSelection],\n    b_selections: Sequence[RapidataSelection],\n)\n</code></pre> <p>               Bases: <code>RapidataSelection</code></p> <p>AbTestSelection Class</p> <p>Splits the userbase into two segments and serves them a different collection of rapids.</p> <p>Useful for A/B Test.</p> <p>Parameters:</p> Name Type Description Default <code>a_selections</code> <code>Sequence[RapidataSelection]</code> <p>List of selections for group A.</p> required <code>b_selections</code> <code>Sequence[RapidataSelection]</code> <p>List of selections for group B.</p> required Source code in <code>src/rapidata/rapidata_client/selection/ab_test_selection.py</code> <pre><code>def __init__(\n    self,\n    a_selections: Sequence[RapidataSelection],\n    b_selections: Sequence[RapidataSelection],\n):\n    self.a_selections = a_selections\n    self.b_selections = b_selections\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/selection/capped_selection/","title":"Capped selection","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/selection/capped_selection/#rapidata.rapidata_client.selection.capped_selection.CappedSelection","title":"CappedSelection","text":"<pre><code>CappedSelection(\n    selections: Sequence[RapidataSelection], max_rapids: int\n)\n</code></pre> <p>               Bases: <code>RapidataSelection</code></p> <p>CappedSelection Class</p> <p>Takes in different selections and caps the amount of rapids that can be shown.</p> <p>Useful for demographic and conditional validation selections.</p> <p>Parameters:</p> Name Type Description Default <code>selections</code> <code>Sequence[RapidataSelection]</code> <p>List of selections to cap.</p> required <code>max_rapids</code> <code>int</code> <p>The maximum amount of rapids that can be shown for this selection.</p> required Source code in <code>src/rapidata/rapidata_client/selection/capped_selection.py</code> <pre><code>def __init__(self, selections: Sequence[RapidataSelection], max_rapids: int):\n    self.selections = selections\n    self.max_rapids = max_rapids\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/selection/conditional_validation_selection/","title":"Conditional validation selection","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/selection/conditional_validation_selection/#rapidata.rapidata_client.selection.conditional_validation_selection.ConditionalValidationSelection","title":"ConditionalValidationSelection","text":"<pre><code>ConditionalValidationSelection(\n    validation_set_id: str,\n    thresholds: list[float],\n    chances: list[float],\n    rapid_counts: list[int],\n    dimension: Optional[str] = None,\n    dimensions: Optional[list[str]] = None,\n)\n</code></pre> <p>               Bases: <code>RapidataSelection</code></p> <p>Conditional validation selection class.</p> <p>Probabilistically decides how many validation rapids you want to show per session based on the user score.</p> <p>Parameters:</p> Name Type Description Default <code>validation_set_id</code> <code>str</code> <p>The id of the validation set to be used.</p> required <code>thresholds</code> <code>list[float]</code> <p>The thresholds to use for the user score.</p> required <code>chances</code> <code>list[float]</code> <p>The chances of showing a validation rapid for each threshold.</p> required <code>rapid_counts</code> <code>list[int]</code> <p>The amount of validation rapids that will be shown per session of this validation set for each threshold if selected by probability. (all or nothing)</p> required <code>dimensions</code> <code>Optional[list[str]]</code> <p>The dimensions of the userScore that will be used in the thresholds. Defaults to None.</p> <code>None</code> Example <p></p><pre><code>ConditionalValidationSelection(\n    validation_set_id=\"validation_set_id\",\n    thresholds=[0, 0.7], # (0 must be the first threshold)\n    chances=[1, 0.2],\n    rapid_counts=[1, 1]\n)\n</code></pre> This means that there's a 100% chance of showing a validation rapid if the user score is between 0 and 0.7, and a 20% chance of showing a validation rapid if the user score is between 0.7 and 1.<p></p> Source code in <code>src/rapidata/rapidata_client/selection/conditional_validation_selection.py</code> <pre><code>def __init__(\n    self,\n    validation_set_id: str,\n    thresholds: list[float],\n    chances: list[float],\n    rapid_counts: list[int],\n    dimension: Optional[str] = None,\n    dimensions: Optional[list[str]] = None,\n):\n    if len(thresholds) != len(chances) or len(thresholds) != len(rapid_counts):\n        raise ValueError(\n            \"The lengths of thresholds, chances and rapid_counts must be equal.\"\n        )\n\n    if dimension:\n        logger.warning(\"dimension is deprecated, use dimensions instead\")\n        dimensions = (dimensions or []) + [dimension]\n\n    self.validation_set_id = validation_set_id\n    self.thresholds = thresholds\n    self.chances = chances\n    self.rapid_counts = rapid_counts\n    self.dimensions = dimensions\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/selection/demographic_selection/","title":"Demographic selection","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/selection/demographic_selection/#rapidata.rapidata_client.selection.demographic_selection.DemographicSelection","title":"DemographicSelection","text":"<pre><code>DemographicSelection(keys: list[str], max_rapids: int)\n</code></pre> <p>               Bases: <code>RapidataSelection</code></p> <p>Demographic selection class.</p> <p>This is used to ask demographic questions in an order.</p> <p>The keys will select the rapids based on the confidence we already saved for each user.</p> <p>If the confidence is high, the users will be selected to solve the rapids with lower probability.</p> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>list[str]</code> <p>List of keys for the demographic rapids to be shown. As an example: \"age\"</p> required <code>max_rapids</code> <code>int</code> <p>The maximum number of rapids to run.</p> <p>Allows to provide more keys, in case some of the earlier ones are not selected because of high confidence.</p> required Example <p></p><pre><code>DemographicSelection([\"age\", \"gender\"], 1)\n</code></pre> This will try to ask the user about their age, if that is not selected due to an already high confidence, it will try asking about their gender. The gender question may also be skipped if the confidence is high enough.<p></p> Source code in <code>src/rapidata/rapidata_client/selection/demographic_selection.py</code> <pre><code>def __init__(self, keys: list[str], max_rapids: int):\n    self.keys = keys\n    self.max_rapids = max_rapids\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/selection/effort_selection/","title":"Effort selection","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/selection/effort_selection/#rapidata.rapidata_client.selection.effort_selection.EffortSelection","title":"EffortSelection","text":"<pre><code>EffortSelection(\n    effort_budget: int,\n    retrieval_mode: RapidataRetrievalMode = Shuffled,\n    max_iterations: int | None = None,\n)\n</code></pre> <p>               Bases: <code>RapidataSelection</code></p> <p>With this selection you can define the effort budget you have for a task. As an example, you have a task that takes 10 seconds to complete. The effort budget would be 10.</p> <p>Parameters:</p> Name Type Description Default <code>effort_budget</code> <code>int</code> <p>The effort budget for the task.</p> required <code>retrieval_mode</code> <code>RetrievalMode</code> <p>The retrieval mode for the task.</p> <code>Shuffled</code> <code>max_iterations</code> <code>int | None</code> <p>The maximum number of iterations for the task.</p> <code>None</code> Source code in <code>src/rapidata/rapidata_client/selection/effort_selection.py</code> <pre><code>def __init__(\n    self,\n    effort_budget: int,\n    retrieval_mode: RapidataRetrievalMode = RapidataRetrievalMode.Shuffled,\n    max_iterations: int | None = None,\n):\n    self.effort_budget = effort_budget\n    self.retrieval_mode = retrieval_mode\n    self.max_iterations = max_iterations\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/selection/labeling_selection/","title":"Labeling selection","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/selection/labeling_selection/#rapidata.rapidata_client.selection.labeling_selection.LabelingSelection","title":"LabelingSelection","text":"<pre><code>LabelingSelection(\n    amount: int,\n    retrieval_mode: RapidataRetrievalMode = Shuffled,\n    max_iterations: int | None = None,\n)\n</code></pre> <p>               Bases: <code>RapidataSelection</code></p> <p>Labeling selection class.</p> <p>Decides how many actual datapoints you want to show per session.</p> <p>Parameters:</p> Name Type Description Default <code>amount</code> <code>int</code> <p>The amount of labeling rapids that will be shown per session.</p> required <code>retrieval_mode</code> <code>RetrievalMode</code> <p>The retrieval mode to use. Defaults to \"Shuffled\".</p> <code>Shuffled</code> <code>max_iterations</code> <code>int | None</code> <p>An annotator can answer the same task only once if the retrieval_mode is \"Shuffled\" or \"Sequential\". max_iterations can increase the amount of responses an annotator can do to the same task (datapoint).</p> <code>None</code> Source code in <code>src/rapidata/rapidata_client/selection/labeling_selection.py</code> <pre><code>def __init__(\n    self,\n    amount: int,\n    retrieval_mode: RapidataRetrievalMode = RapidataRetrievalMode.Shuffled,\n    max_iterations: int | None = None,\n):\n    self.amount = amount\n    self.retrieval_mode = retrieval_mode\n    self.max_iterations = max_iterations\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/selection/rapidata_retrieval_modes/","title":"Rapidata retrieval modes","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/selection/rapidata_retrieval_modes/#rapidata.rapidata_client.selection.rapidata_retrieval_modes.RapidataRetrievalMode","title":"RapidataRetrievalMode","text":"<p>               Bases: <code>Enum</code></p> <p>Enum for defining retrieval modes for datapoints.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/selection/rapidata_retrieval_modes/#rapidata.rapidata_client.selection.rapidata_retrieval_modes.RapidataRetrievalMode.Shuffled","title":"Shuffled  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>Shuffled = SHUFFLED\n</code></pre> <p>Will shuffle the datapoints randomly for each user. The user will then see the datapoints in that order. This will take into account the \"max_iterations\" parameter.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/selection/rapidata_retrieval_modes/#rapidata.rapidata_client.selection.rapidata_retrieval_modes.RapidataRetrievalMode.Sequential","title":"Sequential  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>Sequential = SEQUENTIAL\n</code></pre> <p>Will show the datapoints in the order they are in the dataset. This will take into account the \"max_iterations\" parameter.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/selection/rapidata_retrieval_modes/#rapidata.rapidata_client.selection.rapidata_retrieval_modes.RapidataRetrievalMode.Random","title":"Random  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>Random = RANDOM\n</code></pre> <p>Will just randomly feed the datapoints to the annotators. This will NOT take into account the \"max_iterations\" parameter.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/selection/rapidata_selections/","title":"Rapidata selections","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/selection/rapidata_selections/#rapidata.rapidata_client.selection.rapidata_selections.RapidataSelections","title":"RapidataSelections","text":"<p>RapidataSelections Classes</p> <p>Selections are used to define what type of tasks and in what order they are shown to the user. All selections combined are called a \"Session\". A session can contain multiple tasks of different types of tasks. As an example, a session might be 1 validation task, 2 labeling tasks.</p> <p>Attributes:</p> Name Type Description <code>labeling</code> <code>LabelingSelection</code> <p>Decides how many actual datapoints you want to show per session.</p> <code>validation</code> <code>ValidationSelection</code> <p>Decides how many validation rapids you want to show per session.</p> <code>conditional_validation</code> <code>ConditionalValidationSelection</code> <p>Probabilistically decides how many validation rapids you want to show per session based on the user score.</p> <code>demographic</code> <code>DemographicSelection</code> <p>Decides if and how many demographic questions you want to show per session.</p> <code>capped</code> <code>CappedSelection</code> <p>Takes in different selections and caps the amount of rapids that can be shown.</p> <code>shuffling</code> <code>ShufflingSelection</code> <p>Shuffles the selections provided in the list.</p> Example <pre><code>from rapidata import LabelingSelection, ValidationSelection\nselections=[ValidationSelection(\"your-validation-set-id\", 1),\n            LabelingSelection(2)]\n</code></pre> <p>This will require annotators to complete one validation task followed by two labeling tasks.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/selection/shuffling_selection/","title":"Shuffling selection","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/selection/shuffling_selection/#rapidata.rapidata_client.selection.shuffling_selection.ShufflingSelection","title":"ShufflingSelection","text":"<pre><code>ShufflingSelection(selections: Sequence[RapidataSelection])\n</code></pre> <p>               Bases: <code>RapidataSelection</code></p> <p>ShufflingSelection Class</p> <p>Shuffles the selections provided in the list.</p> <p>Parameters:</p> Name Type Description Default <code>selections</code> <code>Sequence[RapidataSelection]</code> <p>List of selections to shuffle.</p> required Example <p></p><pre><code>selection = ShufflingSelection(\n            [ValidSelections(\"validation_id\", 1), LabelingSelection(2)])\n</code></pre> This means that the users will get 1 validation task and 2 labeling tasks in a shuffled order.<p></p> Source code in <code>src/rapidata/rapidata_client/selection/shuffling_selection.py</code> <pre><code>def __init__(self, selections: Sequence[RapidataSelection]):\n    self.selections = selections\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/selection/static_selection/","title":"Static selection","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/selection/static_selection/#rapidata.rapidata_client.selection.static_selection.StaticSelection","title":"StaticSelection","text":"<pre><code>StaticSelection(rapid_ids: list[str])\n</code></pre> <p>               Bases: <code>RapidataSelection</code></p> <p>StaticSelection Class</p> <p>Given a list of RapidIds, theses specific rapids will be shown in order for every session.</p> <p>Parameters:</p> Name Type Description Default <code>rapid_ids</code> <code>list[str]</code> <p>List of rapid ids to show.</p> required Source code in <code>src/rapidata/rapidata_client/selection/static_selection.py</code> <pre><code>def __init__(self, rapid_ids: list[str]):\n    self.rapid_ids = rapid_ids\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/selection/validation_selection/","title":"Validation selection","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/selection/validation_selection/#rapidata.rapidata_client.selection.validation_selection.ValidationSelection","title":"ValidationSelection","text":"<pre><code>ValidationSelection(\n    validation_set_id: str, amount: int = 1\n)\n</code></pre> <p>               Bases: <code>RapidataSelection</code></p> <p>Validation selection class.</p> <p>Decides how many validation rapids you want to show per session.</p> <p>Parameters:</p> Name Type Description Default <code>validation_set_id</code> <code>str</code> <p>The id of the validation set to be used.</p> required <code>amount</code> <code>int</code> <p>The amount of validation rapids that will be shown per session of this validation set.</p> <code>1</code> Source code in <code>src/rapidata/rapidata_client/selection/validation_selection.py</code> <pre><code>def __init__(self, validation_set_id: str, amount: int = 1):\n    self.validation_set_id = validation_set_id\n    self.amount = amount\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/settings/alert_on_fast_response/","title":"Alert on fast response","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/settings/alert_on_fast_response/#rapidata.rapidata_client.settings.alert_on_fast_response.AlertOnFastResponse","title":"AlertOnFastResponse","text":"<pre><code>AlertOnFastResponse(threshold: int)\n</code></pre> <p>               Bases: <code>RapidataSetting</code></p> <p>Gives an alert as a pop up on the UI when the response time is less than the milliseconds.</p> <p>Parameters:</p> Name Type Description Default <code>threshold</code> <code>int</code> <p>if the user responds in less than this time, an alert will be shown.</p> required Source code in <code>src/rapidata/rapidata_client/settings/alert_on_fast_response.py</code> <pre><code>def __init__(self, threshold: int):\n    if not isinstance(threshold, int):\n        raise ValueError(\"The alert must be an integer.\")\n    if threshold &lt; 10:\n        managed_print(\n            f\"Warning: Are you sure you want to set the threshold so low ({threshold} milliseconds)?\"\n        )\n    if threshold &gt; 25000:\n        raise ValueError(\"The alert must be less than 25000 milliseconds.\")\n    if threshold &lt; 0:\n        raise ValueError(\"The alert must be greater than or equal to 0.\")\n\n    super().__init__(key=\"alert_on_fast_response\", value=threshold)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/settings/allow_neither_both/","title":"Allow neither both","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/settings/allow_neither_both/#rapidata.rapidata_client.settings.allow_neither_both.AllowNeitherBoth","title":"AllowNeitherBoth","text":"<pre><code>AllowNeitherBoth(value: bool = True)\n</code></pre> <p>               Bases: <code>RapidataSetting</code></p> <p>Set whether to allow neither or both options. This setting only works for compare orders.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>bool</code> <p>Whether to allow neither or both options. Defaults to True. If this setting is not added to an order, the users won't be able to select neither or both.</p> <code>True</code> Source code in <code>src/rapidata/rapidata_client/settings/allow_neither_both.py</code> <pre><code>def __init__(self, value: bool = True):\n    if not isinstance(value, bool):\n        raise ValueError(\"The value must be a boolean.\")\n    super().__init__(key=\"compare_unsure\", value=value)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/settings/custom_setting/","title":"Custom setting","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/settings/custom_setting/#rapidata.rapidata_client.settings.custom_setting.CustomSetting","title":"CustomSetting","text":"<pre><code>CustomSetting(key: str, value: str)\n</code></pre> <p>               Bases: <code>RapidataSetting</code></p> <p>Set a custom setting with the given key and value. Use this to enable features that do not have a dedicated method (yet)</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key for the custom setting.</p> required <code>value</code> <code>str</code> <p>The value for the custom setting.</p> required Source code in <code>src/rapidata/rapidata_client/settings/custom_setting.py</code> <pre><code>def __init__(self, key: str, value: str):\n    if not isinstance(key, str):\n        raise ValueError(\"The key must be a string.\")\n\n    super().__init__(key=key, value=value)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/settings/free_text_minimum_characters/","title":"Free text minimum characters","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/settings/free_text_minimum_characters/#rapidata.rapidata_client.settings.free_text_minimum_characters.FreeTextMinimumCharacters","title":"FreeTextMinimumCharacters","text":"<pre><code>FreeTextMinimumCharacters(value: int)\n</code></pre> <p>               Bases: <code>RapidataSetting</code></p> <p>Set the minimum number of characters a user has to type.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>int</code> <p>The minimum number of characters for free text.</p> required Source code in <code>src/rapidata/rapidata_client/settings/free_text_minimum_characters.py</code> <pre><code>def __init__(self, value: int):\n    if value &lt; 1:\n        raise ValueError(\n            \"The minimum number of characters must be greater than or equal to 1.\"\n        )\n    if value &gt; 40:\n        managed_print(\n            f\"Warning: Are you sure you want to set the minimum number of characters at {value}?\"\n        )\n    super().__init__(key=\"free_text_minimum_characters\", value=value)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/settings/mute_video/","title":"Mute video","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/settings/mute_video/#rapidata.rapidata_client.settings.mute_video.MuteVideo","title":"MuteVideo","text":"<pre><code>MuteVideo(value: bool = True)\n</code></pre> <p>               Bases: <code>RapidataSetting</code></p> <p>Mute the video. If this setting is not supplied, the video will not be muted.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>bool</code> <p>Whether to mute the video. Defaults to True.</p> <code>True</code> Source code in <code>src/rapidata/rapidata_client/settings/mute_video.py</code> <pre><code>def __init__(self, value: bool = True):\n    if not isinstance(value, bool):\n        raise ValueError(\"The value must be a boolean.\")\n    super().__init__(key=\"mute_video_asset\", value=value)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/settings/no_shuffle/","title":"No shuffle","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/settings/no_shuffle/#rapidata.rapidata_client.settings.no_shuffle.NoShuffle","title":"NoShuffle","text":"<pre><code>NoShuffle(value: bool = True)\n</code></pre> <p>               Bases: <code>RapidataSetting</code></p> <p>Only for classification and compare tasks. If true, the order of the categories / images will not be shuffled and presented in the same order as specified.</p> <p>If this is not added to the order, the shuffling will be active.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>bool</code> <p>Whether to disable shuffling. Defaults to True for function call.</p> <code>True</code> Source code in <code>src/rapidata/rapidata_client/settings/no_shuffle.py</code> <pre><code>def __init__(self, value: bool = True):\n    if not isinstance(value, bool):\n        raise ValueError(\"The value must be a boolean.\")\n\n    super().__init__(key=\"no_shuffle\", value=value)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/settings/play_video_until_the_end/","title":"Play video until the end","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/settings/play_video_until_the_end/#rapidata.rapidata_client.settings.play_video_until_the_end.PlayVideoUntilTheEnd","title":"PlayVideoUntilTheEnd","text":"<pre><code>PlayVideoUntilTheEnd(additional_time: int = 0)\n</code></pre> <p>               Bases: <code>RapidataSetting</code></p> <p>Allows users to only answer once the video has finished playing. The additional time gets added on top of the video duration. Can be negative to allow answers before the video ends.</p> <p>Parameters:</p> Name Type Description Default <code>additional_time</code> <code>int</code> <p>Additional time in milliseconds. Defaults to 0.</p> <code>0</code> Source code in <code>src/rapidata/rapidata_client/settings/play_video_until_the_end.py</code> <pre><code>def __init__(self, additional_time: int = 0):\n    if additional_time &lt; -25000 or additional_time &gt; 25000:\n        raise ValueError(\"The additional time must be between -25000 and 25000.\")\n\n    super().__init__(\n        key=\"alert_on_fast_response_add_media_duration\", value=additional_time\n    )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/settings/rapidata_settings/","title":"Rapidata settings","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/settings/rapidata_settings/#rapidata.rapidata_client.settings.rapidata_settings.RapidataSettings","title":"RapidataSettings","text":"<p>Container class for all setting factory functions</p> <p>Settings can be added to an order to determine the behaviour of the task.</p> <p>Attributes:</p> Name Type Description <code>alert_on_fast_response</code> <code>AlertOnFastResponse</code> <p>Gives an alert as a pop up on the UI when the response time is less than the milliseconds.</p> <code>translation_behaviour</code> <code>TranslationBehaviour</code> <p>Defines what's the behaviour of the translation in the UI.</p> <code>free_text_minimum_characters</code> <code>FreeTextMinimumCharacters</code> <p>Only for free text tasks. Set the minimum number of characters a user has to type.</p> <code>no_shuffle</code> <code>NoShuffle</code> <p>Only for classification and compare tasks. If true, the order of the categories / images will not be shuffled and presented in the same order as specified.</p> <code>play_video_until_the_end</code> <code>PlayVideoUntilTheEnd</code> <p>Allows users to only answer once the video has finished playing.</p> <code>allow_neither_both</code> <code>AllowNeitherBoth</code> <p>Only for compare tasks. If true, the users will be able to select neither or both instead of exclusively one of the options.</p> <code>swap_context_instruction</code> <code>SwapContextInstruction</code> <p>Swap the place of the context and instruction.</p> <code>mute_video</code> <code>MuteVideo</code> <p>Mute the video.</p> Example <pre><code>from rapidata import FreeTextMinimumCharacters\nsettings=[FreeTextMinimumCharacters(10)]\n</code></pre> <p>This can be used in a free text order to set the minimum number of characters required to submit the task.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/settings/swap_context_instruction/","title":"Swap context instruction","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/settings/swap_context_instruction/#rapidata.rapidata_client.settings.swap_context_instruction.SwapContextInstruction","title":"SwapContextInstruction","text":"<pre><code>SwapContextInstruction(value: bool = True)\n</code></pre> <p>               Bases: <code>RapidataSetting</code></p> <p>Swap the place of the context and instruction.</p> <p>If set to true, the instruction will be shown on top and the context below. if collapsed, only the instruction will be shown.</p> <p>By default, the context will be shown on top and the instruction below.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>bool</code> <p>Whether to swap the place of the context and instruction.</p> <code>True</code> Source code in <code>src/rapidata/rapidata_client/settings/swap_context_instruction.py</code> <pre><code>def __init__(self, value: bool = True):\n    if not isinstance(value, bool):\n        raise ValueError(\"The value must be a boolean.\")\n\n    super().__init__(key=\"swap_question_and_prompt\", value=value)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/settings/translation_behaviour/","title":"Translation behaviour","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/settings/translation_behaviour/#rapidata.rapidata_client.settings.translation_behaviour.TranslationBehaviour","title":"TranslationBehaviour","text":"<pre><code>TranslationBehaviour(value: TranslationBehaviourOptions)\n</code></pre> <p>               Bases: <code>RapidataSetting</code></p> <p>Defines what's the behaviour of the translation in the UI. Will not translate text datapoints or sentences.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>TranslationBehaviourOptions</code> <p>The translation behaviour.</p> required Source code in <code>src/rapidata/rapidata_client/settings/translation_behaviour.py</code> <pre><code>def __init__(self, value: TranslationBehaviourOptions):\n    if not isinstance(value, TranslationBehaviourOptions):\n        raise ValueError(\"The value must be a TranslationBehaviourOptions.\")\n\n    super().__init__(key=\"translation_behaviour\", value=value.value)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/settings/models/translation_behaviour_options/","title":"Translation behaviour options","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/settings/models/translation_behaviour_options/#rapidata.rapidata_client.settings.models.translation_behaviour_options.TranslationBehaviourOptions","title":"TranslationBehaviourOptions","text":"<p>               Bases: <code>Enum</code></p> <p>The options for the translation behaviour setting.</p> <p>Attributes:</p> Name Type Description <code>BOTH</code> <p>Show both the original and the translated text. May clutter the screen if the options are too long.</p> <code>ONLY_ORIGINAL</code> <p>Show only the original text.</p> <code>ONLY_TRANSLATED</code> <p>Show only the translated text.</p>","boost":0.2},{"location":"reference/rapidata/rapidata_client/utils/threaded_uploader/","title":"Threaded uploader","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/utils/threaded_uploader/#rapidata.rapidata_client.utils.threaded_uploader.ThreadedUploader","title":"ThreadedUploader","text":"<pre><code>ThreadedUploader(\n    upload_fn: Callable[[T, int], None],\n    description: str = \"Uploading items\",\n)\n</code></pre> <p>               Bases: <code>Generic[T]</code></p> <p>A generic multi-threaded uploader that handles retries, progress tracking, and OpenTelemetry context propagation.</p> <p>          Class Type Parameters:        </p> Name Bound or Constraints Description Default <code>T</code> <p>The type of items being uploaded.</p> required <p>Parameters:</p> Name Type Description Default <code>upload_fn</code> <code>Callable[[T, int], None]</code> <p>A function that uploads a single item. Takes (item, index) as arguments.</p> required <code>description</code> <code>str</code> <p>Description shown in the progress bar.</p> <code>'Uploading items'</code> Source code in <code>src/rapidata/rapidata_client/utils/threaded_uploader.py</code> <pre><code>def __init__(\n    self,\n    upload_fn: Callable[[T, int], None],\n    description: str = \"Uploading items\",\n):\n    \"\"\"\n    Initialize the threaded uploader.\n\n    Args:\n        upload_fn: A function that uploads a single item. Takes (item, index) as arguments.\n        description: Description shown in the progress bar.\n    \"\"\"\n    self.upload_fn = upload_fn\n    self.description = description\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/utils/threaded_uploader/#rapidata.rapidata_client.utils.threaded_uploader.ThreadedUploader.upload","title":"upload","text":"<pre><code>upload(\n    items: list[T],\n) -&gt; tuple[list[T], list[FailedUpload[T]]]\n</code></pre> <p>Upload items in parallel using multiple threads.</p> <p>Parameters:</p> Name Type Description Default <code>items</code> <code>list[T]</code> <p>List of items to upload.</p> required <p>Returns:</p> Type Description <code>tuple[list[T], list[FailedUpload[T]]]</code> <p>tuple[list[T], list[FailedUpload[T]]]: Lists of successful uploads and failed uploads with error details.</p> Source code in <code>src/rapidata/rapidata_client/utils/threaded_uploader.py</code> <pre><code>def upload(self, items: list[T]) -&gt; tuple[list[T], list[FailedUpload[T]]]:\n    \"\"\"\n    Upload items in parallel using multiple threads.\n\n    Args:\n        items: List of items to upload.\n\n    Returns:\n        tuple[list[T], list[FailedUpload[T]]]: Lists of successful uploads and failed uploads with error details.\n    \"\"\"\n    logger.debug(\n        \"Uploading %s items with %s configuration\",\n        len(items),\n        rapidata_config.upload,\n    )\n    successful_uploads: list[T] = []\n    failed_uploads: list[FailedUpload[T]] = []\n\n    with tqdm(\n        total=len(items),\n        desc=self.description,\n        disable=rapidata_config.logging.silent_mode,\n    ) as progress_bar:\n\n        def process_upload_with_context(\n            context: otel_context.Context, item: T, index: int\n        ) -&gt; tuple[list[T], list[FailedUpload[T]]]:\n            \"\"\"Wrapper function that runs upload with the provided context.\"\"\"\n            token = otel_context.attach(context)\n            try:\n                return self._process_single_upload(item, index)\n            finally:\n                otel_context.detach(token)\n\n        # Capture the current OpenTelemetry context before creating threads\n        current_context = otel_context.get_current()\n\n        with ThreadPoolExecutor(\n            max_workers=rapidata_config.upload.maxWorkers\n        ) as executor:\n            futures = [\n                executor.submit(\n                    process_upload_with_context,\n                    current_context,\n                    item,\n                    i,\n                )\n                for i, item in enumerate(items)\n            ]\n\n            for future in as_completed(futures):\n                try:\n                    chunk_successful, chunk_failed = future.result()\n                    successful_uploads.extend(chunk_successful)\n                    failed_uploads.extend(chunk_failed)\n                    progress_bar.update(len(chunk_successful) + len(chunk_failed))\n                except Exception as e:\n                    logger.error(\"Future execution failed: %s\", str(e))\n\n    if failed_uploads:\n        logger.error(\n            \"Upload failed for %s items: %s\",\n            len(failed_uploads),\n            failed_uploads,\n        )\n\n    return successful_uploads, failed_uploads\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/validation/rapidata_validation_set/","title":"Rapidata validation set","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/validation/rapidata_validation_set/#rapidata.rapidata_client.validation.rapidata_validation_set.RapidataValidationSet","title":"RapidataValidationSet","text":"<pre><code>RapidataValidationSet(\n    validation_set_id,\n    name: str,\n    dimensions: list[str],\n    openapi_service: OpenAPIService,\n)\n</code></pre> <p>A class for interacting with a Rapidata validation set.</p> <p>Represents a set of all the validation tasks that can be added to an order.</p> <p>When added to an order, the tasks will be selected randomly from the set.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>The ID of the validation set.</p> <code>name</code> <code>str</code> <p>The name of the validation set.</p> Source code in <code>src/rapidata/rapidata_client/validation/rapidata_validation_set.py</code> <pre><code>def __init__(\n    self,\n    validation_set_id,\n    name: str,\n    dimensions: list[str],\n    openapi_service: OpenAPIService,\n):\n    self.id = validation_set_id\n    self.name = name\n    self.dimensions = dimensions\n    self.validation_set_details_page = (\n        f\"https://app.{openapi_service.environment}/validation-set/detail/{self.id}\"\n    )\n    self._openapi_service = openapi_service\n    self.validation_rapid_uploader = ValidationRapidUploader(openapi_service)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/validation/rapidata_validation_set/#rapidata.rapidata_client.validation.rapidata_validation_set.RapidataValidationSet.add_rapid","title":"add_rapid","text":"<pre><code>add_rapid(rapid: Rapid)\n</code></pre> <p>Add a Rapid to the validation set.</p> <p>Parameters:</p> Name Type Description Default <code>rapid</code> <code>Rapid</code> <p>The Rapid to add to the validation set.</p> required Source code in <code>src/rapidata/rapidata_client/validation/rapidata_validation_set.py</code> <pre><code>def add_rapid(self, rapid: Rapid):\n    \"\"\"Add a Rapid to the validation set.\n\n    Args:\n        rapid (Rapid): The Rapid to add to the validation set.\n    \"\"\"\n    with tracer.start_as_current_span(\"RapidataValidationSet.add_rapid\"):\n        logger.debug(\"Adding rapid %s to validation set %s\", rapid, self.id)\n        self.validation_rapid_uploader.upload_rapid(rapid, self.id)\n    return self\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/validation/rapidata_validation_set/#rapidata.rapidata_client.validation.rapidata_validation_set.RapidataValidationSet.update_dimensions","title":"update_dimensions","text":"<pre><code>update_dimensions(dimensions: list[str])\n</code></pre> <p>Update the dimensions of the validation set.</p> <p>Parameters:</p> Name Type Description Default <code>dimensions</code> <code>list[str]</code> <p>The new dimensions of the validation set.</p> required Source code in <code>src/rapidata/rapidata_client/validation/rapidata_validation_set.py</code> <pre><code>def update_dimensions(self, dimensions: list[str]):\n    \"\"\"Update the dimensions of the validation set.\n\n    Args:\n        dimensions (list[str]): The new dimensions of the validation set.\n    \"\"\"\n    with tracer.start_as_current_span(\"RapidataValidationSet.update_dimensions\"):\n        logger.debug(\n            \"Updating dimensions for validation set %s to %s\", self.id, dimensions\n        )\n        self._openapi_service.validation_api.validation_set_validation_set_id_patch(\n            self.id, UpdateValidationSetModel(dimensions=dimensions)\n        )\n        self.dimensions = dimensions\n        return self\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/validation/rapidata_validation_set/#rapidata.rapidata_client.validation.rapidata_validation_set.RapidataValidationSet.update_should_alert","title":"update_should_alert","text":"<pre><code>update_should_alert(should_alert: bool)\n</code></pre> <p>Determines whether users should be alerted if they answer incorrectly.</p> <p>Parameters:</p> Name Type Description Default <code>should_alert</code> <code>bool</code> <p>Specifies whether users should be alerted for incorrect answers. Defaults to True if not specifically overridden by this method.</p> required Note <p>The userScore dimensions which are updated when a user answers a validation task are updated regardless of the value of <code>should_alert</code>.</p> Source code in <code>src/rapidata/rapidata_client/validation/rapidata_validation_set.py</code> <pre><code>def update_should_alert(self, should_alert: bool):\n    \"\"\"Determines whether users should be alerted if they answer incorrectly.\n\n    Args:\n        should_alert (bool): Specifies whether users should be alerted for incorrect answers. Defaults to True if not specifically overridden by this method.\n\n    Note:\n        The userScore dimensions which are updated when a user answers a validation task are updated regardless of the value of `should_alert`.\n    \"\"\"\n    with tracer.start_as_current_span(\"RapidataValidationSet.update_should_alert\"):\n        logger.debug(\n            \"Setting shouldAlert for validation set %s to %s\", self.id, should_alert\n        )\n        self._openapi_service.validation_api.validation_set_validation_set_id_patch(\n            self.id, UpdateValidationSetModel(shouldAlert=should_alert)\n        )\n        return self\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/validation/rapidata_validation_set/#rapidata.rapidata_client.validation.rapidata_validation_set.RapidataValidationSet.update_can_be_flagged","title":"update_can_be_flagged","text":"<pre><code>update_can_be_flagged(can_be_flagged: bool)\n</code></pre> <p>Update if tasks in the validation set can be flagged for bad accuracy.</p> <p>Parameters:</p> Name Type Description Default <code>can_be_flagged</code> <code>bool</code> <p>Specifies whether tasks in the validation set can be flagged for bad accuracy. Defaults to True if not specifically overridden by this method.</p> required Source code in <code>src/rapidata/rapidata_client/validation/rapidata_validation_set.py</code> <pre><code>def update_can_be_flagged(self, can_be_flagged: bool):\n    \"\"\"Update if tasks in the validation set can be flagged for bad accuracy.\n\n    Args:\n        can_be_flagged (bool): Specifies whether tasks in the validation set can be flagged for bad accuracy. Defaults to True if not specifically overridden by this method.\n    \"\"\"\n    with tracer.start_as_current_span(\n        \"RapidataValidationSet.update_can_be_flagged\"\n    ):\n        logger.debug(\n            \"Setting canBeFlagged for validation set %s to %s\",\n            self.id,\n            can_be_flagged,\n        )\n        self._openapi_service.validation_api.validation_set_validation_set_id_patch(\n            self.id, UpdateValidationSetModel(isFlagOverruled=(not can_be_flagged))\n        )\n        return self\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/validation/rapidata_validation_set/#rapidata.rapidata_client.validation.rapidata_validation_set.RapidataValidationSet.view","title":"view","text":"<pre><code>view() -&gt; None\n</code></pre> <p>Opens the validation set details page in the browser.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the order is not in processing state.</p> Source code in <code>src/rapidata/rapidata_client/validation/rapidata_validation_set.py</code> <pre><code>def view(self) -&gt; None:\n    \"\"\"\n    Opens the validation set details page in the browser.\n\n    Raises:\n        Exception: If the order is not in processing state.\n    \"\"\"\n    logger.info(\"Opening validation set details page in browser...\")\n    could_open_browser = webbrowser.open(self.validation_set_details_page)\n    if not could_open_browser:\n        encoded_url = urllib.parse.quote(\n            self.validation_set_details_page, safe=\"%/:=&amp;?~#+!$,;'@()*[]\"\n        )\n        managed_print(\n            Fore.RED\n            + f\"Please open this URL in your browser: '{encoded_url}'\"\n            + Fore.RESET\n        )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/validation/rapidata_validation_set/#rapidata.rapidata_client.validation.rapidata_validation_set.RapidataValidationSet.delete","title":"delete","text":"<pre><code>delete() -&gt; None\n</code></pre> <p>Deletes the validation set</p> Source code in <code>src/rapidata/rapidata_client/validation/rapidata_validation_set.py</code> <pre><code>def delete(self) -&gt; None:\n    \"\"\"Deletes the validation set\"\"\"\n    with tracer.start_as_current_span(\"RapidataValidationSet.delete\"):\n        logger.info(\"Deleting ValidationSet '%s'\", self)\n        self._openapi_service.validation_api.validation_set_validation_set_id_delete(\n            self.id\n        )\n        logger.debug(\"ValidationSet '%s' has been deleted.\", self)\n        managed_print(f\"ValidationSet '{self}' has been deleted.\")\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/validation/validation_set_manager/","title":"Validation set manager","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/validation/validation_set_manager/#rapidata.rapidata_client.validation.validation_set_manager.ValidationSetManager","title":"ValidationSetManager","text":"<pre><code>ValidationSetManager(openapi_service: OpenAPIService)\n</code></pre> <p>Responsible for everything related to validation sets. From creation to retrieval.</p> <p>Attributes:</p> Name Type Description <code>rapid</code> <code>RapidsManager</code> <p>The RapidsManager instance.</p> Source code in <code>src/rapidata/rapidata_client/validation/validation_set_manager.py</code> <pre><code>def __init__(self, openapi_service: OpenAPIService) -&gt; None:\n    self._openapi_service = openapi_service\n    self.rapid = RapidsManager(openapi_service)\n    logger.debug(\"ValidationSetManager initialized\")\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/validation/validation_set_manager/#rapidata.rapidata_client.validation.validation_set_manager.ValidationSetManager.create_classification_set","title":"create_classification_set","text":"<pre><code>create_classification_set(\n    name: str,\n    instruction: str,\n    answer_options: list[str],\n    datapoints: list[str],\n    truths: list[list[str]],\n    data_type: Literal[\"media\", \"text\"] = \"media\",\n    contexts: list[str] | None = None,\n    media_contexts: list[str] | None = None,\n    explanations: list[str | None] | None = None,\n    dimensions: list[str] = [],\n) -&gt; RapidataValidationSet\n</code></pre> <p>Create a classification validation set.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the validation set. (will not be shown to the labeler)</p> required <code>instruction</code> <code>str</code> <p>The instruction by which the labeler will answer.</p> required <code>answer_options</code> <code>list[str]</code> <p>The options to choose from when answering.</p> required <code>datapoints</code> <code>list[str]</code> <p>The datapoints that will be used for validation.</p> required <code>truths</code> <code>list[list[str]]</code> <p>The truths for each datapoint. Outer list is for each datapoint, inner list is for each truth.</p> <p>example:     options: [\"yes\", \"no\", \"maybe\"]     datapoints: [\"datapoint1\", \"datapoint2\"]     truths: [[\"yes\"], [\"no\", \"maybe\"]] -&gt; first datapoint correct answer is \"yes\", second datapoint is \"no\" or \"maybe\"</p> required <code>data_type</code> <code>str</code> <p>The type of data. Defaults to \"media\" (any form of image, video or audio). Other option: \"text\".</p> <code>'media'</code> <code>contexts</code> <code>list[str]</code> <p>The contexts for each datapoint. Defaults to None.</p> <p>If provided has to be the same length as datapoints and will be shown in addition to the instruction and answer options. (Therefore will be different for each datapoint) Will be match up with the datapoints using the list index.</p> <code>None</code> <code>media_contexts</code> <code>list[str]</code> <p>The list of media contexts i.e. links to the images / videos for the comparison. Defaults to None.</p> <p>If provided has to be the same length as datapoints and will be shown in addition to the instruction. (Therefore will be different for each datapoint) Will be matched up with the datapoints using the list index.</p> <code>None</code> <code>explanations</code> <code>list[str | None]</code> <p>The explanations for each datapoint. Will be given to the annotators in case the answer is wrong. Defaults to None.</p> <code>None</code> <code>dimensions</code> <code>list[str]</code> <p>The dimensions to add to the validation set accross which users will be tracked. Defaults to [] which is the default dimension.</p> <code>[]</code> Example <p></p><pre><code>options: [\"yes\", \"no\", \"maybe\"]\ndatapoints: [\"datapoint1\", \"datapoint2\"]\ntruths: [[\"yes\"], [\"no\", \"maybe\"]]\n</code></pre> This would mean: first datapoint correct answer is \"yes\", second datapoint is \"no\" or \"maybe\"<p></p> Source code in <code>src/rapidata/rapidata_client/validation/validation_set_manager.py</code> <pre><code>def create_classification_set(\n    self,\n    name: str,\n    instruction: str,\n    answer_options: list[str],\n    datapoints: list[str],\n    truths: list[list[str]],\n    data_type: Literal[\"media\", \"text\"] = \"media\",\n    contexts: list[str] | None = None,\n    media_contexts: list[str] | None = None,\n    explanations: list[str | None] | None = None,\n    dimensions: list[str] = [],\n) -&gt; RapidataValidationSet:\n    \"\"\"Create a classification validation set.\n\n    Args:\n        name (str): The name of the validation set. (will not be shown to the labeler)\n        instruction (str): The instruction by which the labeler will answer.\n        answer_options (list[str]): The options to choose from when answering.\n        datapoints (list[str]): The datapoints that will be used for validation.\n        truths (list[list[str]]): The truths for each datapoint. Outer list is for each datapoint, inner list is for each truth.\\n\n            example:\n                options: [\"yes\", \"no\", \"maybe\"]\n                datapoints: [\"datapoint1\", \"datapoint2\"]\n                truths: [[\"yes\"], [\"no\", \"maybe\"]] -&gt; first datapoint correct answer is \"yes\", second datapoint is \"no\" or \"maybe\"\n        data_type (str, optional): The type of data. Defaults to \"media\" (any form of image, video or audio). Other option: \"text\".\n        contexts (list[str], optional): The contexts for each datapoint. Defaults to None.\\n\n            If provided has to be the same length as datapoints and will be shown in addition to the instruction and answer options. (Therefore will be different for each datapoint)\n            Will be match up with the datapoints using the list index.\n        media_contexts (list[str], optional): The list of media contexts i.e. links to the images / videos for the comparison. Defaults to None.\\n\n            If provided has to be the same length as datapoints and will be shown in addition to the instruction. (Therefore will be different for each datapoint)\n            Will be matched up with the datapoints using the list index.\n        explanations (list[str | None], optional): The explanations for each datapoint. Will be given to the annotators in case the answer is wrong. Defaults to None.\n        dimensions (list[str], optional): The dimensions to add to the validation set accross which users will be tracked. Defaults to [] which is the default dimension.\n\n    Example:\n        ```python\n        options: [\"yes\", \"no\", \"maybe\"]\n        datapoints: [\"datapoint1\", \"datapoint2\"]\n        truths: [[\"yes\"], [\"no\", \"maybe\"]]\n        ```\n        This would mean: first datapoint correct answer is \"yes\", second datapoint is \"no\" or \"maybe\"\n    \"\"\"\n    with tracer.start_as_current_span(\n        \"ValidationSetManager.create_classification_set\"\n    ):\n        if not datapoints:\n            raise ValueError(\"Datapoints cannot be empty\")\n\n        if len(datapoints) != len(truths):\n            raise ValueError(\"The number of datapoints and truths must be equal\")\n\n        if not all([isinstance(truth, (list, tuple)) for truth in truths]):\n            raise ValueError(\"Truths must be a list of lists or tuples\")\n\n        if contexts and len(contexts) != len(datapoints):\n            raise ValueError(\"The number of contexts and datapoints must be equal\")\n\n        if media_contexts and len(media_contexts) != len(datapoints):\n            raise ValueError(\n                \"The number of media contexts and datapoints must be equal\"\n            )\n\n        if explanations and len(explanations) != len(datapoints):\n            raise ValueError(\n                \"The number of explanations and datapoints must be equal, the index must align, but can be padded with None\"\n            )\n\n        logger.debug(\"Creating classification rapids\")\n        rapids: list[Rapid] = []\n        for i in range(len(datapoints)):\n            rapids.append(\n                self.rapid.classification_rapid(\n                    instruction=instruction,\n                    answer_options=answer_options,\n                    datapoint=datapoints[i],\n                    truths=truths[i],\n                    data_type=data_type,\n                    context=contexts[i] if contexts != None else None,\n                    media_context=(\n                        media_contexts[i] if media_contexts != None else None\n                    ),\n                    explanation=explanations[i] if explanations != None else None,\n                )\n            )\n\n        logger.debug(\"Submitting classification rapids\")\n        return self._submit(name=name, rapids=rapids, dimensions=dimensions)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/validation/validation_set_manager/#rapidata.rapidata_client.validation.validation_set_manager.ValidationSetManager.create_compare_set","title":"create_compare_set","text":"<pre><code>create_compare_set(\n    name: str,\n    instruction: str,\n    datapoints: list[list[str]],\n    truths: list[str],\n    data_type: Literal[\"media\", \"text\"] = \"media\",\n    contexts: list[str] | None = None,\n    media_contexts: list[str] | None = None,\n    explanation: list[str | None] | None = None,\n    dimensions: list[str] = [],\n) -&gt; RapidataValidationSet\n</code></pre> <p>Create a comparison validation set.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the validation set. (will not be shown to the labeler)</p> required <code>instruction</code> <code>str</code> <p>The instruction to compare against.</p> required <code>truths</code> <code>list[str]</code> <p>The truths for each comparison. List is for each comparison.</p> <p>example:     instruction: \"Which image has a cat?\"     datapoints = [[\"image1.jpg\", \"image2.jpg\"], [\"image3.jpg\", \"image4.jpg\"]]     truths: [\"image1.jpg\", \"image4.jpg\"] -&gt; first comparison image1.jpg has a cat, second comparison image4.jpg has a cat</p> required <code>datapoints</code> <code>list[list[str]]</code> <p>The compare datapoints to create the validation set with. Outer list is for each comparison, inner list the two images/texts that will be compared.</p> required <code>data_type</code> <code>str</code> <p>The type of data. Defaults to \"media\" (any form of image, video or audio). Other option: \"text\".</p> <code>'media'</code> <code>contexts</code> <code>list[str]</code> <p>The contexts for each datapoint. Defaults to None.</p> <p>If provided has to be the same length as datapoints and will be shown in addition to the instruction and truth. (Therefore will be different for each datapoint) Will be match up with the datapoints using the list index.</p> <code>None</code> <code>media_contexts</code> <code>list[str]</code> <p>The list of media contexts i.e. links to the images / videos for the comparison. Defaults to None.</p> <p>If provided has to be the same length as datapoints and will be shown in addition to the instruction. (Therefore will be different for each datapoint) Will be matched up with the datapoints using the list index.</p> <code>None</code> <code>explanation</code> <code>list[str | None]</code> <p>The explanations for each datapoint. Will be given to the annotators in case the answer is wrong. Defaults to None.</p> <code>None</code> <code>dimensions</code> <code>list[str]</code> <p>The dimensions to add to the validation set accross which users will be tracked. Defaults to [] which is the default dimension.</p> <code>[]</code> Example <p></p><pre><code>instruction: \"Which image has a cat?\"\ndatapoints = [[\"image1.jpg\", \"image2.jpg\"], [\"image3.jpg\", \"image4.jpg\"]]\ntruths: [\"image1.jpg\", \"image4.jpg\"]\n</code></pre> This would mean: first comparison image1.jpg has a cat, second comparison image4.jpg has a cat<p></p> Source code in <code>src/rapidata/rapidata_client/validation/validation_set_manager.py</code> <pre><code>def create_compare_set(\n    self,\n    name: str,\n    instruction: str,\n    datapoints: list[list[str]],\n    truths: list[str],\n    data_type: Literal[\"media\", \"text\"] = \"media\",\n    contexts: list[str] | None = None,\n    media_contexts: list[str] | None = None,\n    explanation: list[str | None] | None = None,\n    dimensions: list[str] = [],\n) -&gt; RapidataValidationSet:\n    \"\"\"Create a comparison validation set.\n\n    Args:\n        name (str): The name of the validation set. (will not be shown to the labeler)\n        instruction (str): The instruction to compare against.\n        truths (list[str]): The truths for each comparison. List is for each comparison.\\n\n            example:\n                instruction: \"Which image has a cat?\"\n                datapoints = [[\"image1.jpg\", \"image2.jpg\"], [\"image3.jpg\", \"image4.jpg\"]]\n                truths: [\"image1.jpg\", \"image4.jpg\"] -&gt; first comparison image1.jpg has a cat, second comparison image4.jpg has a cat\n        datapoints (list[list[str]]): The compare datapoints to create the validation set with.\n            Outer list is for each comparison, inner list the two images/texts that will be compared.\n        data_type (str, optional): The type of data. Defaults to \"media\" (any form of image, video or audio). Other option: \"text\".\n        contexts (list[str], optional): The contexts for each datapoint. Defaults to None.\\n\n            If provided has to be the same length as datapoints and will be shown in addition to the instruction and truth. (Therefore will be different for each datapoint)\n            Will be match up with the datapoints using the list index.\n        media_contexts (list[str], optional): The list of media contexts i.e. links to the images / videos for the comparison. Defaults to None.\\n\n            If provided has to be the same length as datapoints and will be shown in addition to the instruction. (Therefore will be different for each datapoint)\n            Will be matched up with the datapoints using the list index.\n        explanation (list[str | None], optional): The explanations for each datapoint. Will be given to the annotators in case the answer is wrong. Defaults to None.\n        dimensions (list[str], optional): The dimensions to add to the validation set accross which users will be tracked. Defaults to [] which is the default dimension.\n\n    Example:\n        ```python\n        instruction: \"Which image has a cat?\"\n        datapoints = [[\"image1.jpg\", \"image2.jpg\"], [\"image3.jpg\", \"image4.jpg\"]]\n        truths: [\"image1.jpg\", \"image4.jpg\"]\n        ```\n        This would mean: first comparison image1.jpg has a cat, second comparison image4.jpg has a cat\n    \"\"\"\n    with tracer.start_as_current_span(\"ValidationSetManager.create_compare_set\"):\n        if not datapoints:\n            raise ValueError(\"Datapoints cannot be empty\")\n\n        if len(datapoints) != len(truths):\n            raise ValueError(\"The number of datapoints and truths must be equal\")\n\n        if not all([isinstance(truth, str) for truth in truths]):\n            raise ValueError(\"Truths must be a list of strings\")\n\n        if contexts and len(contexts) != len(datapoints):\n            raise ValueError(\"The number of contexts and datapoints must be equal\")\n\n        if media_contexts and len(media_contexts) != len(datapoints):\n            raise ValueError(\n                \"The number of media contexts and datapoints must be equal\"\n            )\n\n        if explanation and len(explanation) != len(datapoints):\n            raise ValueError(\n                \"The number of explanations and datapoints must be equal, the index must align, but can be padded with None\"\n            )\n\n        logger.debug(\"Creating comparison rapids\")\n        rapids: list[Rapid] = []\n        for i in range(len(datapoints)):\n            rapids.append(\n                self.rapid.compare_rapid(\n                    instruction=instruction,\n                    truth=truths[i],\n                    datapoint=datapoints[i],\n                    data_type=data_type,\n                    context=contexts[i] if contexts != None else None,\n                    media_context=(\n                        media_contexts[i] if media_contexts != None else None\n                    ),\n                    explanation=explanation[i] if explanation != None else None,\n                )\n            )\n\n        logger.debug(\"Submitting comparison rapids\")\n        return self._submit(name=name, rapids=rapids, dimensions=dimensions)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/validation/validation_set_manager/#rapidata.rapidata_client.validation.validation_set_manager.ValidationSetManager.create_select_words_set","title":"create_select_words_set","text":"<pre><code>create_select_words_set(\n    name: str,\n    instruction: str,\n    truths: list[list[int]],\n    datapoints: list[str],\n    sentences: list[str],\n    required_precision: float = 1.0,\n    required_completeness: float = 1.0,\n    explanation: list[str | None] | None = None,\n    dimensions: list[str] = [],\n) -&gt; RapidataValidationSet\n</code></pre> <p>Create a select words validation set.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the validation set. (will not be shown to the labeler)</p> required <code>instruction</code> <code>str</code> <p>The instruction to show to the labeler.</p> required <code>truths</code> <code>list[list[int]]</code> <p>The truths for each datapoint. Outer list is for each datapoint, inner list is for each truth.</p> <p>example:     datapoints: [\"datapoint1\", \"datapoint2\"]     sentences: [\"this example 1\", \"this example with another text\"]     truths: [[0, 1], [2]] -&gt; first datapoint correct words are \"this\" and \"example\", second datapoint is \"with\"</p> required <code>datapoints</code> <code>list[str]</code> <p>The datapoints that will be used for validation.</p> required <code>sentences</code> <code>list[str]</code> <p>The sentences that will be used for validation. The sentece will be split up by spaces to be selected by the labeler. Must be the same length as datapoints.</p> required <code>required_precision</code> <code>float</code> <p>The required precision for the labeler to get the rapid correct (minimum ratio of the words selected that need to be correct). Defaults to 1.0 (no wrong word can be selected).</p> <code>1.0</code> <code>required_completeness</code> <code>float</code> <p>The required completeness for the labeler to get the rapid correct (miminum ratio of total correct words selected). Defaults to 1.0 (all correct words need to be selected).</p> <code>1.0</code> <code>explanation</code> <code>list[str | None]</code> <p>The explanations for each datapoint. Will be given to the annotators in case the answer is wrong. Defaults to None.</p> <code>None</code> <code>dimensions</code> <code>list[str]</code> <p>The dimensions to add to the validation set accross which users will be tracked. Defaults to [] which is the default dimension.</p> <code>[]</code> Example <p></p><pre><code>datapoints: [\"datapoint1\", \"datapoint2\"]\nsentences: [\"this example 1\", \"this example with another text\"]\ntruths: [[0, 1], [2]]\n</code></pre> This would mean: first datapoint the correct words are \"this\" and \"example\", second datapoint is \"with\"<p></p> Source code in <code>src/rapidata/rapidata_client/validation/validation_set_manager.py</code> <pre><code>def create_select_words_set(\n    self,\n    name: str,\n    instruction: str,\n    truths: list[list[int]],\n    datapoints: list[str],\n    sentences: list[str],\n    required_precision: float = 1.0,\n    required_completeness: float = 1.0,\n    explanation: list[str | None] | None = None,\n    dimensions: list[str] = [],\n) -&gt; RapidataValidationSet:\n    \"\"\"Create a select words validation set.\n\n    Args:\n        name (str): The name of the validation set. (will not be shown to the labeler)\n        instruction (str): The instruction to show to the labeler.\n        truths (list[list[int]]): The truths for each datapoint. Outer list is for each datapoint, inner list is for each truth.\\n\n            example:\n                datapoints: [\"datapoint1\", \"datapoint2\"]\n                sentences: [\"this example 1\", \"this example with another text\"]\n                truths: [[0, 1], [2]] -&gt; first datapoint correct words are \"this\" and \"example\", second datapoint is \"with\"\n        datapoints (list[str]): The datapoints that will be used for validation.\n        sentences (list[str]): The sentences that will be used for validation. The sentece will be split up by spaces to be selected by the labeler.\n            Must be the same length as datapoints.\n        required_precision (float, optional): The required precision for the labeler to get the rapid correct (minimum ratio of the words selected that need to be correct). Defaults to 1.0 (no wrong word can be selected).\n        required_completeness (float, optional): The required completeness for the labeler to get the rapid correct (miminum ratio of total correct words selected). Defaults to 1.0 (all correct words need to be selected).\n        explanation (list[str | None], optional): The explanations for each datapoint. Will be given to the annotators in case the answer is wrong. Defaults to None.\n        dimensions (list[str], optional): The dimensions to add to the validation set accross which users will be tracked. Defaults to [] which is the default dimension.\n\n    Example:\n        ```python\n        datapoints: [\"datapoint1\", \"datapoint2\"]\n        sentences: [\"this example 1\", \"this example with another text\"]\n        truths: [[0, 1], [2]]\n        ```\n        This would mean: first datapoint the correct words are \"this\" and \"example\", second datapoint is \"with\"\n    \"\"\"\n    with tracer.start_as_current_span(\n        \"ValidationSetManager.create_select_words_set\"\n    ):\n        if not datapoints:\n            raise ValueError(\"Datapoints cannot be empty\")\n\n        if not all([isinstance(truth, (list, tuple)) for truth in truths]):\n            raise ValueError(\"Truths must be a list of lists or tuples\")\n\n        if len(datapoints) != len(truths) or len(datapoints) != len(sentences):\n            raise ValueError(\n                \"The number of datapoints, truths, and sentences must be equal\"\n            )\n\n        if explanation and len(explanation) != len(datapoints):\n            raise ValueError(\n                \"The number of explanations and datapoints must be equal, the index must align, but can be padded with None\"\n            )\n\n        logger.debug(\"Creating select words rapids\")\n        rapids: list[Rapid] = []\n        for i in range(len(datapoints)):\n            rapids.append(\n                self.rapid.select_words_rapid(\n                    instruction=instruction,\n                    truths=truths[i],\n                    datapoint=datapoints[i],\n                    sentence=sentences[i],\n                    required_precision=required_precision,\n                    required_completeness=required_completeness,\n                    explanation=explanation[i] if explanation != None else None,\n                )\n            )\n\n        logger.debug(\"Submitting select words rapids\")\n        return self._submit(name=name, rapids=rapids, dimensions=dimensions)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/validation/validation_set_manager/#rapidata.rapidata_client.validation.validation_set_manager.ValidationSetManager.create_locate_set","title":"create_locate_set","text":"<pre><code>create_locate_set(\n    name: str,\n    instruction: str,\n    truths: list[list[Box]],\n    datapoints: list[str],\n    contexts: list[str] | None = None,\n    media_contexts: list[str] | None = None,\n    explanation: list[str | None] | None = None,\n    dimensions: list[str] = [],\n) -&gt; RapidataValidationSet\n</code></pre> <p>Create a locate validation set.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the validation set. (will not be shown to the labeler)</p> required <code>instruction</code> <code>str</code> <p>The instruction to show to the labeler.</p> required <code>truths</code> <code>list[list[Box]]</code> <p>The truths for each datapoint. Outer list is for each datapoint, inner list is for each truth.</p> <p>example:     datapoints: [\"datapoint1\", \"datapoint2\"]     truths: [[Box(0, 0, 100, 100)], [Box(50, 50, 150, 150)]] -&gt; first datapoint the object is in the top left corner, second datapoint the object is in the center</p> required <code>datapoints</code> <code>list[str]</code> <p>The datapoints that will be used for validation.</p> required <code>contexts</code> <code>list[str]</code> <p>The contexts for each datapoint. Defaults to None.</p> <code>None</code> <code>media_contexts</code> <code>list[str]</code> <p>The list of media contexts i.e. links to the images / videos for the comparison. Defaults to None.</p> <p>If provided has to be the same length as datapoints and will be shown in addition to the instruction. (Therefore will be different for each datapoint) Will be matched up with the datapoints using the list index.</p> <code>None</code> <code>explanation</code> <code>list[str | None]</code> <p>The explanations for each datapoint. Will be given to the annotators in case the answer is wrong. Defaults to None.</p> <code>None</code> <code>dimensions</code> <code>list[str]</code> <p>The dimensions to add to the validation set accross which users will be tracked. Defaults to [] which is the default dimension.</p> <code>[]</code> Example <p></p><pre><code>datapoints: [\"datapoint1\", \"datapoint2\"]\ntruths: [[Box(0, 0, 100, 100)], [Box(50, 50, 150, 150)]]\n</code></pre> This would mean: first datapoint the object is in the top left corner, second datapoint the object is in the center<p></p> Source code in <code>src/rapidata/rapidata_client/validation/validation_set_manager.py</code> <pre><code>def create_locate_set(\n    self,\n    name: str,\n    instruction: str,\n    truths: list[list[Box]],\n    datapoints: list[str],\n    contexts: list[str] | None = None,\n    media_contexts: list[str] | None = None,\n    explanation: list[str | None] | None = None,\n    dimensions: list[str] = [],\n) -&gt; RapidataValidationSet:\n    \"\"\"Create a locate validation set.\n\n    Args:\n        name (str): The name of the validation set. (will not be shown to the labeler)\n        instruction (str): The instruction to show to the labeler.\n        truths (list[list[Box]]): The truths for each datapoint. Outer list is for each datapoint, inner list is for each truth.\\n\n            example:\n                datapoints: [\"datapoint1\", \"datapoint2\"]\n                truths: [[Box(0, 0, 100, 100)], [Box(50, 50, 150, 150)]] -&gt; first datapoint the object is in the top left corner, second datapoint the object is in the center\n        datapoints (list[str]): The datapoints that will be used for validation.\n        contexts (list[str], optional): The contexts for each datapoint. Defaults to None.\n        media_contexts (list[str], optional): The list of media contexts i.e. links to the images / videos for the comparison. Defaults to None.\\n\n            If provided has to be the same length as datapoints and will be shown in addition to the instruction. (Therefore will be different for each datapoint)\n            Will be matched up with the datapoints using the list index.\n        explanation (list[str | None], optional): The explanations for each datapoint. Will be given to the annotators in case the answer is wrong. Defaults to None.\n        dimensions (list[str], optional): The dimensions to add to the validation set accross which users will be tracked. Defaults to [] which is the default dimension.\n\n    Example:\n        ```python\n        datapoints: [\"datapoint1\", \"datapoint2\"]\n        truths: [[Box(0, 0, 100, 100)], [Box(50, 50, 150, 150)]]\n        ```\n        This would mean: first datapoint the object is in the top left corner, second datapoint the object is in the center\n    \"\"\"\n    with tracer.start_as_current_span(\"ValidationSetManager.create_locate_set\"):\n        if not datapoints:\n            raise ValueError(\"Datapoints cannot be empty\")\n\n        if len(datapoints) != len(truths):\n            raise ValueError(\"The number of datapoints and truths must be equal\")\n\n        if not all([isinstance(truth, (list, tuple)) for truth in truths]):\n            raise ValueError(\"Truths must be a list of lists or tuples\")\n\n        if contexts and len(contexts) != len(datapoints):\n            raise ValueError(\"The number of contexts and datapoints must be equal\")\n\n        if media_contexts and len(media_contexts) != len(datapoints):\n            raise ValueError(\n                \"The number of media contexts and datapoints must be equal\"\n            )\n\n        if explanation and len(explanation) != len(datapoints):\n            raise ValueError(\n                \"The number of explanations and datapoints must be equal, the index must align, but can be padded with None\"\n            )\n\n        logger.debug(\"Creating locate rapids\")\n        rapids: list[Rapid] = []\n        for i in range(len(datapoints)):\n            rapids.append(\n                self.rapid.locate_rapid(\n                    instruction=instruction,\n                    truths=truths[i],\n                    datapoint=datapoints[i],\n                    context=contexts[i] if contexts != None else None,\n                    media_context=(\n                        media_contexts[i] if media_contexts != None else None\n                    ),\n                    explanation=explanation[i] if explanation != None else None,\n                )\n            )\n\n        logger.debug(\"Submitting locate rapids\")\n        return self._submit(name=name, rapids=rapids, dimensions=dimensions)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/validation/validation_set_manager/#rapidata.rapidata_client.validation.validation_set_manager.ValidationSetManager.create_draw_set","title":"create_draw_set","text":"<pre><code>create_draw_set(\n    name: str,\n    instruction: str,\n    truths: list[list[Box]],\n    datapoints: list[str],\n    contexts: list[str] | None = None,\n    media_contexts: list[str] | None = None,\n    explanation: list[str | None] | None = None,\n    dimensions: list[str] = [],\n) -&gt; RapidataValidationSet\n</code></pre> <p>Create a draw validation set.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the validation set. (will not be shown to the labeler)</p> required <code>instruction</code> <code>str</code> <p>The instruction to show to the labeler.</p> required <code>truths</code> <code>list[list[Box]]</code> <p>The truths for each datapoint. Outer list is for each datapoint, inner list is for each truth.</p> <p>example:     datapoints: [\"datapoint1\", \"datapoint2\"]     truths: [[Box(0, 0, 100, 100)], [Box(50, 50, 150, 150)]] -&gt; first datapoint the object is in the top left corner, second datapoint the object is in the center</p> required <code>datapoints</code> <code>list[str]</code> <p>The datapoints that will be used for validation.</p> required <code>contexts</code> <code>list[str]</code> <p>The contexts for each datapoint. Defaults to None.</p> <code>None</code> <code>media_contexts</code> <code>list[str]</code> <p>The list of media contexts i.e. links to the images / videos for the comparison. Defaults to None.</p> <p>If provided has to be the same length as datapoints and will be shown in addition to the instruction. (Therefore will be different for each datapoint) Will be matched up with the datapoints using the list index.</p> <code>None</code> <code>explanation</code> <code>list[str | None]</code> <p>The explanations for each datapoint. Will be given to the annotators in case the answer is wrong. Defaults to None.</p> <code>None</code> <code>dimensions</code> <code>list[str]</code> <p>The dimensions to add to the validation set accross which users will be tracked. Defaults to [] which is the default dimension.</p> <code>[]</code> Example <p></p><pre><code>datapoints: [\"datapoint1\", \"datapoint2\"]\ntruths: [[Box(0, 0, 100, 100)], [Box(50, 50, 150, 150)]]\n</code></pre> This would mean: first datapoint the object is in the top left corner, second datapoint the object is in the center<p></p> Source code in <code>src/rapidata/rapidata_client/validation/validation_set_manager.py</code> <pre><code>def create_draw_set(\n    self,\n    name: str,\n    instruction: str,\n    truths: list[list[Box]],\n    datapoints: list[str],\n    contexts: list[str] | None = None,\n    media_contexts: list[str] | None = None,\n    explanation: list[str | None] | None = None,\n    dimensions: list[str] = [],\n) -&gt; RapidataValidationSet:\n    \"\"\"Create a draw validation set.\n\n    Args:\n        name (str): The name of the validation set. (will not be shown to the labeler)\n        instruction (str): The instruction to show to the labeler.\n        truths (list[list[Box]]): The truths for each datapoint. Outer list is for each datapoint, inner list is for each truth.\\n\n            example:\n                datapoints: [\"datapoint1\", \"datapoint2\"]\n                truths: [[Box(0, 0, 100, 100)], [Box(50, 50, 150, 150)]] -&gt; first datapoint the object is in the top left corner, second datapoint the object is in the center\n        datapoints (list[str]): The datapoints that will be used for validation.\n        contexts (list[str], optional): The contexts for each datapoint. Defaults to None.\n        media_contexts (list[str], optional): The list of media contexts i.e. links to the images / videos for the comparison. Defaults to None.\\n\n            If provided has to be the same length as datapoints and will be shown in addition to the instruction. (Therefore will be different for each datapoint)\n            Will be matched up with the datapoints using the list index.\n        explanation (list[str | None], optional): The explanations for each datapoint. Will be given to the annotators in case the answer is wrong. Defaults to None.\n        dimensions (list[str], optional): The dimensions to add to the validation set accross which users will be tracked. Defaults to [] which is the default dimension.\n\n    Example:\n        ```python\n        datapoints: [\"datapoint1\", \"datapoint2\"]\n        truths: [[Box(0, 0, 100, 100)], [Box(50, 50, 150, 150)]]\n        ```\n        This would mean: first datapoint the object is in the top left corner, second datapoint the object is in the center\n    \"\"\"\n    with tracer.start_as_current_span(\"ValidationSetManager.create_draw_set\"):\n        if not datapoints:\n            raise ValueError(\"Datapoints cannot be empty\")\n\n        if len(datapoints) != len(truths):\n            raise ValueError(\"The number of datapoints and truths must be equal\")\n\n        if not all([isinstance(truth, (list, tuple)) for truth in truths]):\n            raise ValueError(\"Truths must be a list of lists or tuples\")\n\n        if contexts and len(contexts) != len(datapoints):\n            raise ValueError(\"The number of contexts and datapoints must be equal\")\n\n        if media_contexts and len(media_contexts) != len(datapoints):\n            raise ValueError(\n                \"The number of media contexts and datapoints must be equal\"\n            )\n\n        if explanation and len(explanation) != len(datapoints):\n            raise ValueError(\n                \"The number of explanations and datapoints must be equal, the index must align, but can be padded with None\"\n            )\n\n        logger.debug(\"Creating draw rapids\")\n        rapids: list[Rapid] = []\n        for i in range(len(datapoints)):\n            rapids.append(\n                self.rapid.draw_rapid(\n                    instruction=instruction,\n                    truths=truths[i],\n                    datapoint=datapoints[i],\n                    context=contexts[i] if contexts != None else None,\n                    media_context=(\n                        media_contexts[i] if media_contexts != None else None\n                    ),\n                    explanation=explanation[i] if explanation != None else None,\n                )\n            )\n\n        logger.debug(\"Submitting draw rapids\")\n        return self._submit(name=name, rapids=rapids, dimensions=dimensions)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/validation/validation_set_manager/#rapidata.rapidata_client.validation.validation_set_manager.ValidationSetManager.create_timestamp_set","title":"create_timestamp_set","text":"<pre><code>create_timestamp_set(\n    name: str,\n    instruction: str,\n    truths: list[list[tuple[int, int]]],\n    datapoints: list[str],\n    contexts: list[str] | None = None,\n    media_contexts: list[str] | None = None,\n    explanation: list[str | None] | None = None,\n    dimensions: list[str] = [],\n) -&gt; RapidataValidationSet\n</code></pre> <p>Create a timestamp validation set.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the validation set. (will not be shown to the labeler)</p> required <code>instruction</code> <code>str</code> <p>The instruction to show to the labeler.</p> required <code>truths</code> <code>list[list[tuple[int, int]]]</code> <p>The truths for each datapoint defined as start and endpoint based on miliseconds. Outer list is for each datapoint, inner list is for each truth.</p> <p>example:     datapoints: [\"datapoint1\", \"datapoint2\"]     truths: [[(0, 10)], [(20, 30)]] -&gt; first datapoint the correct interval is from 0 to 10, second datapoint the correct interval is from 20 to 30</p> required <code>datapoints</code> <code>list[str]</code> <p>The datapoints that will be used for validation.</p> required <code>contexts</code> <code>list[str]</code> <p>The contexts for each datapoint. Defaults to None.</p> <code>None</code> <code>media_contexts</code> <code>list[str]</code> <p>The list of media contexts i.e. links to the images / videos for the comparison. Defaults to None.</p> <p>If provided has to be the same length as datapoints and will be shown in addition to the instruction. (Therefore will be different for each datapoint) Will be matched up with the datapoints using the list index.</p> <code>None</code> <code>explanation</code> <code>list[str | None]</code> <p>The explanations for each datapoint. Will be given to the annotators in case the answer is wrong. Defaults to None.</p> <code>None</code> <code>dimensions</code> <code>list[str]</code> <p>The dimensions to add to the validation set accross which users will be tracked. Defaults to [] which is the default dimension.</p> <code>[]</code> Example <p></p><pre><code>datapoints: [\"datapoint1\", \"datapoint2\"]\ntruths: [[(0, 10)], [(20, 30)]]\n</code></pre> This would mean: first datapoint the correct interval is from 0 to 10, second datapoint the correct interval is from 20 to 30<p></p> Source code in <code>src/rapidata/rapidata_client/validation/validation_set_manager.py</code> <pre><code>def create_timestamp_set(\n    self,\n    name: str,\n    instruction: str,\n    truths: list[list[tuple[int, int]]],\n    datapoints: list[str],\n    contexts: list[str] | None = None,\n    media_contexts: list[str] | None = None,\n    explanation: list[str | None] | None = None,\n    dimensions: list[str] = [],\n) -&gt; RapidataValidationSet:\n    \"\"\"Create a timestamp validation set.\n\n    Args:\n        name (str): The name of the validation set. (will not be shown to the labeler)\n        instruction (str): The instruction to show to the labeler.\n        truths (list[list[tuple[int, int]]]): The truths for each datapoint defined as start and endpoint based on miliseconds.\n            Outer list is for each datapoint, inner list is for each truth.\\n\n            example:\n                datapoints: [\"datapoint1\", \"datapoint2\"]\n                truths: [[(0, 10)], [(20, 30)]] -&gt; first datapoint the correct interval is from 0 to 10, second datapoint the correct interval is from 20 to 30\n        datapoints (list[str]): The datapoints that will be used for validation.\n        contexts (list[str], optional): The contexts for each datapoint. Defaults to None.\n        media_contexts (list[str], optional): The list of media contexts i.e. links to the images / videos for the comparison. Defaults to None.\\n\n            If provided has to be the same length as datapoints and will be shown in addition to the instruction. (Therefore will be different for each datapoint)\n            Will be matched up with the datapoints using the list index.\n        explanation (list[str | None], optional): The explanations for each datapoint. Will be given to the annotators in case the answer is wrong. Defaults to None.\n        dimensions (list[str], optional): The dimensions to add to the validation set accross which users will be tracked. Defaults to [] which is the default dimension.\n\n    Example:\n        ```python\n        datapoints: [\"datapoint1\", \"datapoint2\"]\n        truths: [[(0, 10)], [(20, 30)]]\n        ```\n        This would mean: first datapoint the correct interval is from 0 to 10, second datapoint the correct interval is from 20 to 30\n    \"\"\"\n    with tracer.start_as_current_span(\"ValidationSetManager.create_timestamp_set\"):\n        if not datapoints:\n            raise ValueError(\"Datapoints cannot be empty\")\n\n        if len(datapoints) != len(truths):\n            raise ValueError(\"The number of datapoints and truths must be equal\")\n\n        if not all([isinstance(truth, (list, tuple)) for truth in truths]):\n            raise ValueError(\"Truths must be a list of lists or tuples\")\n\n        if contexts and len(contexts) != len(datapoints):\n            raise ValueError(\"The number of contexts and datapoints must be equal\")\n\n        if media_contexts and len(media_contexts) != len(datapoints):\n            raise ValueError(\n                \"The number of media contexts and datapoints must be equal\"\n            )\n\n        if explanation and len(explanation) != len(datapoints):\n            raise ValueError(\n                \"The number of explanations and datapoints must be equal, the index must align, but can be padded with None\"\n            )\n\n        logger.debug(\"Creating timestamp rapids\")\n        rapids: list[Rapid] = []\n        for i in range(len(datapoints)):\n            rapids.append(\n                self.rapid.timestamp_rapid(\n                    instruction=instruction,\n                    truths=truths[i],\n                    datapoint=datapoints[i],\n                    context=contexts[i] if contexts != None else None,\n                    media_context=(\n                        media_contexts[i] if media_contexts != None else None\n                    ),\n                    explanation=explanation[i] if explanation != None else None,\n                )\n            )\n\n        logger.debug(\"Submitting timestamp rapids\")\n        return self._submit(name=name, rapids=rapids, dimensions=dimensions)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/validation/validation_set_manager/#rapidata.rapidata_client.validation.validation_set_manager.ValidationSetManager.create_mixed_set","title":"create_mixed_set","text":"<pre><code>create_mixed_set(\n    name: str,\n    rapids: list[Rapid],\n    dimensions: list[str] = [],\n) -&gt; RapidataValidationSet\n</code></pre> <p>Create a validation set with a list of rapids.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the validation set. (will not be shown to the labeler)</p> required <code>rapids</code> <code>list[Rapid]</code> <p>The list of rapids to add to the validation set.</p> required <code>dimensions</code> <code>list[str]</code> <p>The dimensions to add to the validation set accross which users will be tracked. Defaults to [] which is the default dimension.</p> <code>[]</code> Source code in <code>src/rapidata/rapidata_client/validation/validation_set_manager.py</code> <pre><code>def create_mixed_set(\n    self,\n    name: str,\n    rapids: list[Rapid],\n    dimensions: list[str] = [],\n) -&gt; RapidataValidationSet:\n    \"\"\"Create a validation set with a list of rapids.\n\n    Args:\n        name (str): The name of the validation set. (will not be shown to the labeler)\n        rapids (list[Rapid]): The list of rapids to add to the validation set.\n        dimensions (list[str], optional): The dimensions to add to the validation set accross which users will be tracked. Defaults to [] which is the default dimension.\n    \"\"\"\n    with tracer.start_as_current_span(\"ValidationSetManager.create_mixed_set\"):\n        if not rapids:\n            raise ValueError(\"Rapids cannot be empty\")\n\n        return self._submit(name=name, rapids=rapids, dimensions=dimensions)\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/validation/validation_set_manager/#rapidata.rapidata_client.validation.validation_set_manager.ValidationSetManager.get_validation_set_by_id","title":"get_validation_set_by_id","text":"<pre><code>get_validation_set_by_id(\n    validation_set_id: str,\n) -&gt; RapidataValidationSet\n</code></pre> <p>Get a validation set by ID.</p> <p>Parameters:</p> Name Type Description Default <code>validation_set_id</code> <code>str</code> <p>The ID of the validation set.</p> required <p>Returns:</p> Name Type Description <code>RapidataValidationSet</code> <code>RapidataValidationSet</code> <p>The ValidationSet instance.</p> Source code in <code>src/rapidata/rapidata_client/validation/validation_set_manager.py</code> <pre><code>def get_validation_set_by_id(self, validation_set_id: str) -&gt; RapidataValidationSet:\n    \"\"\"Get a validation set by ID.\n\n    Args:\n        validation_set_id (str): The ID of the validation set.\n\n    Returns:\n        RapidataValidationSet: The ValidationSet instance.\n    \"\"\"\n\n    with tracer.start_as_current_span(\n        \"ValidationSetManager.get_validation_set_by_id\"\n    ):\n        logger.debug(\"Getting validation set by ID: %s\", validation_set_id)\n        validation_set = self._openapi_service.validation_api.validation_set_validation_set_id_get(\n            validation_set_id=validation_set_id\n        )\n\n        return RapidataValidationSet(\n            validation_set_id,\n            str(validation_set.name),\n            validation_set.dimensions,\n            self._openapi_service,\n        )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/validation/validation_set_manager/#rapidata.rapidata_client.validation.validation_set_manager.ValidationSetManager.find_validation_sets","title":"find_validation_sets","text":"<pre><code>find_validation_sets(\n    name: str = \"\", amount: int = 10\n) -&gt; list[RapidataValidationSet]\n</code></pre> <p>Find validation sets by name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name to search for. Defaults to \"\" to match with any set.</p> <code>''</code> <code>amount</code> <code>int</code> <p>The amount of validation sets to return. Defaults to 10.</p> <code>10</code> <p>Returns:</p> Type Description <code>list[RapidataValidationSet]</code> <p>list[RapidataValidationSet]: The list of validation sets.</p> Source code in <code>src/rapidata/rapidata_client/validation/validation_set_manager.py</code> <pre><code>def find_validation_sets(\n    self, name: str = \"\", amount: int = 10\n) -&gt; list[RapidataValidationSet]:\n    \"\"\"Find validation sets by name.\n\n    Args:\n        name (str, optional): The name to search for. Defaults to \"\" to match with any set.\n        amount (int, optional): The amount of validation sets to return. Defaults to 10.\n\n    Returns:\n        list[RapidataValidationSet]: The list of validation sets.\n    \"\"\"\n    with tracer.start_as_current_span(\"ValidationSetManager.find_validation_sets\"):\n        logger.debug(\n            \"Finding validation sets with name: %s and amount: %s\", name, amount\n        )\n\n        validation_page_result = (\n            self._openapi_service.validation_api.validation_sets_get(\n                QueryModel(\n                    page=PageInfo(index=1, size=amount),\n                    filter=RootFilter(\n                        filters=[\n                            Filter(\n                                field=\"Name\",\n                                operator=FilterOperator.CONTAINS,\n                                value=name,\n                            )\n                        ]\n                    ),\n                    sortCriteria=[\n                        SortCriterion(\n                            direction=SortDirection.DESC, propertyName=\"CreatedAt\"\n                        )\n                    ],\n                )\n            )\n        )\n\n        logger.debug(\"Validation sets found: %s\", validation_page_result.items)\n\n        validation_sets = [\n            self.get_validation_set_by_id(str(validation_set.id))\n            for validation_set in validation_page_result.items\n        ]\n        return validation_sets\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/validation/rapids/box/","title":"Box","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/validation/rapids/box/#rapidata.rapidata_client.validation.rapids.box.Box","title":"Box","text":"<p>               Bases: <code>BaseModel</code></p> <p>Used in the Locate and Draw Validation sets. All coordinates are in ratio of the image size (0.0 to 1.0).</p> <p>Parameters:</p> Name Type Description Default <code>x_min</code> <code>float</code> <p>The minimum x value of the box in ratio of the image size.</p> required <code>y_min</code> <code>float</code> <p>The minimum y value of the box in ratio of the image size.</p> required <code>x_max</code> <code>float</code> <p>The maximum x value of the box in ratio of the image size.</p> required <code>y_max</code> <code>float</code> <p>The maximum y value of the box in ratio of the image size.</p> required","boost":0.2},{"location":"reference/rapidata/rapidata_client/validation/rapids/rapids/","title":"Rapids","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/validation/rapids/rapids_manager/","title":"Rapids manager","text":"","boost":0.2},{"location":"reference/rapidata/rapidata_client/validation/rapids/rapids_manager/#rapidata.rapidata_client.validation.rapids.rapids_manager.RapidsManager","title":"RapidsManager","text":"<pre><code>RapidsManager(openapi_service: OpenAPIService)\n</code></pre> <p>Can be used to build different types of rapids. That can then be added to Validation sets</p> Source code in <code>src/rapidata/rapidata_client/validation/rapids/rapids_manager.py</code> <pre><code>def __init__(self, openapi_service: OpenAPIService):\n    self._openapi_service = openapi_service\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/validation/rapids/rapids_manager/#rapidata.rapidata_client.validation.rapids.rapids_manager.RapidsManager.classification_rapid","title":"classification_rapid","text":"<pre><code>classification_rapid(\n    instruction: str,\n    answer_options: list[str],\n    datapoint: str,\n    truths: list[str],\n    data_type: Literal[\"media\", \"text\"] = \"media\",\n    context: str | None = None,\n    media_context: str | None = None,\n    explanation: str | None = None,\n) -&gt; Rapid\n</code></pre> <p>Build a classification rapid</p> <p>Parameters:</p> Name Type Description Default <code>instruction</code> <code>str</code> <p>The instruction/question to be shown to the labeler.</p> required <code>answer_options</code> <code>list[str]</code> <p>The options that the labeler can choose from to answer the question.</p> required <code>datapoint</code> <code>str</code> <p>The datapoint that the labeler will be labeling.</p> required <code>truths</code> <code>list[str]</code> <p>The correct answers to the question.</p> required <code>data_type</code> <code>str</code> <p>The type of the datapoint. Defaults to \"media\" (any form of image, video or audio).</p> <code>'media'</code> <code>context</code> <code>str</code> <p>The context is text that will be shown in addition to the instruction. Defaults to None.</p> <code>None</code> <code>media_context</code> <code>str</code> <p>The media context is a link to an image / video that will be shown in addition to the instruction (can be combined with context). Defaults to None.</p> <code>None</code> <code>explanation</code> <code>str</code> <p>The explanation that will be shown to the labeler if the answer is wrong. Defaults to None.</p> <code>None</code> Source code in <code>src/rapidata/rapidata_client/validation/rapids/rapids_manager.py</code> <pre><code>def classification_rapid(\n    self,\n    instruction: str,\n    answer_options: list[str],\n    datapoint: str,\n    truths: list[str],\n    data_type: Literal[\"media\", \"text\"] = \"media\",\n    context: str | None = None,\n    media_context: str | None = None,\n    explanation: str | None = None,\n) -&gt; Rapid:\n    \"\"\"Build a classification rapid\n\n    Args:\n        instruction (str): The instruction/question to be shown to the labeler.\n        answer_options (list[str]): The options that the labeler can choose from to answer the question.\n        datapoint (str): The datapoint that the labeler will be labeling.\n        truths (list[str]): The correct answers to the question.\n        data_type (str, optional): The type of the datapoint. Defaults to \"media\" (any form of image, video or audio).\n        context (str, optional): The context is text that will be shown in addition to the instruction. Defaults to None.\n        media_context (str, optional): The media context is a link to an image / video that will be shown in addition to the instruction (can be combined with context). Defaults to None.\n        explanation (str, optional): The explanation that will be shown to the labeler if the answer is wrong. Defaults to None.\n    \"\"\"\n    from rapidata.api_client.models.i_rapid_payload import IRapidPayload\n    from rapidata.api_client.models.i_rapid_payload_classify_payload import (\n        IRapidPayloadClassifyPayload,\n    )\n    from rapidata.api_client.models.classify_payload_category import (\n        ClassifyPayloadCategory,\n    )\n    from rapidata.api_client.models.i_validation_truth_model import (\n        IValidationTruthModel,\n    )\n    from rapidata.api_client.models.i_validation_truth_model_attach_category_truth_model import (\n        IValidationTruthModelAttachCategoryTruthModel,\n    )\n    from rapidata.rapidata_client.validation.rapids.rapids import Rapid\n\n    if not isinstance(truths, list):\n        raise ValueError(\"Truths must be a list of strings\")\n\n    if not all(truth in answer_options for truth in truths):\n        raise ValueError(\"Truths must be part of the answer options\")\n\n    payload = IRapidPayload(\n        actual_instance=IRapidPayloadClassifyPayload(\n            _t=\"ClassifyPayload\",\n            categories=[\n                ClassifyPayloadCategory(label=option, value=option)\n                for option in answer_options\n            ],\n            title=instruction,\n        )\n    )\n    model_truth = IValidationTruthModel(\n        actual_instance=IValidationTruthModelAttachCategoryTruthModel(\n            correctCategories=truths, _t=\"AttachCategoryTruth\"\n        )\n    )\n\n    return Rapid(\n        asset=datapoint,\n        data_type=data_type,\n        context=context,\n        media_context=media_context,\n        explanation=explanation,\n        payload=payload,\n        truth=model_truth,\n        random_correct_probability=len(truths) / len(answer_options),\n    )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/validation/rapids/rapids_manager/#rapidata.rapidata_client.validation.rapids.rapids_manager.RapidsManager.compare_rapid","title":"compare_rapid","text":"<pre><code>compare_rapid(\n    instruction: str,\n    truth: str,\n    datapoint: list[str],\n    data_type: Literal[\"media\", \"text\"] = \"media\",\n    context: str | None = None,\n    media_context: str | None = None,\n    explanation: str | None = None,\n) -&gt; Rapid\n</code></pre> <p>Build a compare rapid</p> <p>Parameters:</p> Name Type Description Default <code>instruction</code> <code>str</code> <p>The instruction that the labeler will be comparing the assets on.</p> required <code>truth</code> <code>str</code> <p>The correct answer to the comparison. (has to be one of the assets)</p> required <code>datapoint</code> <code>list[str]</code> <p>The two assets that the labeler will be comparing.</p> required <code>data_type</code> <code>str</code> <p>The type of the datapoint. Defaults to \"media\" (any form of image, video or audio).</p> <code>'media'</code> <code>context</code> <code>str</code> <p>The context is text that will be shown in addition to the instruction. Defaults to None.</p> <code>None</code> <code>media_context</code> <code>str</code> <p>The media context is a link to an image / video that will be shown in addition to the instruction (can be combined with context). Defaults to None.</p> <code>None</code> <code>explanation</code> <code>str</code> <p>The explanation that will be shown to the labeler if the answer is wrong. Defaults to None.</p> <code>None</code> Source code in <code>src/rapidata/rapidata_client/validation/rapids/rapids_manager.py</code> <pre><code>def compare_rapid(\n    self,\n    instruction: str,\n    truth: str,\n    datapoint: list[str],\n    data_type: Literal[\"media\", \"text\"] = \"media\",\n    context: str | None = None,\n    media_context: str | None = None,\n    explanation: str | None = None,\n) -&gt; Rapid:\n    \"\"\"Build a compare rapid\n\n    Args:\n        instruction (str): The instruction that the labeler will be comparing the assets on.\n        truth (str): The correct answer to the comparison. (has to be one of the assets)\n        datapoint (list[str]): The two assets that the labeler will be comparing.\n        data_type (str, optional): The type of the datapoint. Defaults to \"media\" (any form of image, video or audio).\n        context (str, optional): The context is text that will be shown in addition to the instruction. Defaults to None.\n        media_context (str, optional): The media context is a link to an image / video that will be shown in addition to the instruction (can be combined with context). Defaults to None.\n        explanation (str, optional): The explanation that will be shown to the labeler if the answer is wrong. Defaults to None.\n    \"\"\"\n    from rapidata.api_client.models.i_rapid_payload import IRapidPayload\n    from rapidata.api_client.models.i_rapid_payload_compare_payload import (\n        IRapidPayloadComparePayload,\n    )\n    from rapidata.api_client.models.i_validation_truth_model import (\n        IValidationTruthModel,\n    )\n    from rapidata.api_client.models.i_validation_truth_model_compare_truth_model import (\n        IValidationTruthModelCompareTruthModel,\n    )\n    from rapidata.rapidata_client.validation.rapids.rapids import Rapid\n\n    payload = IRapidPayload(\n        actual_instance=IRapidPayloadComparePayload(\n            _t=\"ComparePayload\", criteria=instruction\n        )\n    )\n    truth_basename = os.path.basename(truth)\n    model_truth = IValidationTruthModel(\n        actual_instance=IValidationTruthModelCompareTruthModel(\n            _t=\"CompareTruth\", winnerId=truth_basename\n        )\n    )\n\n    if len(datapoint) != 2:\n        raise ValueError(\"Compare rapid requires exactly two media paths\")\n\n    return Rapid(\n        asset=datapoint,\n        data_type=data_type,\n        truth=model_truth,\n        context=context,\n        media_context=media_context,\n        payload=payload,\n        explanation=explanation,\n        random_correct_probability=0.5,\n    )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/validation/rapids/rapids_manager/#rapidata.rapidata_client.validation.rapids.rapids_manager.RapidsManager.select_words_rapid","title":"select_words_rapid","text":"<pre><code>select_words_rapid(\n    instruction: str,\n    truths: list[int],\n    datapoint: str,\n    sentence: str,\n    required_precision: float = 1,\n    required_completeness: float = 1,\n    explanation: str | None = None,\n) -&gt; Rapid\n</code></pre> <p>Build a select words rapid</p> <p>Parameters:</p> Name Type Description Default <code>instruction</code> <code>str</code> <p>The instruction for the labeler.</p> required <code>truths</code> <code>list[int]</code> <p>The indices of the words that are the correct answers.</p> required <code>datapoint</code> <code>str</code> <p>The asset that the labeler will be selecting words from.</p> required <code>sentence</code> <code>str</code> <p>The sentence that the labeler will be selecting words from. (split up by spaces)</p> required <code>required_precision</code> <code>float</code> <p>The required precision for the labeler to get the rapid correct (minimum ratio of the words selected that need to be correct). defaults to 1. (no wrong words can be selected)</p> <code>1</code> <code>required_completeness</code> <code>float</code> <p>The required completeness for the labeler to get the rapid correct (miminum ratio of total correct words selected). defaults to 1. (all correct words need to be selected)</p> <code>1</code> <code>explanation</code> <code>str</code> <p>The explanation that will be shown to the labeler if the answer is wrong. Defaults to None.</p> <code>None</code> Source code in <code>src/rapidata/rapidata_client/validation/rapids/rapids_manager.py</code> <pre><code>def select_words_rapid(\n    self,\n    instruction: str,\n    truths: list[int],\n    datapoint: str,\n    sentence: str,\n    required_precision: float = 1,\n    required_completeness: float = 1,\n    explanation: str | None = None,\n) -&gt; Rapid:\n    \"\"\"Build a select words rapid\n\n    Args:\n        instruction (str): The instruction for the labeler.\n        truths (list[int]): The indices of the words that are the correct answers.\n        datapoint (str): The asset that the labeler will be selecting words from.\n        sentence (str): The sentence that the labeler will be selecting words from. (split up by spaces)\n        required_precision (float): The required precision for the labeler to get the rapid correct (minimum ratio of the words selected that need to be correct). defaults to 1. (no wrong words can be selected)\n        required_completeness (float): The required completeness for the labeler to get the rapid correct (miminum ratio of total correct words selected). defaults to 1. (all correct words need to be selected)\n        explanation (str, optional): The explanation that will be shown to the labeler if the answer is wrong. Defaults to None.\n    \"\"\"\n    from rapidata.api_client.models.i_rapid_payload import IRapidPayload\n    from rapidata.api_client.models.i_rapid_payload_transcription_payload import (\n        IRapidPayloadTranscriptionPayload,\n    )\n    from rapidata.api_client.models.transcription_word import TranscriptionWord\n    from rapidata.api_client.models.i_validation_truth_model import (\n        IValidationTruthModel,\n    )\n    from rapidata.api_client.models.i_validation_truth_model_transcription_truth_model import (\n        IValidationTruthModelTranscriptionTruthModel,\n    )\n    from rapidata.rapidata_client.validation.rapids.rapids import Rapid\n\n    transcription_words = [\n        TranscriptionWord(word=word, wordIndex=i)\n        for i, word in enumerate(sentence.split(\" \"))\n    ]\n\n    correct_transcription_words: list[TranscriptionWord] = []\n    for index in truths:\n        correct_transcription_words.append(\n            TranscriptionWord(word=transcription_words[index].word, wordIndex=index)\n        )\n\n    payload = IRapidPayload(\n        actual_instance=IRapidPayloadTranscriptionPayload(\n            _t=\"TranscriptionPayload\",\n            title=instruction,\n            transcription=transcription_words,\n        )\n    )\n\n    model_truth = IValidationTruthModel(\n        actual_instance=IValidationTruthModelTranscriptionTruthModel(\n            _t=\"TranscriptionTruth\",\n            correctWords=correct_transcription_words,\n            requiredPrecision=required_precision,\n            requiredCompleteness=required_completeness,\n        )\n    )\n\n    return Rapid(\n        payload=payload,\n        truth=model_truth,\n        asset=datapoint,\n        sentence=sentence,\n        explanation=explanation,\n        random_correct_probability=len(correct_transcription_words)\n        / len(transcription_words),\n    )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/validation/rapids/rapids_manager/#rapidata.rapidata_client.validation.rapids.rapids_manager.RapidsManager.locate_rapid","title":"locate_rapid","text":"<pre><code>locate_rapid(\n    instruction: str,\n    truths: list[Box],\n    datapoint: str,\n    context: str | None = None,\n    media_context: str | None = None,\n    explanation: str | None = None,\n) -&gt; Rapid\n</code></pre> <p>Build a locate rapid</p> <p>Parameters:</p> Name Type Description Default <code>instruction</code> <code>str</code> <p>The instruction on what the labeler should do.</p> required <code>truths</code> <code>list[Box]</code> <p>The bounding boxes of the object that the labeler ought to be locating.</p> required <code>datapoint</code> <code>str</code> <p>The asset that the labeler will be locating the object in.</p> required <code>context</code> <code>str</code> <p>The context is text that will be shown in addition to the instruction. Defaults to None.</p> <code>None</code> <code>media_context</code> <code>str</code> <p>The media context is a link to an image / video that will be shown in addition to the instruction (can be combined with context). Defaults to None.</p> <code>None</code> <code>explanation</code> <code>str</code> <p>The explanation that will be shown to the labeler if the answer is wrong. Defaults to None.</p> <code>None</code> Source code in <code>src/rapidata/rapidata_client/validation/rapids/rapids_manager.py</code> <pre><code>def locate_rapid(\n    self,\n    instruction: str,\n    truths: list[Box],\n    datapoint: str,\n    context: str | None = None,\n    media_context: str | None = None,\n    explanation: str | None = None,\n) -&gt; Rapid:\n    \"\"\"Build a locate rapid\n\n    Args:\n        instruction (str): The instruction on what the labeler should do.\n        truths (list[Box]): The bounding boxes of the object that the labeler ought to be locating.\n        datapoint (str): The asset that the labeler will be locating the object in.\n        context (str, optional): The context is text that will be shown in addition to the instruction. Defaults to None.\n        media_context (str, optional): The media context is a link to an image / video that will be shown in addition to the instruction (can be combined with context). Defaults to None.\n        explanation (str, optional): The explanation that will be shown to the labeler if the answer is wrong. Defaults to None.\n    \"\"\"\n    from rapidata.api_client.models.i_rapid_payload import IRapidPayload\n    from rapidata.api_client.models.i_rapid_payload_locate_payload import (\n        IRapidPayloadLocatePayload,\n    )\n    from rapidata.api_client.models.i_validation_truth_model import (\n        IValidationTruthModel,\n    )\n    from rapidata.api_client.models.i_validation_truth_model_locate_box_truth_model import (\n        IValidationTruthModelLocateBoxTruthModel,\n    )\n    from rapidata.rapidata_client.validation.rapids.rapids import Rapid\n\n    payload = IRapidPayload(\n        actual_instance=IRapidPayloadLocatePayload(\n            _t=\"LocatePayload\", target=instruction\n        )\n    )\n\n    model_truth = IValidationTruthModel(\n        actual_instance=IValidationTruthModelLocateBoxTruthModel(\n            _t=\"LocateBoxTruth\",\n            boundingBoxes=[truth.to_model() for truth in truths],\n        )\n    )\n\n    coverage = self._calculate_boxes_coverage(\n        truths,\n    )\n\n    return Rapid(\n        payload=payload,\n        truth=model_truth,\n        asset=datapoint,\n        context=context,\n        media_context=media_context,\n        explanation=explanation,\n        random_correct_probability=coverage,\n    )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/validation/rapids/rapids_manager/#rapidata.rapidata_client.validation.rapids.rapids_manager.RapidsManager.draw_rapid","title":"draw_rapid","text":"<pre><code>draw_rapid(\n    instruction: str,\n    truths: list[Box],\n    datapoint: str,\n    context: str | None = None,\n    media_context: str | None = None,\n    explanation: str | None = None,\n) -&gt; Rapid\n</code></pre> <p>Build a draw rapid</p> <p>Parameters:</p> Name Type Description Default <code>instruction</code> <code>str</code> <p>The instructions on what the labeler</p> required <code>truths</code> <code>list[Box]</code> <p>The bounding boxes of the object that the labeler ought to be drawing.</p> required <code>datapoint</code> <code>str</code> <p>The asset that the labeler will be drawing the object in.</p> required <code>context</code> <code>str</code> <p>The context is text that will be shown in addition to the instruction. Defaults to None.</p> <code>None</code> <code>media_context</code> <code>str</code> <p>The media context is a link to an image / video that will be shown in addition to the instruction (can be combined with context). Defaults to None.</p> <code>None</code> <code>explanation</code> <code>str</code> <p>The explanation that will be shown to the labeler if the answer is wrong. Defaults to None.</p> <code>None</code> Source code in <code>src/rapidata/rapidata_client/validation/rapids/rapids_manager.py</code> <pre><code>def draw_rapid(\n    self,\n    instruction: str,\n    truths: list[Box],\n    datapoint: str,\n    context: str | None = None,\n    media_context: str | None = None,\n    explanation: str | None = None,\n) -&gt; Rapid:\n    \"\"\"Build a draw rapid\n\n    Args:\n        instruction (str): The instructions on what the labeler\n        truths (list[Box]): The bounding boxes of the object that the labeler ought to be drawing.\n        datapoint (str): The asset that the labeler will be drawing the object in.\n        context (str, optional): The context is text that will be shown in addition to the instruction. Defaults to None.\n        media_context (str, optional): The media context is a link to an image / video that will be shown in addition to the instruction (can be combined with context). Defaults to None.\n        explanation (str, optional): The explanation that will be shown to the labeler if the answer is wrong. Defaults to None.\n    \"\"\"\n    from rapidata.api_client.models.i_rapid_payload import IRapidPayload\n    from rapidata.api_client.models.i_rapid_payload_line_payload import (\n        IRapidPayloadLinePayload,\n    )\n    from rapidata.api_client.models.i_validation_truth_model import (\n        IValidationTruthModel,\n    )\n    from rapidata.api_client.models.i_validation_truth_model_bounding_box_truth_model import (\n        IValidationTruthModelBoundingBoxTruthModel,\n    )\n    from rapidata.rapidata_client.validation.rapids.rapids import Rapid\n\n    payload = IRapidPayload(\n        actual_instance=IRapidPayloadLinePayload(\n            _t=\"LinePayload\", target=instruction\n        )\n    )\n\n    model_truth = IValidationTruthModel(\n        actual_instance=IValidationTruthModelBoundingBoxTruthModel(\n            _t=\"BoundingBoxTruth\",\n            xMax=truths[0].x_max * 100,\n            xMin=truths[0].x_min * 100,\n            yMax=truths[0].y_max * 100,\n            yMin=truths[0].y_min * 100,\n        )\n    )\n\n    coverage = self._calculate_boxes_coverage(\n        truths,\n    )\n\n    return Rapid(\n        payload=payload,\n        truth=model_truth,\n        asset=datapoint,\n        context=context,\n        media_context=media_context,\n        explanation=explanation,\n        random_correct_probability=coverage,\n    )\n</code></pre>","boost":0.2},{"location":"reference/rapidata/rapidata_client/validation/rapids/rapids_manager/#rapidata.rapidata_client.validation.rapids.rapids_manager.RapidsManager.timestamp_rapid","title":"timestamp_rapid","text":"<pre><code>timestamp_rapid(\n    instruction: str,\n    truths: list[tuple[int, int]],\n    datapoint: str,\n    context: str | None = None,\n    media_context: str | None = None,\n    explanation: str | None = None,\n) -&gt; Rapid\n</code></pre> <p>Build a timestamp rapid</p> <p>Parameters:</p> Name Type Description Default <code>instruction</code> <code>str</code> <p>The instruction for the labeler.</p> required <code>truths</code> <code>list[tuple[int, int]]</code> <p>The possible accepted timestamps intervals for the labeler (in miliseconds). The first element of the tuple is the start of the interval and the second element is the end of the interval.</p> required <code>datapoint</code> <code>str</code> <p>The asset that the labeler will be timestamping.</p> required <code>context</code> <code>str</code> <p>The context is text that will be shown in addition to the instruction. Defaults to None.</p> <code>None</code> <code>media_context</code> <code>str</code> <p>The media context is a link to an image / video that will be shown in addition to the instruction (can be combined with context). Defaults to None.</p> <code>None</code> <code>explanation</code> <code>str</code> <p>The explanation that will be shown to the labeler if the answer is wrong. Defaults to None.</p> <code>None</code> Source code in <code>src/rapidata/rapidata_client/validation/rapids/rapids_manager.py</code> <pre><code>def timestamp_rapid(\n    self,\n    instruction: str,\n    truths: list[tuple[int, int]],\n    datapoint: str,\n    context: str | None = None,\n    media_context: str | None = None,\n    explanation: str | None = None,\n) -&gt; Rapid:\n    \"\"\"Build a timestamp rapid\n\n    Args:\n        instruction (str): The instruction for the labeler.\n        truths (list[tuple[int, int]]): The possible accepted timestamps intervals for the labeler (in miliseconds).\n            The first element of the tuple is the start of the interval and the second element is the end of the interval.\n        datapoint (str): The asset that the labeler will be timestamping.\n        context (str, optional): The context is text that will be shown in addition to the instruction. Defaults to None.\n        media_context (str, optional): The media context is a link to an image / video that will be shown in addition to the instruction (can be combined with context). Defaults to None.\n        explanation (str, optional): The explanation that will be shown to the labeler if the answer is wrong. Defaults to None.\n    \"\"\"\n    from rapidata.api_client.models.i_rapid_payload import IRapidPayload\n    from rapidata.api_client.models.i_rapid_payload_scrub_payload import (\n        IRapidPayloadScrubPayload,\n    )\n    from rapidata.api_client.models.scrub_range import ScrubRange\n    from rapidata.api_client.models.i_validation_truth_model import (\n        IValidationTruthModel,\n    )\n    from rapidata.api_client.models.i_validation_truth_model_scrub_truth_model import (\n        IValidationTruthModelScrubTruthModel,\n    )\n    from rapidata.rapidata_client.validation.rapids.rapids import Rapid\n\n    for truth in truths:\n        if len(truth) != 2:\n            raise ValueError(\n                \"The truths per datapoint must be a tuple of exactly two integers.\"\n            )\n        if truth[0] &gt; truth[1]:\n            raise ValueError(\n                \"The start of the interval must be smaller than the end of the interval.\"\n            )\n\n    payload = IRapidPayload(\n        actual_instance=IRapidPayloadScrubPayload(\n            _t=\"ScrubPayload\", target=instruction\n        )\n    )\n\n    model_truth = IValidationTruthModel(\n        actual_instance=IValidationTruthModelScrubTruthModel(\n            _t=\"ScrubTruth\",\n            validRanges=[\n                ScrubRange(start=truth[0], end=truth[1]) for truth in truths\n            ],\n        )\n    )\n\n    return Rapid(\n        payload=payload,\n        truth=model_truth,\n        asset=datapoint,\n        context=context,\n        media_context=media_context,\n        explanation=explanation,\n        random_correct_probability=0.5,  # TODO: implement coverage ratio\n    )\n</code></pre>","boost":0.2}]}